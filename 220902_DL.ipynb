{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "185PIWiH1X3awi5btv648BA7m3dyO3B6b",
      "authorship_tag": "ABX9TyMv5vOn0yc+DnarFIYoBZjF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtype2100/DeepLearning/blob/master/220902_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbAOS1Y4qm9v",
        "outputId": "719532e2-0034-40d4-8aa5-bb7021dc634a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deeplearning'...\n",
            "remote: Enumerating objects: 787, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 787 (delta 4), reused 1 (delta 0), pack-reused 776\u001b[K\n",
            "Receiving objects: 100% (787/787), 46.72 MiB | 45.17 MiB/s, done.\n",
            "Resolving deltas: 100% (304/304), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/taehojo/deeplearning.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "metadata": {
        "id": "xugDlQd1q4E2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/deeplearning/data/wine.csv')"
      ],
      "metadata": {
        "id": "mYtA41HGrK82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mJnjkzZWrSZc",
        "outputId": "75a2728a-5aad-4670-b2bd-6713dc4430bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    7.4   0.7     0  1.9  0.076    11    34  0.9978  3.51  0.56  9.4  5  1\n",
              "0   7.8  0.88  0.00  2.6  0.098  25.0  67.0  0.9968  3.20  0.68  9.8  5  1\n",
              "1   7.8  0.76  0.04  2.3  0.092  15.0  54.0  0.9970  3.26  0.65  9.8  5  1\n",
              "2  11.2  0.28  0.56  1.9  0.075  17.0  60.0  0.9980  3.16  0.58  9.8  6  1\n",
              "3   7.4  0.70  0.00  1.9  0.076  11.0  34.0  0.9978  3.51  0.56  9.4  5  1\n",
              "4   7.4  0.66  0.00  1.8  0.075  13.0  40.0  0.9978  3.51  0.56  9.4  5  1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7bc0fd77-1e0e-4ad2-ade7-0a5417cdb796\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>7.4</th>\n",
              "      <th>0.7</th>\n",
              "      <th>0</th>\n",
              "      <th>1.9</th>\n",
              "      <th>0.076</th>\n",
              "      <th>11</th>\n",
              "      <th>34</th>\n",
              "      <th>0.9978</th>\n",
              "      <th>3.51</th>\n",
              "      <th>0.56</th>\n",
              "      <th>9.4</th>\n",
              "      <th>5</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.9970</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.9980</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.075</td>\n",
              "      <td>13.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7bc0fd77-1e0e-4ad2-ade7-0a5417cdb796')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7bc0fd77-1e0e-4ad2-ade7-0a5417cdb796 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7bc0fd77-1e0e-4ad2-ade7-0a5417cdb796');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:, 0:12]\n",
        "y = df.iloc[:, 12]"
      ],
      "metadata": {
        "id": "jC371ld0rSzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(30, input_dim=12, activation='relu'))\n",
        "model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=500, validation_split=0.25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3XZALtLsACW",
        "outputId": "b1429f7e-7204-4c0d-9a18-d9b50afb6c7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "8/8 [==============================] - 1s 24ms/step - loss: 15.1524 - accuracy: 0.2484 - val_loss: 11.2405 - val_accuracy: 0.2402\n",
            "Epoch 2/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 8.3668 - accuracy: 0.2484 - val_loss: 5.2866 - val_accuracy: 0.2402\n",
            "Epoch 3/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.3534 - accuracy: 0.2484 - val_loss: 2.2153 - val_accuracy: 0.2402\n",
            "Epoch 4/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.0774 - accuracy: 0.2484 - val_loss: 1.9843 - val_accuracy: 0.2402\n",
            "Epoch 5/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.8383 - accuracy: 0.2484 - val_loss: 1.7246 - val_accuracy: 0.2402\n",
            "Epoch 6/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5844 - accuracy: 0.2484 - val_loss: 1.4738 - val_accuracy: 0.2402\n",
            "Epoch 7/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3527 - accuracy: 0.2484 - val_loss: 1.2574 - val_accuracy: 0.2402\n",
            "Epoch 8/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1584 - accuracy: 0.2484 - val_loss: 1.0833 - val_accuracy: 0.2402\n",
            "Epoch 9/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.0038 - accuracy: 0.2484 - val_loss: 0.9498 - val_accuracy: 0.2402\n",
            "Epoch 10/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.8872 - accuracy: 0.2484 - val_loss: 0.8472 - val_accuracy: 0.2402\n",
            "Epoch 11/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7970 - accuracy: 0.2484 - val_loss: 0.7723 - val_accuracy: 0.2402\n",
            "Epoch 12/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7328 - accuracy: 0.2484 - val_loss: 0.7218 - val_accuracy: 0.2402\n",
            "Epoch 13/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6920 - accuracy: 0.2476 - val_loss: 0.6878 - val_accuracy: 0.2379\n",
            "Epoch 14/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6618 - accuracy: 0.2520 - val_loss: 0.6620 - val_accuracy: 0.2533\n",
            "Epoch 15/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6397 - accuracy: 0.2784 - val_loss: 0.6411 - val_accuracy: 0.3010\n",
            "Epoch 16/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6227 - accuracy: 0.3390 - val_loss: 0.6242 - val_accuracy: 0.3895\n",
            "Epoch 17/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.4519 - val_loss: 0.6110 - val_accuracy: 0.5173\n",
            "Epoch 18/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5954 - accuracy: 0.5733 - val_loss: 0.5990 - val_accuracy: 0.6513\n",
            "Epoch 19/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5846 - accuracy: 0.7113 - val_loss: 0.5881 - val_accuracy: 0.7583\n",
            "Epoch 20/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5743 - accuracy: 0.8217 - val_loss: 0.5788 - val_accuracy: 0.8345\n",
            "Epoch 21/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5651 - accuracy: 0.8707 - val_loss: 0.5692 - val_accuracy: 0.8584\n",
            "Epoch 22/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5568 - accuracy: 0.8915 - val_loss: 0.5604 - val_accuracy: 0.8830\n",
            "Epoch 23/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5491 - accuracy: 0.9128 - val_loss: 0.5533 - val_accuracy: 0.9076\n",
            "Epoch 24/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5434 - accuracy: 0.9187 - val_loss: 0.5487 - val_accuracy: 0.9145\n",
            "Epoch 25/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5396 - accuracy: 0.9210 - val_loss: 0.5436 - val_accuracy: 0.9176\n",
            "Epoch 26/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5362 - accuracy: 0.9228 - val_loss: 0.5403 - val_accuracy: 0.9199\n",
            "Epoch 27/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5339 - accuracy: 0.9256 - val_loss: 0.5379 - val_accuracy: 0.9199\n",
            "Epoch 28/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5313 - accuracy: 0.9279 - val_loss: 0.5356 - val_accuracy: 0.9215\n",
            "Epoch 29/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5292 - accuracy: 0.9281 - val_loss: 0.5335 - val_accuracy: 0.9246\n",
            "Epoch 30/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5270 - accuracy: 0.9284 - val_loss: 0.5313 - val_accuracy: 0.9253\n",
            "Epoch 31/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5249 - accuracy: 0.9284 - val_loss: 0.5294 - val_accuracy: 0.9261\n",
            "Epoch 32/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5230 - accuracy: 0.9284 - val_loss: 0.5270 - val_accuracy: 0.9276\n",
            "Epoch 33/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5210 - accuracy: 0.9284 - val_loss: 0.5251 - val_accuracy: 0.9276\n",
            "Epoch 34/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5190 - accuracy: 0.9281 - val_loss: 0.5230 - val_accuracy: 0.9269\n",
            "Epoch 35/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5168 - accuracy: 0.9289 - val_loss: 0.5213 - val_accuracy: 0.9299\n",
            "Epoch 36/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5149 - accuracy: 0.9289 - val_loss: 0.5191 - val_accuracy: 0.9299\n",
            "Epoch 37/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5129 - accuracy: 0.9292 - val_loss: 0.5169 - val_accuracy: 0.9315\n",
            "Epoch 38/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5112 - accuracy: 0.9287 - val_loss: 0.5150 - val_accuracy: 0.9284\n",
            "Epoch 39/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.9289 - val_loss: 0.5134 - val_accuracy: 0.9315\n",
            "Epoch 40/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.9299 - val_loss: 0.5110 - val_accuracy: 0.9330\n",
            "Epoch 41/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5052 - accuracy: 0.9294 - val_loss: 0.5089 - val_accuracy: 0.9323\n",
            "Epoch 42/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5031 - accuracy: 0.9305 - val_loss: 0.5070 - val_accuracy: 0.9346\n",
            "Epoch 43/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.9312 - val_loss: 0.5051 - val_accuracy: 0.9353\n",
            "Epoch 44/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4992 - accuracy: 0.9310 - val_loss: 0.5027 - val_accuracy: 0.9346\n",
            "Epoch 45/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4971 - accuracy: 0.9323 - val_loss: 0.5010 - val_accuracy: 0.9353\n",
            "Epoch 46/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4952 - accuracy: 0.9325 - val_loss: 0.4988 - val_accuracy: 0.9338\n",
            "Epoch 47/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4929 - accuracy: 0.9323 - val_loss: 0.4968 - val_accuracy: 0.9346\n",
            "Epoch 48/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4911 - accuracy: 0.9330 - val_loss: 0.4947 - val_accuracy: 0.9361\n",
            "Epoch 49/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4891 - accuracy: 0.9328 - val_loss: 0.4927 - val_accuracy: 0.9384\n",
            "Epoch 50/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4872 - accuracy: 0.9343 - val_loss: 0.4903 - val_accuracy: 0.9384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, y_test)\n",
        "print('Test accuracy', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OInQvUJIs-C2",
        "outputId": "4cf73fd2-49b5-4b6d-d6c9-a0bec4ea2739"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 0s 869us/step - loss: 0.4903 - accuracy: 0.9362\n",
            "0.9361538290977478\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.read_csv('/content/deeplearning/data/wine.csv')\n",
        "\n",
        "X = df.iloc[:,0:12]\n",
        "y = df.iloc[:,12]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(30,  input_dim=12, activation='relu'))\n",
        "model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-5YdF2YvBY9",
        "outputId": "4ffb9f5e-4200-47cd-ee89-a1d731636b72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 30)                390       \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 12)                372       \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 8)                 104       \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 875\n",
            "Trainable params: 875\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelpath = '{epoch:02d}-{val_accuracy:.4f}.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath=modelpath, vervose=1)\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=500,\n",
        "                    validation_split=0.25, verbose=0, callbacks=[checkpoint])"
      ],
      "metadata": {
        "id": "ohWNFY8iw6Aq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, y_test)\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJKu_5yBxgGj",
        "outputId": "49efdd1f-3975-4f31-ecf7-a6734068a020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 0s 925us/step - loss: 0.0822 - accuracy: 0.9746\n",
            "Test accuracy: 0.9746153950691223\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(X_train, y_train, epochs=2000, batch_size=500, verbose=0, validation_split=0.25)"
      ],
      "metadata": {
        "id": "u2B94Y3A2iXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist_df = pd.DataFrame(history.history)\n",
        "hist_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "QaHg_rJgyP7j",
        "outputId": "57bbfd51-94cc-434d-e415-afee12a17bc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          loss  accuracy  val_loss  val_accuracy\n",
              "0     0.091192  0.970490  0.110295      0.966128\n",
              "1     0.093593  0.971260  0.108574      0.958430\n",
              "2     0.091327  0.972286  0.108670      0.961509\n",
              "3     0.092662  0.968694  0.105977      0.967667\n",
              "4     0.090206  0.972543  0.105040      0.966898\n",
              "...        ...       ...       ...           ...\n",
              "1995  0.039531  0.989222  0.095203      0.980754\n",
              "1996  0.027398  0.992558  0.089678      0.989222\n",
              "1997  0.019335  0.995381  0.153300      0.977675\n",
              "1998  0.027291  0.992815  0.139970      0.981524\n",
              "1999  0.021747  0.994355  0.107696      0.986143\n",
              "\n",
              "[2000 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a8e3cfc-ede6-4e93-8805-1f1c3821f7ec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.091192</td>\n",
              "      <td>0.970490</td>\n",
              "      <td>0.110295</td>\n",
              "      <td>0.966128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.093593</td>\n",
              "      <td>0.971260</td>\n",
              "      <td>0.108574</td>\n",
              "      <td>0.958430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.091327</td>\n",
              "      <td>0.972286</td>\n",
              "      <td>0.108670</td>\n",
              "      <td>0.961509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.092662</td>\n",
              "      <td>0.968694</td>\n",
              "      <td>0.105977</td>\n",
              "      <td>0.967667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.090206</td>\n",
              "      <td>0.972543</td>\n",
              "      <td>0.105040</td>\n",
              "      <td>0.966898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>0.039531</td>\n",
              "      <td>0.989222</td>\n",
              "      <td>0.095203</td>\n",
              "      <td>0.980754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>0.027398</td>\n",
              "      <td>0.992558</td>\n",
              "      <td>0.089678</td>\n",
              "      <td>0.989222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>0.019335</td>\n",
              "      <td>0.995381</td>\n",
              "      <td>0.153300</td>\n",
              "      <td>0.977675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>0.027291</td>\n",
              "      <td>0.992815</td>\n",
              "      <td>0.139970</td>\n",
              "      <td>0.981524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>0.021747</td>\n",
              "      <td>0.994355</td>\n",
              "      <td>0.107696</td>\n",
              "      <td>0.986143</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a8e3cfc-ede6-4e93-8805-1f1c3821f7ec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7a8e3cfc-ede6-4e93-8805-1f1c3821f7ec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7a8e3cfc-ede6-4e93-8805-1f1c3821f7ec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_vloss=hist_df['val_loss']\n",
        "y_loss=hist_df['loss']\n",
        "\n",
        "x_len = np.arange(len(y_loss))\n",
        "plt.plot(x_len, y_vloss, 'o', c='red', markersize=2, label='Testset_loss')\n",
        "plt.plot(x_len, y_loss, 'o', c='blue', markersize=2, label='Trainset_loss')\n",
        "\n",
        "plt.legend(loc='upper right')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "NxzBdmwj2UF_",
        "outputId": "39e316c2-5822-4212-f864-518c68811920"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/deeplearning/data/wine.csv', header=None)\n",
        "\n",
        "X = df.iloc[:,0:12]\n",
        "y = df.iloc[:,12]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(30,  input_dim=12, activation='relu'))\n",
        "model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCtzbfKe3r-W",
        "outputId": "d6bc971a-1409-4000-dc4b-2675ad70c7de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 30)                390       \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 12)                372       \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 8)                 104       \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 875\n",
            "Trainable params: 875\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)\n",
        "\n",
        "modelpath=\"Ch14-4-bestmodel.hdf5\"\n",
        "\n",
        "# 최적화 모델을 업데이트하고 저장\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=0, save_best_only=True)\n",
        "\n",
        "history=model.fit(X_train, y_train, epochs=2000, batch_size=500, validation_split=0.25, verbose=1, callbacks=[checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZgZiSSJ4LXX",
        "outputId": "c9321bdc-3646-440e-b71d-4c25d40c4e0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "8/8 [==============================] - 1s 22ms/step - loss: 1.2226 - accuracy: 0.7619 - val_loss: 0.8759 - val_accuracy: 0.7838\n",
            "Epoch 2/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6086 - accuracy: 0.8009 - val_loss: 0.3649 - val_accuracy: 0.8600\n",
            "Epoch 3/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3173 - accuracy: 0.8886 - val_loss: 0.3052 - val_accuracy: 0.9177\n",
            "Epoch 4/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2645 - accuracy: 0.9217 - val_loss: 0.2529 - val_accuracy: 0.9200\n",
            "Epoch 5/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2421 - accuracy: 0.9215 - val_loss: 0.2262 - val_accuracy: 0.9346\n",
            "Epoch 6/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2198 - accuracy: 0.9312 - val_loss: 0.2088 - val_accuracy: 0.9369\n",
            "Epoch 7/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2097 - accuracy: 0.9346 - val_loss: 0.1974 - val_accuracy: 0.9331\n",
            "Epoch 8/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2006 - accuracy: 0.9379 - val_loss: 0.1930 - val_accuracy: 0.9338\n",
            "Epoch 9/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1945 - accuracy: 0.9387 - val_loss: 0.1846 - val_accuracy: 0.9362\n",
            "Epoch 10/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1912 - accuracy: 0.9369 - val_loss: 0.1826 - val_accuracy: 0.9369\n",
            "Epoch 11/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1878 - accuracy: 0.9382 - val_loss: 0.1805 - val_accuracy: 0.9369\n",
            "Epoch 12/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1856 - accuracy: 0.9382 - val_loss: 0.1789 - val_accuracy: 0.9369\n",
            "Epoch 13/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1839 - accuracy: 0.9382 - val_loss: 0.1775 - val_accuracy: 0.9392\n",
            "Epoch 14/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1821 - accuracy: 0.9392 - val_loss: 0.1779 - val_accuracy: 0.9369\n",
            "Epoch 15/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1809 - accuracy: 0.9394 - val_loss: 0.1754 - val_accuracy: 0.9400\n",
            "Epoch 16/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1791 - accuracy: 0.9400 - val_loss: 0.1745 - val_accuracy: 0.9385\n",
            "Epoch 17/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1760 - accuracy: 0.9407 - val_loss: 0.1708 - val_accuracy: 0.9385\n",
            "Epoch 18/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1730 - accuracy: 0.9402 - val_loss: 0.1682 - val_accuracy: 0.9369\n",
            "Epoch 19/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1707 - accuracy: 0.9407 - val_loss: 0.1650 - val_accuracy: 0.9377\n",
            "Epoch 20/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1701 - accuracy: 0.9405 - val_loss: 0.1647 - val_accuracy: 0.9385\n",
            "Epoch 21/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1680 - accuracy: 0.9405 - val_loss: 0.1640 - val_accuracy: 0.9369\n",
            "Epoch 22/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1665 - accuracy: 0.9402 - val_loss: 0.1614 - val_accuracy: 0.9392\n",
            "Epoch 23/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1654 - accuracy: 0.9425 - val_loss: 0.1603 - val_accuracy: 0.9392\n",
            "Epoch 24/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1641 - accuracy: 0.9428 - val_loss: 0.1592 - val_accuracy: 0.9400\n",
            "Epoch 25/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1629 - accuracy: 0.9425 - val_loss: 0.1598 - val_accuracy: 0.9377\n",
            "Epoch 26/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1627 - accuracy: 0.9433 - val_loss: 0.1563 - val_accuracy: 0.9423\n",
            "Epoch 27/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1613 - accuracy: 0.9438 - val_loss: 0.1580 - val_accuracy: 0.9385\n",
            "Epoch 28/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1594 - accuracy: 0.9425 - val_loss: 0.1535 - val_accuracy: 0.9423\n",
            "Epoch 29/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1578 - accuracy: 0.9453 - val_loss: 0.1585 - val_accuracy: 0.9369\n",
            "Epoch 30/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1576 - accuracy: 0.9448 - val_loss: 0.1514 - val_accuracy: 0.9431\n",
            "Epoch 31/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1581 - accuracy: 0.9441 - val_loss: 0.1500 - val_accuracy: 0.9423\n",
            "Epoch 32/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1553 - accuracy: 0.9474 - val_loss: 0.1504 - val_accuracy: 0.9415\n",
            "Epoch 33/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1532 - accuracy: 0.9474 - val_loss: 0.1499 - val_accuracy: 0.9415\n",
            "Epoch 34/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1518 - accuracy: 0.9464 - val_loss: 0.1463 - val_accuracy: 0.9431\n",
            "Epoch 35/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1506 - accuracy: 0.9482 - val_loss: 0.1456 - val_accuracy: 0.9431\n",
            "Epoch 36/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1490 - accuracy: 0.9479 - val_loss: 0.1461 - val_accuracy: 0.9438\n",
            "Epoch 37/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1490 - accuracy: 0.9479 - val_loss: 0.1558 - val_accuracy: 0.9385\n",
            "Epoch 38/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1487 - accuracy: 0.9474 - val_loss: 0.1430 - val_accuracy: 0.9454\n",
            "Epoch 39/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1462 - accuracy: 0.9487 - val_loss: 0.1412 - val_accuracy: 0.9446\n",
            "Epoch 40/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1436 - accuracy: 0.9492 - val_loss: 0.1415 - val_accuracy: 0.9446\n",
            "Epoch 41/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1428 - accuracy: 0.9494 - val_loss: 0.1410 - val_accuracy: 0.9438\n",
            "Epoch 42/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1420 - accuracy: 0.9492 - val_loss: 0.1365 - val_accuracy: 0.9477\n",
            "Epoch 43/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1393 - accuracy: 0.9512 - val_loss: 0.1384 - val_accuracy: 0.9446\n",
            "Epoch 44/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1383 - accuracy: 0.9507 - val_loss: 0.1348 - val_accuracy: 0.9454\n",
            "Epoch 45/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1370 - accuracy: 0.9494 - val_loss: 0.1328 - val_accuracy: 0.9462\n",
            "Epoch 46/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1354 - accuracy: 0.9520 - val_loss: 0.1331 - val_accuracy: 0.9469\n",
            "Epoch 47/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1337 - accuracy: 0.9502 - val_loss: 0.1298 - val_accuracy: 0.9477\n",
            "Epoch 48/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1329 - accuracy: 0.9512 - val_loss: 0.1304 - val_accuracy: 0.9485\n",
            "Epoch 49/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1308 - accuracy: 0.9533 - val_loss: 0.1317 - val_accuracy: 0.9485\n",
            "Epoch 50/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1299 - accuracy: 0.9533 - val_loss: 0.1275 - val_accuracy: 0.9485\n",
            "Epoch 51/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1288 - accuracy: 0.9530 - val_loss: 0.1260 - val_accuracy: 0.9492\n",
            "Epoch 52/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1303 - accuracy: 0.9541 - val_loss: 0.1294 - val_accuracy: 0.9615\n",
            "Epoch 53/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1268 - accuracy: 0.9536 - val_loss: 0.1236 - val_accuracy: 0.9500\n",
            "Epoch 54/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1241 - accuracy: 0.9528 - val_loss: 0.1251 - val_accuracy: 0.9485\n",
            "Epoch 55/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1228 - accuracy: 0.9536 - val_loss: 0.1224 - val_accuracy: 0.9515\n",
            "Epoch 56/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1213 - accuracy: 0.9538 - val_loss: 0.1194 - val_accuracy: 0.9523\n",
            "Epoch 57/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1198 - accuracy: 0.9554 - val_loss: 0.1211 - val_accuracy: 0.9508\n",
            "Epoch 58/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1189 - accuracy: 0.9548 - val_loss: 0.1202 - val_accuracy: 0.9500\n",
            "Epoch 59/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1179 - accuracy: 0.9551 - val_loss: 0.1175 - val_accuracy: 0.9531\n",
            "Epoch 60/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1161 - accuracy: 0.9569 - val_loss: 0.1165 - val_accuracy: 0.9523\n",
            "Epoch 61/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1153 - accuracy: 0.9566 - val_loss: 0.1149 - val_accuracy: 0.9531\n",
            "Epoch 62/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1139 - accuracy: 0.9574 - val_loss: 0.1129 - val_accuracy: 0.9592\n",
            "Epoch 63/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1135 - accuracy: 0.9605 - val_loss: 0.1185 - val_accuracy: 0.9508\n",
            "Epoch 64/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1124 - accuracy: 0.9615 - val_loss: 0.1156 - val_accuracy: 0.9523\n",
            "Epoch 65/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1109 - accuracy: 0.9610 - val_loss: 0.1107 - val_accuracy: 0.9585\n",
            "Epoch 66/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1096 - accuracy: 0.9600 - val_loss: 0.1098 - val_accuracy: 0.9569\n",
            "Epoch 67/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1086 - accuracy: 0.9605 - val_loss: 0.1081 - val_accuracy: 0.9592\n",
            "Epoch 68/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1075 - accuracy: 0.9610 - val_loss: 0.1068 - val_accuracy: 0.9615\n",
            "Epoch 69/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1075 - accuracy: 0.9636 - val_loss: 0.1062 - val_accuracy: 0.9646\n",
            "Epoch 70/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1059 - accuracy: 0.9638 - val_loss: 0.1075 - val_accuracy: 0.9577\n",
            "Epoch 71/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1034 - accuracy: 0.9630 - val_loss: 0.1033 - val_accuracy: 0.9646\n",
            "Epoch 72/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1059 - accuracy: 0.9638 - val_loss: 0.1030 - val_accuracy: 0.9677\n",
            "Epoch 73/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1020 - accuracy: 0.9638 - val_loss: 0.1017 - val_accuracy: 0.9700\n",
            "Epoch 74/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1017 - accuracy: 0.9651 - val_loss: 0.1006 - val_accuracy: 0.9685\n",
            "Epoch 75/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0994 - accuracy: 0.9659 - val_loss: 0.1000 - val_accuracy: 0.9646\n",
            "Epoch 76/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0990 - accuracy: 0.9651 - val_loss: 0.0975 - val_accuracy: 0.9700\n",
            "Epoch 77/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0988 - accuracy: 0.9672 - val_loss: 0.0976 - val_accuracy: 0.9669\n",
            "Epoch 78/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0966 - accuracy: 0.9690 - val_loss: 0.1057 - val_accuracy: 0.9554\n",
            "Epoch 79/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0974 - accuracy: 0.9669 - val_loss: 0.0938 - val_accuracy: 0.9700\n",
            "Epoch 80/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0942 - accuracy: 0.9705 - val_loss: 0.0964 - val_accuracy: 0.9662\n",
            "Epoch 81/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0939 - accuracy: 0.9692 - val_loss: 0.0925 - val_accuracy: 0.9731\n",
            "Epoch 82/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0935 - accuracy: 0.9692 - val_loss: 0.0909 - val_accuracy: 0.9731\n",
            "Epoch 83/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0917 - accuracy: 0.9725 - val_loss: 0.0920 - val_accuracy: 0.9692\n",
            "Epoch 84/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0908 - accuracy: 0.9720 - val_loss: 0.0889 - val_accuracy: 0.9731\n",
            "Epoch 85/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0888 - accuracy: 0.9718 - val_loss: 0.0894 - val_accuracy: 0.9800\n",
            "Epoch 86/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0888 - accuracy: 0.9723 - val_loss: 0.0873 - val_accuracy: 0.9746\n",
            "Epoch 87/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0877 - accuracy: 0.9713 - val_loss: 0.0859 - val_accuracy: 0.9769\n",
            "Epoch 88/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0911 - accuracy: 0.9697 - val_loss: 0.0865 - val_accuracy: 0.9800\n",
            "Epoch 89/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0889 - accuracy: 0.9707 - val_loss: 0.0836 - val_accuracy: 0.9769\n",
            "Epoch 90/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0861 - accuracy: 0.9728 - val_loss: 0.0852 - val_accuracy: 0.9746\n",
            "Epoch 91/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0841 - accuracy: 0.9754 - val_loss: 0.0902 - val_accuracy: 0.9692\n",
            "Epoch 92/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0830 - accuracy: 0.9720 - val_loss: 0.0863 - val_accuracy: 0.9715\n",
            "Epoch 93/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0833 - accuracy: 0.9743 - val_loss: 0.0886 - val_accuracy: 0.9692\n",
            "Epoch 94/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0837 - accuracy: 0.9715 - val_loss: 0.0888 - val_accuracy: 0.9692\n",
            "Epoch 95/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0828 - accuracy: 0.9720 - val_loss: 0.0798 - val_accuracy: 0.9769\n",
            "Epoch 96/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0808 - accuracy: 0.9746 - val_loss: 0.0857 - val_accuracy: 0.9708\n",
            "Epoch 97/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0794 - accuracy: 0.9751 - val_loss: 0.0788 - val_accuracy: 0.9792\n",
            "Epoch 98/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0808 - accuracy: 0.9741 - val_loss: 0.0771 - val_accuracy: 0.9815\n",
            "Epoch 99/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0826 - accuracy: 0.9718 - val_loss: 0.0772 - val_accuracy: 0.9800\n",
            "Epoch 100/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0849 - accuracy: 0.9749 - val_loss: 0.0762 - val_accuracy: 0.9792\n",
            "Epoch 101/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0846 - accuracy: 0.9728 - val_loss: 0.0775 - val_accuracy: 0.9762\n",
            "Epoch 102/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0785 - accuracy: 0.9743 - val_loss: 0.0749 - val_accuracy: 0.9800\n",
            "Epoch 103/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0768 - accuracy: 0.9759 - val_loss: 0.0742 - val_accuracy: 0.9815\n",
            "Epoch 104/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0764 - accuracy: 0.9779 - val_loss: 0.0741 - val_accuracy: 0.9838\n",
            "Epoch 105/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0751 - accuracy: 0.9774 - val_loss: 0.0734 - val_accuracy: 0.9815\n",
            "Epoch 106/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0737 - accuracy: 0.9772 - val_loss: 0.0768 - val_accuracy: 0.9769\n",
            "Epoch 107/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0760 - accuracy: 0.9759 - val_loss: 0.0843 - val_accuracy: 0.9715\n",
            "Epoch 108/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0754 - accuracy: 0.9784 - val_loss: 0.0769 - val_accuracy: 0.9754\n",
            "Epoch 109/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0726 - accuracy: 0.9769 - val_loss: 0.0717 - val_accuracy: 0.9823\n",
            "Epoch 110/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0718 - accuracy: 0.9779 - val_loss: 0.0735 - val_accuracy: 0.9792\n",
            "Epoch 111/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0715 - accuracy: 0.9782 - val_loss: 0.0710 - val_accuracy: 0.9838\n",
            "Epoch 112/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0776 - accuracy: 0.9754 - val_loss: 0.0745 - val_accuracy: 0.9823\n",
            "Epoch 113/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0771 - accuracy: 0.9738 - val_loss: 0.0707 - val_accuracy: 0.9831\n",
            "Epoch 114/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0717 - accuracy: 0.9790 - val_loss: 0.0695 - val_accuracy: 0.9862\n",
            "Epoch 115/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0705 - accuracy: 0.9787 - val_loss: 0.0698 - val_accuracy: 0.9823\n",
            "Epoch 116/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0685 - accuracy: 0.9800 - val_loss: 0.0692 - val_accuracy: 0.9823\n",
            "Epoch 117/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0684 - accuracy: 0.9787 - val_loss: 0.0703 - val_accuracy: 0.9800\n",
            "Epoch 118/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0686 - accuracy: 0.9779 - val_loss: 0.0688 - val_accuracy: 0.9838\n",
            "Epoch 119/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0671 - accuracy: 0.9795 - val_loss: 0.0673 - val_accuracy: 0.9854\n",
            "Epoch 120/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0682 - accuracy: 0.9782 - val_loss: 0.0694 - val_accuracy: 0.9854\n",
            "Epoch 121/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0663 - accuracy: 0.9800 - val_loss: 0.0687 - val_accuracy: 0.9831\n",
            "Epoch 122/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0687 - accuracy: 0.9784 - val_loss: 0.0706 - val_accuracy: 0.9808\n",
            "Epoch 123/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0688 - accuracy: 0.9774 - val_loss: 0.0769 - val_accuracy: 0.9754\n",
            "Epoch 124/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0696 - accuracy: 0.9795 - val_loss: 0.0673 - val_accuracy: 0.9823\n",
            "Epoch 125/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0675 - accuracy: 0.9792 - val_loss: 0.0674 - val_accuracy: 0.9823\n",
            "Epoch 126/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0670 - accuracy: 0.9787 - val_loss: 0.0721 - val_accuracy: 0.9792\n",
            "Epoch 127/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0682 - accuracy: 0.9797 - val_loss: 0.0694 - val_accuracy: 0.9808\n",
            "Epoch 128/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0684 - accuracy: 0.9787 - val_loss: 0.0654 - val_accuracy: 0.9815\n",
            "Epoch 129/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0638 - accuracy: 0.9808 - val_loss: 0.0667 - val_accuracy: 0.9823\n",
            "Epoch 130/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0633 - accuracy: 0.9813 - val_loss: 0.0640 - val_accuracy: 0.9862\n",
            "Epoch 131/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0649 - accuracy: 0.9813 - val_loss: 0.0656 - val_accuracy: 0.9854\n",
            "Epoch 132/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0678 - accuracy: 0.9795 - val_loss: 0.0653 - val_accuracy: 0.9862\n",
            "Epoch 133/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0656 - accuracy: 0.9800 - val_loss: 0.0629 - val_accuracy: 0.9877\n",
            "Epoch 134/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0628 - accuracy: 0.9805 - val_loss: 0.0647 - val_accuracy: 0.9815\n",
            "Epoch 135/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0626 - accuracy: 0.9818 - val_loss: 0.0649 - val_accuracy: 0.9823\n",
            "Epoch 136/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0620 - accuracy: 0.9808 - val_loss: 0.0651 - val_accuracy: 0.9831\n",
            "Epoch 137/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0614 - accuracy: 0.9808 - val_loss: 0.0628 - val_accuracy: 0.9838\n",
            "Epoch 138/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0604 - accuracy: 0.9828 - val_loss: 0.0627 - val_accuracy: 0.9831\n",
            "Epoch 139/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0611 - accuracy: 0.9813 - val_loss: 0.0620 - val_accuracy: 0.9846\n",
            "Epoch 140/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0605 - accuracy: 0.9820 - val_loss: 0.0624 - val_accuracy: 0.9854\n",
            "Epoch 141/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0597 - accuracy: 0.9820 - val_loss: 0.0620 - val_accuracy: 0.9838\n",
            "Epoch 142/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0594 - accuracy: 0.9808 - val_loss: 0.0710 - val_accuracy: 0.9823\n",
            "Epoch 143/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0636 - accuracy: 0.9797 - val_loss: 0.0625 - val_accuracy: 0.9862\n",
            "Epoch 144/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0655 - accuracy: 0.9813 - val_loss: 0.0727 - val_accuracy: 0.9815\n",
            "Epoch 145/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0719 - accuracy: 0.9800 - val_loss: 0.0638 - val_accuracy: 0.9869\n",
            "Epoch 146/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0638 - accuracy: 0.9802 - val_loss: 0.0607 - val_accuracy: 0.9838\n",
            "Epoch 147/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0592 - accuracy: 0.9818 - val_loss: 0.0645 - val_accuracy: 0.9838\n",
            "Epoch 148/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0591 - accuracy: 0.9820 - val_loss: 0.0602 - val_accuracy: 0.9838\n",
            "Epoch 149/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0584 - accuracy: 0.9820 - val_loss: 0.0611 - val_accuracy: 0.9831\n",
            "Epoch 150/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0598 - accuracy: 0.9810 - val_loss: 0.0616 - val_accuracy: 0.9823\n",
            "Epoch 151/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0579 - accuracy: 0.9810 - val_loss: 0.0729 - val_accuracy: 0.9785\n",
            "Epoch 152/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0643 - accuracy: 0.9813 - val_loss: 0.0673 - val_accuracy: 0.9792\n",
            "Epoch 153/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0636 - accuracy: 0.9808 - val_loss: 0.0642 - val_accuracy: 0.9831\n",
            "Epoch 154/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0660 - accuracy: 0.9792 - val_loss: 0.0609 - val_accuracy: 0.9831\n",
            "Epoch 155/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0596 - accuracy: 0.9828 - val_loss: 0.0608 - val_accuracy: 0.9862\n",
            "Epoch 156/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0592 - accuracy: 0.9831 - val_loss: 0.0592 - val_accuracy: 0.9877\n",
            "Epoch 157/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0582 - accuracy: 0.9815 - val_loss: 0.0608 - val_accuracy: 0.9862\n",
            "Epoch 158/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0563 - accuracy: 0.9833 - val_loss: 0.0595 - val_accuracy: 0.9862\n",
            "Epoch 159/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0587 - accuracy: 0.9826 - val_loss: 0.0636 - val_accuracy: 0.9854\n",
            "Epoch 160/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0600 - accuracy: 0.9805 - val_loss: 0.0596 - val_accuracy: 0.9862\n",
            "Epoch 161/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0572 - accuracy: 0.9823 - val_loss: 0.0590 - val_accuracy: 0.9862\n",
            "Epoch 162/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0558 - accuracy: 0.9826 - val_loss: 0.0610 - val_accuracy: 0.9831\n",
            "Epoch 163/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0556 - accuracy: 0.9836 - val_loss: 0.0638 - val_accuracy: 0.9823\n",
            "Epoch 164/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0563 - accuracy: 0.9826 - val_loss: 0.0584 - val_accuracy: 0.9862\n",
            "Epoch 165/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0546 - accuracy: 0.9838 - val_loss: 0.0584 - val_accuracy: 0.9862\n",
            "Epoch 166/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0554 - accuracy: 0.9831 - val_loss: 0.0617 - val_accuracy: 0.9838\n",
            "Epoch 167/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0552 - accuracy: 0.9831 - val_loss: 0.0593 - val_accuracy: 0.9846\n",
            "Epoch 168/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0548 - accuracy: 0.9828 - val_loss: 0.0600 - val_accuracy: 0.9846\n",
            "Epoch 169/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0559 - accuracy: 0.9813 - val_loss: 0.0578 - val_accuracy: 0.9869\n",
            "Epoch 170/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0548 - accuracy: 0.9851 - val_loss: 0.0608 - val_accuracy: 0.9838\n",
            "Epoch 171/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0535 - accuracy: 0.9836 - val_loss: 0.0665 - val_accuracy: 0.9815\n",
            "Epoch 172/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0602 - accuracy: 0.9831 - val_loss: 0.0607 - val_accuracy: 0.9862\n",
            "Epoch 173/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0541 - accuracy: 0.9838 - val_loss: 0.0596 - val_accuracy: 0.9854\n",
            "Epoch 174/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0539 - accuracy: 0.9826 - val_loss: 0.0576 - val_accuracy: 0.9869\n",
            "Epoch 175/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0537 - accuracy: 0.9836 - val_loss: 0.0638 - val_accuracy: 0.9846\n",
            "Epoch 176/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0573 - accuracy: 0.9833 - val_loss: 0.0602 - val_accuracy: 0.9854\n",
            "Epoch 177/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0533 - accuracy: 0.9841 - val_loss: 0.0608 - val_accuracy: 0.9838\n",
            "Epoch 178/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0561 - accuracy: 0.9808 - val_loss: 0.0651 - val_accuracy: 0.9808\n",
            "Epoch 179/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0565 - accuracy: 0.9808 - val_loss: 0.0613 - val_accuracy: 0.9846\n",
            "Epoch 180/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0551 - accuracy: 0.9826 - val_loss: 0.0587 - val_accuracy: 0.9846\n",
            "Epoch 181/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0536 - accuracy: 0.9820 - val_loss: 0.0597 - val_accuracy: 0.9846\n",
            "Epoch 182/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0529 - accuracy: 0.9833 - val_loss: 0.0599 - val_accuracy: 0.9846\n",
            "Epoch 183/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0523 - accuracy: 0.9833 - val_loss: 0.0574 - val_accuracy: 0.9869\n",
            "Epoch 184/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0526 - accuracy: 0.9843 - val_loss: 0.0584 - val_accuracy: 0.9877\n",
            "Epoch 185/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0525 - accuracy: 0.9838 - val_loss: 0.0577 - val_accuracy: 0.9877\n",
            "Epoch 186/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0523 - accuracy: 0.9838 - val_loss: 0.0573 - val_accuracy: 0.9862\n",
            "Epoch 187/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0527 - accuracy: 0.9833 - val_loss: 0.0565 - val_accuracy: 0.9877\n",
            "Epoch 188/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0527 - accuracy: 0.9833 - val_loss: 0.0576 - val_accuracy: 0.9869\n",
            "Epoch 189/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0565 - accuracy: 0.9826 - val_loss: 0.0572 - val_accuracy: 0.9877\n",
            "Epoch 190/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0537 - accuracy: 0.9843 - val_loss: 0.0666 - val_accuracy: 0.9815\n",
            "Epoch 191/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0548 - accuracy: 0.9813 - val_loss: 0.0599 - val_accuracy: 0.9846\n",
            "Epoch 192/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0531 - accuracy: 0.9833 - val_loss: 0.0635 - val_accuracy: 0.9823\n",
            "Epoch 193/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0563 - accuracy: 0.9818 - val_loss: 0.0635 - val_accuracy: 0.9823\n",
            "Epoch 194/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0552 - accuracy: 0.9841 - val_loss: 0.0699 - val_accuracy: 0.9792\n",
            "Epoch 195/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0558 - accuracy: 0.9841 - val_loss: 0.0585 - val_accuracy: 0.9846\n",
            "Epoch 196/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0535 - accuracy: 0.9818 - val_loss: 0.0559 - val_accuracy: 0.9862\n",
            "Epoch 197/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0504 - accuracy: 0.9836 - val_loss: 0.0582 - val_accuracy: 0.9854\n",
            "Epoch 198/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0501 - accuracy: 0.9861 - val_loss: 0.0592 - val_accuracy: 0.9846\n",
            "Epoch 199/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0513 - accuracy: 0.9826 - val_loss: 0.0555 - val_accuracy: 0.9869\n",
            "Epoch 200/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0516 - accuracy: 0.9831 - val_loss: 0.0562 - val_accuracy: 0.9885\n",
            "Epoch 201/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0516 - accuracy: 0.9854 - val_loss: 0.0557 - val_accuracy: 0.9869\n",
            "Epoch 202/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0497 - accuracy: 0.9849 - val_loss: 0.0553 - val_accuracy: 0.9885\n",
            "Epoch 203/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0505 - accuracy: 0.9846 - val_loss: 0.0645 - val_accuracy: 0.9823\n",
            "Epoch 204/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0538 - accuracy: 0.9828 - val_loss: 0.0604 - val_accuracy: 0.9838\n",
            "Epoch 205/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0522 - accuracy: 0.9826 - val_loss: 0.0553 - val_accuracy: 0.9885\n",
            "Epoch 206/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0511 - accuracy: 0.9851 - val_loss: 0.0550 - val_accuracy: 0.9885\n",
            "Epoch 207/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0527 - accuracy: 0.9828 - val_loss: 0.0553 - val_accuracy: 0.9862\n",
            "Epoch 208/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0517 - accuracy: 0.9841 - val_loss: 0.0572 - val_accuracy: 0.9846\n",
            "Epoch 209/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0495 - accuracy: 0.9854 - val_loss: 0.0544 - val_accuracy: 0.9877\n",
            "Epoch 210/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0491 - accuracy: 0.9854 - val_loss: 0.0559 - val_accuracy: 0.9862\n",
            "Epoch 211/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0490 - accuracy: 0.9851 - val_loss: 0.0592 - val_accuracy: 0.9846\n",
            "Epoch 212/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0515 - accuracy: 0.9849 - val_loss: 0.0573 - val_accuracy: 0.9846\n",
            "Epoch 213/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0517 - accuracy: 0.9831 - val_loss: 0.0547 - val_accuracy: 0.9869\n",
            "Epoch 214/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0495 - accuracy: 0.9846 - val_loss: 0.0544 - val_accuracy: 0.9885\n",
            "Epoch 215/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0484 - accuracy: 0.9849 - val_loss: 0.0552 - val_accuracy: 0.9885\n",
            "Epoch 216/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0498 - accuracy: 0.9838 - val_loss: 0.0547 - val_accuracy: 0.9885\n",
            "Epoch 217/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0495 - accuracy: 0.9856 - val_loss: 0.0592 - val_accuracy: 0.9846\n",
            "Epoch 218/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0510 - accuracy: 0.9836 - val_loss: 0.0648 - val_accuracy: 0.9815\n",
            "Epoch 219/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0508 - accuracy: 0.9843 - val_loss: 0.0610 - val_accuracy: 0.9838\n",
            "Epoch 220/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0500 - accuracy: 0.9841 - val_loss: 0.0546 - val_accuracy: 0.9869\n",
            "Epoch 221/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0490 - accuracy: 0.9849 - val_loss: 0.0537 - val_accuracy: 0.9877\n",
            "Epoch 222/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0484 - accuracy: 0.9856 - val_loss: 0.0539 - val_accuracy: 0.9877\n",
            "Epoch 223/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0500 - accuracy: 0.9846 - val_loss: 0.0538 - val_accuracy: 0.9885\n",
            "Epoch 224/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0480 - accuracy: 0.9841 - val_loss: 0.0544 - val_accuracy: 0.9885\n",
            "Epoch 225/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0474 - accuracy: 0.9859 - val_loss: 0.0541 - val_accuracy: 0.9862\n",
            "Epoch 226/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0476 - accuracy: 0.9854 - val_loss: 0.0536 - val_accuracy: 0.9877\n",
            "Epoch 227/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0495 - accuracy: 0.9838 - val_loss: 0.0573 - val_accuracy: 0.9846\n",
            "Epoch 228/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0549 - accuracy: 0.9823 - val_loss: 0.0636 - val_accuracy: 0.9800\n",
            "Epoch 229/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0545 - accuracy: 0.9818 - val_loss: 0.0638 - val_accuracy: 0.9823\n",
            "Epoch 230/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0522 - accuracy: 0.9815 - val_loss: 0.0565 - val_accuracy: 0.9854\n",
            "Epoch 231/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0482 - accuracy: 0.9854 - val_loss: 0.0543 - val_accuracy: 0.9854\n",
            "Epoch 232/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0469 - accuracy: 0.9854 - val_loss: 0.0530 - val_accuracy: 0.9885\n",
            "Epoch 233/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0473 - accuracy: 0.9856 - val_loss: 0.0540 - val_accuracy: 0.9885\n",
            "Epoch 234/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0533 - accuracy: 0.9818 - val_loss: 0.0573 - val_accuracy: 0.9862\n",
            "Epoch 235/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0559 - accuracy: 0.9818 - val_loss: 0.0556 - val_accuracy: 0.9846\n",
            "Epoch 236/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0514 - accuracy: 0.9859 - val_loss: 0.0633 - val_accuracy: 0.9838\n",
            "Epoch 237/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0490 - accuracy: 0.9856 - val_loss: 0.0543 - val_accuracy: 0.9854\n",
            "Epoch 238/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0484 - accuracy: 0.9854 - val_loss: 0.0527 - val_accuracy: 0.9869\n",
            "Epoch 239/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0469 - accuracy: 0.9856 - val_loss: 0.0556 - val_accuracy: 0.9854\n",
            "Epoch 240/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0472 - accuracy: 0.9856 - val_loss: 0.0535 - val_accuracy: 0.9862\n",
            "Epoch 241/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0468 - accuracy: 0.9859 - val_loss: 0.0534 - val_accuracy: 0.9862\n",
            "Epoch 242/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0463 - accuracy: 0.9864 - val_loss: 0.0525 - val_accuracy: 0.9869\n",
            "Epoch 243/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0460 - accuracy: 0.9859 - val_loss: 0.0524 - val_accuracy: 0.9877\n",
            "Epoch 244/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0458 - accuracy: 0.9859 - val_loss: 0.0531 - val_accuracy: 0.9869\n",
            "Epoch 245/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0460 - accuracy: 0.9864 - val_loss: 0.0530 - val_accuracy: 0.9869\n",
            "Epoch 246/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0458 - accuracy: 0.9861 - val_loss: 0.0523 - val_accuracy: 0.9885\n",
            "Epoch 247/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0460 - accuracy: 0.9859 - val_loss: 0.0521 - val_accuracy: 0.9877\n",
            "Epoch 248/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0454 - accuracy: 0.9861 - val_loss: 0.0531 - val_accuracy: 0.9877\n",
            "Epoch 249/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0464 - accuracy: 0.9851 - val_loss: 0.0530 - val_accuracy: 0.9877\n",
            "Epoch 250/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0457 - accuracy: 0.9864 - val_loss: 0.0529 - val_accuracy: 0.9877\n",
            "Epoch 251/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0459 - accuracy: 0.9867 - val_loss: 0.0547 - val_accuracy: 0.9877\n",
            "Epoch 252/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0499 - accuracy: 0.9836 - val_loss: 0.0584 - val_accuracy: 0.9854\n",
            "Epoch 253/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0478 - accuracy: 0.9841 - val_loss: 0.0540 - val_accuracy: 0.9885\n",
            "Epoch 254/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0569 - accuracy: 0.9820 - val_loss: 0.0549 - val_accuracy: 0.9846\n",
            "Epoch 255/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0503 - accuracy: 0.9831 - val_loss: 0.0587 - val_accuracy: 0.9862\n",
            "Epoch 256/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0476 - accuracy: 0.9843 - val_loss: 0.0572 - val_accuracy: 0.9854\n",
            "Epoch 257/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0475 - accuracy: 0.9859 - val_loss: 0.0552 - val_accuracy: 0.9854\n",
            "Epoch 258/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0482 - accuracy: 0.9846 - val_loss: 0.0616 - val_accuracy: 0.9815\n",
            "Epoch 259/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0473 - accuracy: 0.9841 - val_loss: 0.0525 - val_accuracy: 0.9869\n",
            "Epoch 260/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0467 - accuracy: 0.9874 - val_loss: 0.0520 - val_accuracy: 0.9877\n",
            "Epoch 261/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0462 - accuracy: 0.9864 - val_loss: 0.0521 - val_accuracy: 0.9869\n",
            "Epoch 262/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0448 - accuracy: 0.9874 - val_loss: 0.0525 - val_accuracy: 0.9869\n",
            "Epoch 263/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0444 - accuracy: 0.9867 - val_loss: 0.0525 - val_accuracy: 0.9869\n",
            "Epoch 264/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0442 - accuracy: 0.9867 - val_loss: 0.0541 - val_accuracy: 0.9877\n",
            "Epoch 265/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0465 - accuracy: 0.9867 - val_loss: 0.0524 - val_accuracy: 0.9877\n",
            "Epoch 266/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0456 - accuracy: 0.9877 - val_loss: 0.0526 - val_accuracy: 0.9869\n",
            "Epoch 267/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0440 - accuracy: 0.9859 - val_loss: 0.0521 - val_accuracy: 0.9877\n",
            "Epoch 268/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0443 - accuracy: 0.9869 - val_loss: 0.0519 - val_accuracy: 0.9877\n",
            "Epoch 269/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0441 - accuracy: 0.9867 - val_loss: 0.0517 - val_accuracy: 0.9877\n",
            "Epoch 270/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0458 - accuracy: 0.9849 - val_loss: 0.0521 - val_accuracy: 0.9869\n",
            "Epoch 271/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0464 - accuracy: 0.9859 - val_loss: 0.0588 - val_accuracy: 0.9823\n",
            "Epoch 272/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0462 - accuracy: 0.9861 - val_loss: 0.0555 - val_accuracy: 0.9854\n",
            "Epoch 273/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0458 - accuracy: 0.9864 - val_loss: 0.0554 - val_accuracy: 0.9862\n",
            "Epoch 274/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0469 - accuracy: 0.9843 - val_loss: 0.0543 - val_accuracy: 0.9854\n",
            "Epoch 275/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0446 - accuracy: 0.9856 - val_loss: 0.0520 - val_accuracy: 0.9877\n",
            "Epoch 276/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0464 - accuracy: 0.9859 - val_loss: 0.0564 - val_accuracy: 0.9862\n",
            "Epoch 277/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0458 - accuracy: 0.9872 - val_loss: 0.0534 - val_accuracy: 0.9846\n",
            "Epoch 278/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0442 - accuracy: 0.9872 - val_loss: 0.0545 - val_accuracy: 0.9862\n",
            "Epoch 279/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0453 - accuracy: 0.9877 - val_loss: 0.0566 - val_accuracy: 0.9854\n",
            "Epoch 280/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0452 - accuracy: 0.9856 - val_loss: 0.0554 - val_accuracy: 0.9869\n",
            "Epoch 281/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0528 - accuracy: 0.9836 - val_loss: 0.0556 - val_accuracy: 0.9869\n",
            "Epoch 282/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0453 - accuracy: 0.9867 - val_loss: 0.0523 - val_accuracy: 0.9885\n",
            "Epoch 283/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0444 - accuracy: 0.9867 - val_loss: 0.0537 - val_accuracy: 0.9869\n",
            "Epoch 284/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0436 - accuracy: 0.9864 - val_loss: 0.0525 - val_accuracy: 0.9854\n",
            "Epoch 285/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0457 - accuracy: 0.9856 - val_loss: 0.0517 - val_accuracy: 0.9885\n",
            "Epoch 286/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0442 - accuracy: 0.9849 - val_loss: 0.0577 - val_accuracy: 0.9869\n",
            "Epoch 287/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0444 - accuracy: 0.9872 - val_loss: 0.0517 - val_accuracy: 0.9854\n",
            "Epoch 288/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0431 - accuracy: 0.9874 - val_loss: 0.0519 - val_accuracy: 0.9877\n",
            "Epoch 289/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0441 - accuracy: 0.9872 - val_loss: 0.0520 - val_accuracy: 0.9885\n",
            "Epoch 290/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0425 - accuracy: 0.9879 - val_loss: 0.0514 - val_accuracy: 0.9869\n",
            "Epoch 291/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0429 - accuracy: 0.9861 - val_loss: 0.0512 - val_accuracy: 0.9869\n",
            "Epoch 292/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0436 - accuracy: 0.9869 - val_loss: 0.0530 - val_accuracy: 0.9892\n",
            "Epoch 293/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0430 - accuracy: 0.9882 - val_loss: 0.0511 - val_accuracy: 0.9885\n",
            "Epoch 294/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0431 - accuracy: 0.9874 - val_loss: 0.0514 - val_accuracy: 0.9877\n",
            "Epoch 295/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0426 - accuracy: 0.9867 - val_loss: 0.0517 - val_accuracy: 0.9877\n",
            "Epoch 296/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0438 - accuracy: 0.9867 - val_loss: 0.0513 - val_accuracy: 0.9869\n",
            "Epoch 297/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0447 - accuracy: 0.9879 - val_loss: 0.0532 - val_accuracy: 0.9862\n",
            "Epoch 298/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0467 - accuracy: 0.9864 - val_loss: 0.0521 - val_accuracy: 0.9877\n",
            "Epoch 299/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0464 - accuracy: 0.9861 - val_loss: 0.0539 - val_accuracy: 0.9877\n",
            "Epoch 300/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0488 - accuracy: 0.9838 - val_loss: 0.0560 - val_accuracy: 0.9869\n",
            "Epoch 301/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0451 - accuracy: 0.9854 - val_loss: 0.0512 - val_accuracy: 0.9885\n",
            "Epoch 302/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0421 - accuracy: 0.9867 - val_loss: 0.0517 - val_accuracy: 0.9885\n",
            "Epoch 303/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0426 - accuracy: 0.9882 - val_loss: 0.0516 - val_accuracy: 0.9877\n",
            "Epoch 304/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0423 - accuracy: 0.9877 - val_loss: 0.0523 - val_accuracy: 0.9885\n",
            "Epoch 305/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0422 - accuracy: 0.9869 - val_loss: 0.0561 - val_accuracy: 0.9869\n",
            "Epoch 306/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0432 - accuracy: 0.9864 - val_loss: 0.0536 - val_accuracy: 0.9862\n",
            "Epoch 307/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0437 - accuracy: 0.9872 - val_loss: 0.0508 - val_accuracy: 0.9877\n",
            "Epoch 308/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0442 - accuracy: 0.9869 - val_loss: 0.0507 - val_accuracy: 0.9885\n",
            "Epoch 309/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0412 - accuracy: 0.9879 - val_loss: 0.0528 - val_accuracy: 0.9877\n",
            "Epoch 310/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0427 - accuracy: 0.9869 - val_loss: 0.0511 - val_accuracy: 0.9869\n",
            "Epoch 311/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0421 - accuracy: 0.9887 - val_loss: 0.0532 - val_accuracy: 0.9892\n",
            "Epoch 312/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0421 - accuracy: 0.9872 - val_loss: 0.0507 - val_accuracy: 0.9885\n",
            "Epoch 313/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0413 - accuracy: 0.9890 - val_loss: 0.0504 - val_accuracy: 0.9877\n",
            "Epoch 314/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0424 - accuracy: 0.9879 - val_loss: 0.0574 - val_accuracy: 0.9862\n",
            "Epoch 315/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0431 - accuracy: 0.9872 - val_loss: 0.0502 - val_accuracy: 0.9885\n",
            "Epoch 316/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0414 - accuracy: 0.9872 - val_loss: 0.0506 - val_accuracy: 0.9885\n",
            "Epoch 317/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0433 - accuracy: 0.9879 - val_loss: 0.0508 - val_accuracy: 0.9877\n",
            "Epoch 318/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0418 - accuracy: 0.9879 - val_loss: 0.0502 - val_accuracy: 0.9885\n",
            "Epoch 319/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0414 - accuracy: 0.9885 - val_loss: 0.0522 - val_accuracy: 0.9862\n",
            "Epoch 320/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0446 - accuracy: 0.9874 - val_loss: 0.0753 - val_accuracy: 0.9777\n",
            "Epoch 321/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0483 - accuracy: 0.9856 - val_loss: 0.0654 - val_accuracy: 0.9815\n",
            "Epoch 322/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0515 - accuracy: 0.9843 - val_loss: 0.0512 - val_accuracy: 0.9877\n",
            "Epoch 323/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0454 - accuracy: 0.9859 - val_loss: 0.0523 - val_accuracy: 0.9869\n",
            "Epoch 324/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0447 - accuracy: 0.9864 - val_loss: 0.0498 - val_accuracy: 0.9892\n",
            "Epoch 325/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0407 - accuracy: 0.9885 - val_loss: 0.0504 - val_accuracy: 0.9877\n",
            "Epoch 326/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0416 - accuracy: 0.9885 - val_loss: 0.0504 - val_accuracy: 0.9877\n",
            "Epoch 327/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0430 - accuracy: 0.9882 - val_loss: 0.0562 - val_accuracy: 0.9869\n",
            "Epoch 328/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0419 - accuracy: 0.9885 - val_loss: 0.0511 - val_accuracy: 0.9869\n",
            "Epoch 329/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0415 - accuracy: 0.9882 - val_loss: 0.0535 - val_accuracy: 0.9877\n",
            "Epoch 330/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0417 - accuracy: 0.9879 - val_loss: 0.0516 - val_accuracy: 0.9869\n",
            "Epoch 331/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0440 - accuracy: 0.9877 - val_loss: 0.0570 - val_accuracy: 0.9854\n",
            "Epoch 332/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0431 - accuracy: 0.9885 - val_loss: 0.0558 - val_accuracy: 0.9869\n",
            "Epoch 333/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0431 - accuracy: 0.9885 - val_loss: 0.0538 - val_accuracy: 0.9869\n",
            "Epoch 334/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0438 - accuracy: 0.9877 - val_loss: 0.0535 - val_accuracy: 0.9862\n",
            "Epoch 335/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0426 - accuracy: 0.9885 - val_loss: 0.0505 - val_accuracy: 0.9877\n",
            "Epoch 336/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0409 - accuracy: 0.9885 - val_loss: 0.0499 - val_accuracy: 0.9892\n",
            "Epoch 337/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0410 - accuracy: 0.9892 - val_loss: 0.0510 - val_accuracy: 0.9900\n",
            "Epoch 338/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0411 - accuracy: 0.9892 - val_loss: 0.0503 - val_accuracy: 0.9900\n",
            "Epoch 339/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0417 - accuracy: 0.9882 - val_loss: 0.0588 - val_accuracy: 0.9862\n",
            "Epoch 340/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0534 - accuracy: 0.9854 - val_loss: 0.0515 - val_accuracy: 0.9892\n",
            "Epoch 341/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0485 - accuracy: 0.9851 - val_loss: 0.0507 - val_accuracy: 0.9885\n",
            "Epoch 342/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0408 - accuracy: 0.9885 - val_loss: 0.0497 - val_accuracy: 0.9885\n",
            "Epoch 343/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0411 - accuracy: 0.9882 - val_loss: 0.0526 - val_accuracy: 0.9862\n",
            "Epoch 344/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0411 - accuracy: 0.9882 - val_loss: 0.0522 - val_accuracy: 0.9869\n",
            "Epoch 345/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0405 - accuracy: 0.9897 - val_loss: 0.0498 - val_accuracy: 0.9885\n",
            "Epoch 346/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0395 - accuracy: 0.9897 - val_loss: 0.0493 - val_accuracy: 0.9877\n",
            "Epoch 347/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0395 - accuracy: 0.9885 - val_loss: 0.0504 - val_accuracy: 0.9900\n",
            "Epoch 348/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0411 - accuracy: 0.9874 - val_loss: 0.0529 - val_accuracy: 0.9885\n",
            "Epoch 349/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0402 - accuracy: 0.9885 - val_loss: 0.0509 - val_accuracy: 0.9877\n",
            "Epoch 350/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0419 - accuracy: 0.9874 - val_loss: 0.0596 - val_accuracy: 0.9846\n",
            "Epoch 351/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0431 - accuracy: 0.9867 - val_loss: 0.0544 - val_accuracy: 0.9862\n",
            "Epoch 352/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0411 - accuracy: 0.9879 - val_loss: 0.0503 - val_accuracy: 0.9869\n",
            "Epoch 353/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0417 - accuracy: 0.9882 - val_loss: 0.0506 - val_accuracy: 0.9900\n",
            "Epoch 354/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0395 - accuracy: 0.9895 - val_loss: 0.0501 - val_accuracy: 0.9869\n",
            "Epoch 355/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0395 - accuracy: 0.9890 - val_loss: 0.0510 - val_accuracy: 0.9862\n",
            "Epoch 356/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0405 - accuracy: 0.9890 - val_loss: 0.0593 - val_accuracy: 0.9854\n",
            "Epoch 357/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0411 - accuracy: 0.9867 - val_loss: 0.0496 - val_accuracy: 0.9892\n",
            "Epoch 358/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0395 - accuracy: 0.9885 - val_loss: 0.0509 - val_accuracy: 0.9877\n",
            "Epoch 359/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0391 - accuracy: 0.9900 - val_loss: 0.0499 - val_accuracy: 0.9900\n",
            "Epoch 360/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0396 - accuracy: 0.9897 - val_loss: 0.0496 - val_accuracy: 0.9885\n",
            "Epoch 361/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0402 - accuracy: 0.9885 - val_loss: 0.0496 - val_accuracy: 0.9900\n",
            "Epoch 362/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0391 - accuracy: 0.9890 - val_loss: 0.0501 - val_accuracy: 0.9900\n",
            "Epoch 363/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0389 - accuracy: 0.9895 - val_loss: 0.0499 - val_accuracy: 0.9877\n",
            "Epoch 364/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0392 - accuracy: 0.9882 - val_loss: 0.0591 - val_accuracy: 0.9862\n",
            "Epoch 365/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0438 - accuracy: 0.9879 - val_loss: 0.0529 - val_accuracy: 0.9908\n",
            "Epoch 366/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0433 - accuracy: 0.9877 - val_loss: 0.0502 - val_accuracy: 0.9892\n",
            "Epoch 367/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0421 - accuracy: 0.9879 - val_loss: 0.0573 - val_accuracy: 0.9854\n",
            "Epoch 368/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0410 - accuracy: 0.9887 - val_loss: 0.0495 - val_accuracy: 0.9892\n",
            "Epoch 369/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0396 - accuracy: 0.9900 - val_loss: 0.0496 - val_accuracy: 0.9892\n",
            "Epoch 370/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0387 - accuracy: 0.9897 - val_loss: 0.0517 - val_accuracy: 0.9877\n",
            "Epoch 371/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0398 - accuracy: 0.9890 - val_loss: 0.0504 - val_accuracy: 0.9869\n",
            "Epoch 372/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0402 - accuracy: 0.9885 - val_loss: 0.0497 - val_accuracy: 0.9877\n",
            "Epoch 373/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0393 - accuracy: 0.9892 - val_loss: 0.0510 - val_accuracy: 0.9885\n",
            "Epoch 374/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0394 - accuracy: 0.9895 - val_loss: 0.0499 - val_accuracy: 0.9892\n",
            "Epoch 375/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0396 - accuracy: 0.9892 - val_loss: 0.0508 - val_accuracy: 0.9900\n",
            "Epoch 376/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0403 - accuracy: 0.9885 - val_loss: 0.0529 - val_accuracy: 0.9869\n",
            "Epoch 377/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0403 - accuracy: 0.9885 - val_loss: 0.0533 - val_accuracy: 0.9869\n",
            "Epoch 378/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0416 - accuracy: 0.9879 - val_loss: 0.0538 - val_accuracy: 0.9862\n",
            "Epoch 379/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0386 - accuracy: 0.9892 - val_loss: 0.0500 - val_accuracy: 0.9885\n",
            "Epoch 380/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0401 - accuracy: 0.9885 - val_loss: 0.0508 - val_accuracy: 0.9877\n",
            "Epoch 381/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0406 - accuracy: 0.9892 - val_loss: 0.0504 - val_accuracy: 0.9885\n",
            "Epoch 382/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0401 - accuracy: 0.9885 - val_loss: 0.0507 - val_accuracy: 0.9869\n",
            "Epoch 383/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0383 - accuracy: 0.9902 - val_loss: 0.0501 - val_accuracy: 0.9892\n",
            "Epoch 384/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0391 - accuracy: 0.9892 - val_loss: 0.0500 - val_accuracy: 0.9892\n",
            "Epoch 385/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0395 - accuracy: 0.9890 - val_loss: 0.0518 - val_accuracy: 0.9900\n",
            "Epoch 386/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0421 - accuracy: 0.9882 - val_loss: 0.0641 - val_accuracy: 0.9854\n",
            "Epoch 387/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0436 - accuracy: 0.9861 - val_loss: 0.0503 - val_accuracy: 0.9892\n",
            "Epoch 388/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0394 - accuracy: 0.9902 - val_loss: 0.0491 - val_accuracy: 0.9885\n",
            "Epoch 389/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0394 - accuracy: 0.9887 - val_loss: 0.0509 - val_accuracy: 0.9877\n",
            "Epoch 390/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0408 - accuracy: 0.9879 - val_loss: 0.0554 - val_accuracy: 0.9869\n",
            "Epoch 391/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0394 - accuracy: 0.9892 - val_loss: 0.0546 - val_accuracy: 0.9877\n",
            "Epoch 392/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0394 - accuracy: 0.9892 - val_loss: 0.0502 - val_accuracy: 0.9885\n",
            "Epoch 393/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0381 - accuracy: 0.9897 - val_loss: 0.0502 - val_accuracy: 0.9885\n",
            "Epoch 394/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0410 - accuracy: 0.9885 - val_loss: 0.0515 - val_accuracy: 0.9892\n",
            "Epoch 395/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0438 - accuracy: 0.9856 - val_loss: 0.0573 - val_accuracy: 0.9869\n",
            "Epoch 396/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0416 - accuracy: 0.9872 - val_loss: 0.0513 - val_accuracy: 0.9892\n",
            "Epoch 397/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0384 - accuracy: 0.9892 - val_loss: 0.0499 - val_accuracy: 0.9885\n",
            "Epoch 398/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0381 - accuracy: 0.9895 - val_loss: 0.0493 - val_accuracy: 0.9892\n",
            "Epoch 399/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0382 - accuracy: 0.9897 - val_loss: 0.0506 - val_accuracy: 0.9869\n",
            "Epoch 400/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0388 - accuracy: 0.9892 - val_loss: 0.0504 - val_accuracy: 0.9892\n",
            "Epoch 401/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0387 - accuracy: 0.9887 - val_loss: 0.0499 - val_accuracy: 0.9885\n",
            "Epoch 402/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0395 - accuracy: 0.9905 - val_loss: 0.0514 - val_accuracy: 0.9885\n",
            "Epoch 403/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0411 - accuracy: 0.9890 - val_loss: 0.0510 - val_accuracy: 0.9892\n",
            "Epoch 404/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0386 - accuracy: 0.9902 - val_loss: 0.0505 - val_accuracy: 0.9885\n",
            "Epoch 405/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0387 - accuracy: 0.9895 - val_loss: 0.0502 - val_accuracy: 0.9900\n",
            "Epoch 406/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0386 - accuracy: 0.9895 - val_loss: 0.0570 - val_accuracy: 0.9846\n",
            "Epoch 407/2000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0443 - accuracy: 0.9869 - val_loss: 0.0537 - val_accuracy: 0.9869\n",
            "Epoch 408/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0381 - accuracy: 0.9895 - val_loss: 0.0584 - val_accuracy: 0.9854\n",
            "Epoch 409/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0404 - accuracy: 0.9892 - val_loss: 0.0514 - val_accuracy: 0.9869\n",
            "Epoch 410/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0382 - accuracy: 0.9885 - val_loss: 0.0518 - val_accuracy: 0.9877\n",
            "Epoch 411/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0391 - accuracy: 0.9902 - val_loss: 0.0506 - val_accuracy: 0.9885\n",
            "Epoch 412/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0380 - accuracy: 0.9887 - val_loss: 0.0528 - val_accuracy: 0.9854\n",
            "Epoch 413/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0385 - accuracy: 0.9895 - val_loss: 0.0503 - val_accuracy: 0.9892\n",
            "Epoch 414/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0374 - accuracy: 0.9892 - val_loss: 0.0517 - val_accuracy: 0.9885\n",
            "Epoch 415/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0394 - accuracy: 0.9887 - val_loss: 0.0564 - val_accuracy: 0.9862\n",
            "Epoch 416/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0395 - accuracy: 0.9872 - val_loss: 0.0519 - val_accuracy: 0.9885\n",
            "Epoch 417/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0402 - accuracy: 0.9900 - val_loss: 0.0504 - val_accuracy: 0.9885\n",
            "Epoch 418/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0378 - accuracy: 0.9892 - val_loss: 0.0510 - val_accuracy: 0.9869\n",
            "Epoch 419/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0377 - accuracy: 0.9892 - val_loss: 0.0543 - val_accuracy: 0.9877\n",
            "Epoch 420/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0391 - accuracy: 0.9882 - val_loss: 0.0504 - val_accuracy: 0.9885\n",
            "Epoch 421/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0377 - accuracy: 0.9905 - val_loss: 0.0583 - val_accuracy: 0.9854\n",
            "Epoch 422/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0438 - accuracy: 0.9872 - val_loss: 0.0569 - val_accuracy: 0.9854\n",
            "Epoch 423/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0390 - accuracy: 0.9892 - val_loss: 0.0510 - val_accuracy: 0.9885\n",
            "Epoch 424/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0373 - accuracy: 0.9900 - val_loss: 0.0508 - val_accuracy: 0.9869\n",
            "Epoch 425/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0374 - accuracy: 0.9900 - val_loss: 0.0508 - val_accuracy: 0.9877\n",
            "Epoch 426/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0375 - accuracy: 0.9902 - val_loss: 0.0511 - val_accuracy: 0.9892\n",
            "Epoch 427/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0370 - accuracy: 0.9900 - val_loss: 0.0502 - val_accuracy: 0.9885\n",
            "Epoch 428/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0372 - accuracy: 0.9910 - val_loss: 0.0503 - val_accuracy: 0.9885\n",
            "Epoch 429/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0366 - accuracy: 0.9900 - val_loss: 0.0512 - val_accuracy: 0.9869\n",
            "Epoch 430/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0392 - accuracy: 0.9890 - val_loss: 0.0522 - val_accuracy: 0.9869\n",
            "Epoch 431/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0446 - accuracy: 0.9869 - val_loss: 0.0527 - val_accuracy: 0.9869\n",
            "Epoch 432/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0396 - accuracy: 0.9887 - val_loss: 0.0619 - val_accuracy: 0.9846\n",
            "Epoch 433/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0429 - accuracy: 0.9874 - val_loss: 0.0569 - val_accuracy: 0.9854\n",
            "Epoch 434/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0405 - accuracy: 0.9895 - val_loss: 0.0496 - val_accuracy: 0.9892\n",
            "Epoch 435/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0369 - accuracy: 0.9905 - val_loss: 0.0536 - val_accuracy: 0.9877\n",
            "Epoch 436/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0384 - accuracy: 0.9885 - val_loss: 0.0575 - val_accuracy: 0.9854\n",
            "Epoch 437/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0413 - accuracy: 0.9885 - val_loss: 0.0545 - val_accuracy: 0.9869\n",
            "Epoch 438/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0381 - accuracy: 0.9900 - val_loss: 0.0506 - val_accuracy: 0.9885\n",
            "Epoch 439/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0381 - accuracy: 0.9890 - val_loss: 0.0517 - val_accuracy: 0.9885\n",
            "Epoch 440/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0373 - accuracy: 0.9892 - val_loss: 0.0549 - val_accuracy: 0.9869\n",
            "Epoch 441/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0374 - accuracy: 0.9900 - val_loss: 0.0508 - val_accuracy: 0.9900\n",
            "Epoch 442/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0367 - accuracy: 0.9902 - val_loss: 0.0544 - val_accuracy: 0.9869\n",
            "Epoch 443/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0378 - accuracy: 0.9892 - val_loss: 0.0500 - val_accuracy: 0.9885\n",
            "Epoch 444/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0368 - accuracy: 0.9895 - val_loss: 0.0520 - val_accuracy: 0.9885\n",
            "Epoch 445/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0374 - accuracy: 0.9892 - val_loss: 0.0515 - val_accuracy: 0.9869\n",
            "Epoch 446/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0376 - accuracy: 0.9908 - val_loss: 0.0517 - val_accuracy: 0.9869\n",
            "Epoch 447/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0363 - accuracy: 0.9897 - val_loss: 0.0510 - val_accuracy: 0.9892\n",
            "Epoch 448/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0359 - accuracy: 0.9897 - val_loss: 0.0506 - val_accuracy: 0.9885\n",
            "Epoch 449/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0365 - accuracy: 0.9900 - val_loss: 0.0500 - val_accuracy: 0.9885\n",
            "Epoch 450/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0371 - accuracy: 0.9900 - val_loss: 0.0521 - val_accuracy: 0.9885\n",
            "Epoch 451/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0361 - accuracy: 0.9892 - val_loss: 0.0537 - val_accuracy: 0.9869\n",
            "Epoch 452/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0379 - accuracy: 0.9895 - val_loss: 0.0526 - val_accuracy: 0.9900\n",
            "Epoch 453/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0373 - accuracy: 0.9897 - val_loss: 0.0499 - val_accuracy: 0.9877\n",
            "Epoch 454/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0370 - accuracy: 0.9900 - val_loss: 0.0517 - val_accuracy: 0.9877\n",
            "Epoch 455/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0367 - accuracy: 0.9895 - val_loss: 0.0509 - val_accuracy: 0.9892\n",
            "Epoch 456/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0372 - accuracy: 0.9892 - val_loss: 0.0513 - val_accuracy: 0.9892\n",
            "Epoch 457/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0370 - accuracy: 0.9897 - val_loss: 0.0500 - val_accuracy: 0.9885\n",
            "Epoch 458/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0364 - accuracy: 0.9905 - val_loss: 0.0538 - val_accuracy: 0.9862\n",
            "Epoch 459/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0386 - accuracy: 0.9887 - val_loss: 0.0523 - val_accuracy: 0.9869\n",
            "Epoch 460/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0355 - accuracy: 0.9905 - val_loss: 0.0502 - val_accuracy: 0.9892\n",
            "Epoch 461/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0363 - accuracy: 0.9908 - val_loss: 0.0509 - val_accuracy: 0.9877\n",
            "Epoch 462/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0357 - accuracy: 0.9905 - val_loss: 0.0523 - val_accuracy: 0.9869\n",
            "Epoch 463/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0367 - accuracy: 0.9890 - val_loss: 0.0626 - val_accuracy: 0.9823\n",
            "Epoch 464/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0387 - accuracy: 0.9877 - val_loss: 0.0558 - val_accuracy: 0.9862\n",
            "Epoch 465/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0379 - accuracy: 0.9892 - val_loss: 0.0527 - val_accuracy: 0.9862\n",
            "Epoch 466/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0364 - accuracy: 0.9908 - val_loss: 0.0569 - val_accuracy: 0.9869\n",
            "Epoch 467/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0376 - accuracy: 0.9895 - val_loss: 0.0516 - val_accuracy: 0.9877\n",
            "Epoch 468/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0357 - accuracy: 0.9905 - val_loss: 0.0507 - val_accuracy: 0.9892\n",
            "Epoch 469/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0350 - accuracy: 0.9902 - val_loss: 0.0506 - val_accuracy: 0.9900\n",
            "Epoch 470/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0355 - accuracy: 0.9897 - val_loss: 0.0513 - val_accuracy: 0.9885\n",
            "Epoch 471/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0355 - accuracy: 0.9902 - val_loss: 0.0528 - val_accuracy: 0.9862\n",
            "Epoch 472/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0369 - accuracy: 0.9895 - val_loss: 0.0574 - val_accuracy: 0.9854\n",
            "Epoch 473/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0420 - accuracy: 0.9874 - val_loss: 0.0569 - val_accuracy: 0.9862\n",
            "Epoch 474/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0369 - accuracy: 0.9897 - val_loss: 0.0610 - val_accuracy: 0.9823\n",
            "Epoch 475/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0402 - accuracy: 0.9877 - val_loss: 0.0532 - val_accuracy: 0.9854\n",
            "Epoch 476/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0370 - accuracy: 0.9892 - val_loss: 0.0501 - val_accuracy: 0.9900\n",
            "Epoch 477/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0360 - accuracy: 0.9900 - val_loss: 0.0502 - val_accuracy: 0.9885\n",
            "Epoch 478/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0359 - accuracy: 0.9900 - val_loss: 0.0527 - val_accuracy: 0.9885\n",
            "Epoch 479/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0360 - accuracy: 0.9908 - val_loss: 0.0526 - val_accuracy: 0.9869\n",
            "Epoch 480/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0370 - accuracy: 0.9897 - val_loss: 0.0546 - val_accuracy: 0.9869\n",
            "Epoch 481/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0373 - accuracy: 0.9902 - val_loss: 0.0503 - val_accuracy: 0.9885\n",
            "Epoch 482/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0355 - accuracy: 0.9895 - val_loss: 0.0519 - val_accuracy: 0.9877\n",
            "Epoch 483/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0351 - accuracy: 0.9915 - val_loss: 0.0537 - val_accuracy: 0.9869\n",
            "Epoch 484/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0383 - accuracy: 0.9905 - val_loss: 0.0529 - val_accuracy: 0.9869\n",
            "Epoch 485/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0351 - accuracy: 0.9910 - val_loss: 0.0520 - val_accuracy: 0.9892\n",
            "Epoch 486/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0358 - accuracy: 0.9913 - val_loss: 0.0528 - val_accuracy: 0.9854\n",
            "Epoch 487/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0361 - accuracy: 0.9900 - val_loss: 0.0507 - val_accuracy: 0.9877\n",
            "Epoch 488/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0351 - accuracy: 0.9900 - val_loss: 0.0510 - val_accuracy: 0.9877\n",
            "Epoch 489/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0359 - accuracy: 0.9897 - val_loss: 0.0525 - val_accuracy: 0.9885\n",
            "Epoch 490/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0368 - accuracy: 0.9905 - val_loss: 0.0512 - val_accuracy: 0.9877\n",
            "Epoch 491/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0355 - accuracy: 0.9900 - val_loss: 0.0559 - val_accuracy: 0.9862\n",
            "Epoch 492/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0394 - accuracy: 0.9897 - val_loss: 0.0588 - val_accuracy: 0.9831\n",
            "Epoch 493/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0364 - accuracy: 0.9900 - val_loss: 0.0511 - val_accuracy: 0.9885\n",
            "Epoch 494/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0386 - accuracy: 0.9885 - val_loss: 0.0537 - val_accuracy: 0.9869\n",
            "Epoch 495/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0351 - accuracy: 0.9915 - val_loss: 0.0510 - val_accuracy: 0.9869\n",
            "Epoch 496/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0348 - accuracy: 0.9908 - val_loss: 0.0515 - val_accuracy: 0.9885\n",
            "Epoch 497/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0343 - accuracy: 0.9908 - val_loss: 0.0506 - val_accuracy: 0.9877\n",
            "Epoch 498/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0352 - accuracy: 0.9910 - val_loss: 0.0512 - val_accuracy: 0.9885\n",
            "Epoch 499/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0346 - accuracy: 0.9897 - val_loss: 0.0527 - val_accuracy: 0.9885\n",
            "Epoch 500/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0353 - accuracy: 0.9910 - val_loss: 0.0509 - val_accuracy: 0.9877\n",
            "Epoch 501/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0344 - accuracy: 0.9908 - val_loss: 0.0524 - val_accuracy: 0.9869\n",
            "Epoch 502/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0360 - accuracy: 0.9900 - val_loss: 0.0587 - val_accuracy: 0.9838\n",
            "Epoch 503/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0378 - accuracy: 0.9892 - val_loss: 0.0541 - val_accuracy: 0.9869\n",
            "Epoch 504/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0363 - accuracy: 0.9885 - val_loss: 0.0586 - val_accuracy: 0.9838\n",
            "Epoch 505/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0366 - accuracy: 0.9892 - val_loss: 0.0511 - val_accuracy: 0.9869\n",
            "Epoch 506/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0358 - accuracy: 0.9905 - val_loss: 0.0516 - val_accuracy: 0.9885\n",
            "Epoch 507/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0371 - accuracy: 0.9890 - val_loss: 0.0513 - val_accuracy: 0.9885\n",
            "Epoch 508/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0353 - accuracy: 0.9897 - val_loss: 0.0510 - val_accuracy: 0.9885\n",
            "Epoch 509/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0355 - accuracy: 0.9897 - val_loss: 0.0550 - val_accuracy: 0.9854\n",
            "Epoch 510/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0370 - accuracy: 0.9895 - val_loss: 0.0511 - val_accuracy: 0.9885\n",
            "Epoch 511/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0346 - accuracy: 0.9915 - val_loss: 0.0525 - val_accuracy: 0.9869\n",
            "Epoch 512/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0377 - accuracy: 0.9895 - val_loss: 0.0509 - val_accuracy: 0.9900\n",
            "Epoch 513/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0345 - accuracy: 0.9902 - val_loss: 0.0527 - val_accuracy: 0.9862\n",
            "Epoch 514/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0363 - accuracy: 0.9902 - val_loss: 0.0514 - val_accuracy: 0.9877\n",
            "Epoch 515/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0349 - accuracy: 0.9910 - val_loss: 0.0510 - val_accuracy: 0.9869\n",
            "Epoch 516/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0351 - accuracy: 0.9897 - val_loss: 0.0540 - val_accuracy: 0.9869\n",
            "Epoch 517/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0342 - accuracy: 0.9908 - val_loss: 0.0519 - val_accuracy: 0.9892\n",
            "Epoch 518/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0344 - accuracy: 0.9908 - val_loss: 0.0594 - val_accuracy: 0.9831\n",
            "Epoch 519/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0360 - accuracy: 0.9902 - val_loss: 0.0514 - val_accuracy: 0.9885\n",
            "Epoch 520/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0350 - accuracy: 0.9900 - val_loss: 0.0519 - val_accuracy: 0.9877\n",
            "Epoch 521/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0359 - accuracy: 0.9908 - val_loss: 0.0568 - val_accuracy: 0.9846\n",
            "Epoch 522/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0374 - accuracy: 0.9885 - val_loss: 0.0585 - val_accuracy: 0.9831\n",
            "Epoch 523/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0355 - accuracy: 0.9897 - val_loss: 0.0513 - val_accuracy: 0.9892\n",
            "Epoch 524/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0349 - accuracy: 0.9900 - val_loss: 0.0521 - val_accuracy: 0.9862\n",
            "Epoch 525/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0346 - accuracy: 0.9910 - val_loss: 0.0516 - val_accuracy: 0.9877\n",
            "Epoch 526/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0339 - accuracy: 0.9908 - val_loss: 0.0555 - val_accuracy: 0.9854\n",
            "Epoch 527/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0360 - accuracy: 0.9892 - val_loss: 0.0542 - val_accuracy: 0.9869\n",
            "Epoch 528/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0352 - accuracy: 0.9892 - val_loss: 0.0520 - val_accuracy: 0.9869\n",
            "Epoch 529/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0343 - accuracy: 0.9918 - val_loss: 0.0520 - val_accuracy: 0.9885\n",
            "Epoch 530/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0342 - accuracy: 0.9920 - val_loss: 0.0542 - val_accuracy: 0.9854\n",
            "Epoch 531/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0358 - accuracy: 0.9905 - val_loss: 0.0608 - val_accuracy: 0.9831\n",
            "Epoch 532/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0365 - accuracy: 0.9902 - val_loss: 0.0525 - val_accuracy: 0.9862\n",
            "Epoch 533/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0360 - accuracy: 0.9902 - val_loss: 0.0505 - val_accuracy: 0.9885\n",
            "Epoch 534/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0340 - accuracy: 0.9905 - val_loss: 0.0512 - val_accuracy: 0.9877\n",
            "Epoch 535/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0338 - accuracy: 0.9913 - val_loss: 0.0533 - val_accuracy: 0.9885\n",
            "Epoch 536/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0353 - accuracy: 0.9900 - val_loss: 0.0535 - val_accuracy: 0.9854\n",
            "Epoch 537/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0347 - accuracy: 0.9908 - val_loss: 0.0502 - val_accuracy: 0.9877\n",
            "Epoch 538/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0356 - accuracy: 0.9905 - val_loss: 0.0521 - val_accuracy: 0.9877\n",
            "Epoch 539/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0368 - accuracy: 0.9900 - val_loss: 0.0603 - val_accuracy: 0.9831\n",
            "Epoch 540/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0370 - accuracy: 0.9887 - val_loss: 0.0513 - val_accuracy: 0.9885\n",
            "Epoch 541/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0335 - accuracy: 0.9913 - val_loss: 0.0526 - val_accuracy: 0.9869\n",
            "Epoch 542/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0347 - accuracy: 0.9902 - val_loss: 0.0535 - val_accuracy: 0.9877\n",
            "Epoch 543/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0366 - accuracy: 0.9910 - val_loss: 0.0514 - val_accuracy: 0.9885\n",
            "Epoch 544/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0335 - accuracy: 0.9915 - val_loss: 0.0515 - val_accuracy: 0.9862\n",
            "Epoch 545/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0332 - accuracy: 0.9920 - val_loss: 0.0518 - val_accuracy: 0.9892\n",
            "Epoch 546/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0330 - accuracy: 0.9913 - val_loss: 0.0548 - val_accuracy: 0.9838\n",
            "Epoch 547/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0347 - accuracy: 0.9900 - val_loss: 0.0538 - val_accuracy: 0.9869\n",
            "Epoch 548/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0348 - accuracy: 0.9918 - val_loss: 0.0513 - val_accuracy: 0.9869\n",
            "Epoch 549/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0354 - accuracy: 0.9895 - val_loss: 0.0507 - val_accuracy: 0.9885\n",
            "Epoch 550/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0346 - accuracy: 0.9910 - val_loss: 0.0535 - val_accuracy: 0.9877\n",
            "Epoch 551/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0356 - accuracy: 0.9908 - val_loss: 0.0532 - val_accuracy: 0.9869\n",
            "Epoch 552/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0344 - accuracy: 0.9905 - val_loss: 0.0531 - val_accuracy: 0.9846\n",
            "Epoch 553/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0331 - accuracy: 0.9915 - val_loss: 0.0515 - val_accuracy: 0.9885\n",
            "Epoch 554/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0326 - accuracy: 0.9923 - val_loss: 0.0547 - val_accuracy: 0.9862\n",
            "Epoch 555/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0355 - accuracy: 0.9897 - val_loss: 0.0516 - val_accuracy: 0.9885\n",
            "Epoch 556/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0325 - accuracy: 0.9913 - val_loss: 0.0507 - val_accuracy: 0.9892\n",
            "Epoch 557/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0331 - accuracy: 0.9910 - val_loss: 0.0526 - val_accuracy: 0.9877\n",
            "Epoch 558/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0331 - accuracy: 0.9910 - val_loss: 0.0518 - val_accuracy: 0.9877\n",
            "Epoch 559/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0327 - accuracy: 0.9918 - val_loss: 0.0518 - val_accuracy: 0.9877\n",
            "Epoch 560/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0335 - accuracy: 0.9913 - val_loss: 0.0520 - val_accuracy: 0.9885\n",
            "Epoch 561/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0344 - accuracy: 0.9908 - val_loss: 0.0522 - val_accuracy: 0.9877\n",
            "Epoch 562/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0345 - accuracy: 0.9913 - val_loss: 0.0522 - val_accuracy: 0.9877\n",
            "Epoch 563/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0330 - accuracy: 0.9910 - val_loss: 0.0515 - val_accuracy: 0.9877\n",
            "Epoch 564/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0332 - accuracy: 0.9913 - val_loss: 0.0529 - val_accuracy: 0.9892\n",
            "Epoch 565/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0343 - accuracy: 0.9910 - val_loss: 0.0510 - val_accuracy: 0.9892\n",
            "Epoch 566/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0346 - accuracy: 0.9902 - val_loss: 0.0519 - val_accuracy: 0.9877\n",
            "Epoch 567/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0346 - accuracy: 0.9910 - val_loss: 0.0530 - val_accuracy: 0.9877\n",
            "Epoch 568/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0330 - accuracy: 0.9895 - val_loss: 0.0579 - val_accuracy: 0.9862\n",
            "Epoch 569/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0338 - accuracy: 0.9920 - val_loss: 0.0520 - val_accuracy: 0.9869\n",
            "Epoch 570/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0352 - accuracy: 0.9908 - val_loss: 0.0530 - val_accuracy: 0.9885\n",
            "Epoch 571/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0385 - accuracy: 0.9879 - val_loss: 0.0520 - val_accuracy: 0.9877\n",
            "Epoch 572/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0358 - accuracy: 0.9897 - val_loss: 0.0529 - val_accuracy: 0.9862\n",
            "Epoch 573/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0338 - accuracy: 0.9908 - val_loss: 0.0519 - val_accuracy: 0.9885\n",
            "Epoch 574/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0332 - accuracy: 0.9915 - val_loss: 0.0529 - val_accuracy: 0.9885\n",
            "Epoch 575/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0319 - accuracy: 0.9920 - val_loss: 0.0507 - val_accuracy: 0.9885\n",
            "Epoch 576/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0330 - accuracy: 0.9913 - val_loss: 0.0529 - val_accuracy: 0.9877\n",
            "Epoch 577/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0326 - accuracy: 0.9918 - val_loss: 0.0536 - val_accuracy: 0.9877\n",
            "Epoch 578/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0343 - accuracy: 0.9905 - val_loss: 0.0510 - val_accuracy: 0.9877\n",
            "Epoch 579/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0371 - accuracy: 0.9882 - val_loss: 0.0522 - val_accuracy: 0.9885\n",
            "Epoch 580/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0340 - accuracy: 0.9915 - val_loss: 0.0516 - val_accuracy: 0.9877\n",
            "Epoch 581/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0321 - accuracy: 0.9913 - val_loss: 0.0513 - val_accuracy: 0.9892\n",
            "Epoch 582/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0323 - accuracy: 0.9918 - val_loss: 0.0543 - val_accuracy: 0.9869\n",
            "Epoch 583/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0315 - accuracy: 0.9923 - val_loss: 0.0519 - val_accuracy: 0.9885\n",
            "Epoch 584/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0323 - accuracy: 0.9926 - val_loss: 0.0511 - val_accuracy: 0.9877\n",
            "Epoch 585/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0327 - accuracy: 0.9920 - val_loss: 0.0527 - val_accuracy: 0.9877\n",
            "Epoch 586/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0334 - accuracy: 0.9905 - val_loss: 0.0546 - val_accuracy: 0.9854\n",
            "Epoch 587/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0328 - accuracy: 0.9910 - val_loss: 0.0520 - val_accuracy: 0.9892\n",
            "Epoch 588/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0320 - accuracy: 0.9915 - val_loss: 0.0534 - val_accuracy: 0.9846\n",
            "Epoch 589/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0337 - accuracy: 0.9910 - val_loss: 0.0560 - val_accuracy: 0.9846\n",
            "Epoch 590/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0339 - accuracy: 0.9910 - val_loss: 0.0529 - val_accuracy: 0.9892\n",
            "Epoch 591/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0324 - accuracy: 0.9910 - val_loss: 0.0509 - val_accuracy: 0.9885\n",
            "Epoch 592/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0319 - accuracy: 0.9920 - val_loss: 0.0507 - val_accuracy: 0.9892\n",
            "Epoch 593/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0314 - accuracy: 0.9923 - val_loss: 0.0527 - val_accuracy: 0.9885\n",
            "Epoch 594/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0330 - accuracy: 0.9910 - val_loss: 0.0522 - val_accuracy: 0.9885\n",
            "Epoch 595/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0324 - accuracy: 0.9915 - val_loss: 0.0529 - val_accuracy: 0.9846\n",
            "Epoch 596/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0335 - accuracy: 0.9908 - val_loss: 0.0547 - val_accuracy: 0.9862\n",
            "Epoch 597/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0333 - accuracy: 0.9913 - val_loss: 0.0560 - val_accuracy: 0.9838\n",
            "Epoch 598/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0332 - accuracy: 0.9913 - val_loss: 0.0523 - val_accuracy: 0.9885\n",
            "Epoch 599/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0353 - accuracy: 0.9900 - val_loss: 0.0558 - val_accuracy: 0.9846\n",
            "Epoch 600/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0335 - accuracy: 0.9920 - val_loss: 0.0545 - val_accuracy: 0.9854\n",
            "Epoch 601/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0329 - accuracy: 0.9920 - val_loss: 0.0519 - val_accuracy: 0.9877\n",
            "Epoch 602/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0335 - accuracy: 0.9915 - val_loss: 0.0514 - val_accuracy: 0.9869\n",
            "Epoch 603/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0329 - accuracy: 0.9900 - val_loss: 0.0525 - val_accuracy: 0.9892\n",
            "Epoch 604/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0342 - accuracy: 0.9918 - val_loss: 0.0527 - val_accuracy: 0.9869\n",
            "Epoch 605/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0337 - accuracy: 0.9923 - val_loss: 0.0510 - val_accuracy: 0.9892\n",
            "Epoch 606/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0337 - accuracy: 0.9905 - val_loss: 0.0535 - val_accuracy: 0.9862\n",
            "Epoch 607/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0366 - accuracy: 0.9897 - val_loss: 0.0535 - val_accuracy: 0.9877\n",
            "Epoch 608/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0336 - accuracy: 0.9897 - val_loss: 0.0520 - val_accuracy: 0.9892\n",
            "Epoch 609/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0325 - accuracy: 0.9920 - val_loss: 0.0539 - val_accuracy: 0.9869\n",
            "Epoch 610/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0307 - accuracy: 0.9918 - val_loss: 0.0527 - val_accuracy: 0.9885\n",
            "Epoch 611/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0316 - accuracy: 0.9920 - val_loss: 0.0522 - val_accuracy: 0.9885\n",
            "Epoch 612/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0312 - accuracy: 0.9926 - val_loss: 0.0503 - val_accuracy: 0.9885\n",
            "Epoch 613/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0321 - accuracy: 0.9918 - val_loss: 0.0545 - val_accuracy: 0.9846\n",
            "Epoch 614/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0314 - accuracy: 0.9920 - val_loss: 0.0537 - val_accuracy: 0.9877\n",
            "Epoch 615/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0308 - accuracy: 0.9920 - val_loss: 0.0516 - val_accuracy: 0.9885\n",
            "Epoch 616/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0319 - accuracy: 0.9915 - val_loss: 0.0608 - val_accuracy: 0.9831\n",
            "Epoch 617/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0362 - accuracy: 0.9895 - val_loss: 0.0565 - val_accuracy: 0.9846\n",
            "Epoch 618/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0332 - accuracy: 0.9902 - val_loss: 0.0526 - val_accuracy: 0.9892\n",
            "Epoch 619/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0316 - accuracy: 0.9910 - val_loss: 0.0513 - val_accuracy: 0.9892\n",
            "Epoch 620/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0333 - accuracy: 0.9931 - val_loss: 0.0593 - val_accuracy: 0.9823\n",
            "Epoch 621/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0348 - accuracy: 0.9892 - val_loss: 0.0594 - val_accuracy: 0.9823\n",
            "Epoch 622/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0371 - accuracy: 0.9882 - val_loss: 0.0557 - val_accuracy: 0.9854\n",
            "Epoch 623/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0338 - accuracy: 0.9902 - val_loss: 0.0524 - val_accuracy: 0.9877\n",
            "Epoch 624/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0351 - accuracy: 0.9910 - val_loss: 0.0527 - val_accuracy: 0.9885\n",
            "Epoch 625/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0346 - accuracy: 0.9910 - val_loss: 0.0562 - val_accuracy: 0.9831\n",
            "Epoch 626/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0324 - accuracy: 0.9923 - val_loss: 0.0509 - val_accuracy: 0.9877\n",
            "Epoch 627/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0315 - accuracy: 0.9926 - val_loss: 0.0518 - val_accuracy: 0.9900\n",
            "Epoch 628/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0313 - accuracy: 0.9920 - val_loss: 0.0519 - val_accuracy: 0.9877\n",
            "Epoch 629/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0314 - accuracy: 0.9918 - val_loss: 0.0522 - val_accuracy: 0.9877\n",
            "Epoch 630/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0347 - accuracy: 0.9897 - val_loss: 0.0516 - val_accuracy: 0.9892\n",
            "Epoch 631/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0337 - accuracy: 0.9918 - val_loss: 0.0550 - val_accuracy: 0.9862\n",
            "Epoch 632/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0346 - accuracy: 0.9913 - val_loss: 0.0573 - val_accuracy: 0.9823\n",
            "Epoch 633/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0335 - accuracy: 0.9895 - val_loss: 0.0544 - val_accuracy: 0.9854\n",
            "Epoch 634/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0337 - accuracy: 0.9926 - val_loss: 0.0531 - val_accuracy: 0.9846\n",
            "Epoch 635/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0324 - accuracy: 0.9923 - val_loss: 0.0548 - val_accuracy: 0.9846\n",
            "Epoch 636/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0326 - accuracy: 0.9915 - val_loss: 0.0527 - val_accuracy: 0.9892\n",
            "Epoch 637/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0318 - accuracy: 0.9910 - val_loss: 0.0540 - val_accuracy: 0.9862\n",
            "Epoch 638/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0334 - accuracy: 0.9902 - val_loss: 0.0523 - val_accuracy: 0.9885\n",
            "Epoch 639/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0316 - accuracy: 0.9920 - val_loss: 0.0535 - val_accuracy: 0.9869\n",
            "Epoch 640/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0323 - accuracy: 0.9920 - val_loss: 0.0534 - val_accuracy: 0.9862\n",
            "Epoch 641/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0318 - accuracy: 0.9910 - val_loss: 0.0545 - val_accuracy: 0.9862\n",
            "Epoch 642/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0327 - accuracy: 0.9908 - val_loss: 0.0523 - val_accuracy: 0.9869\n",
            "Epoch 643/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0312 - accuracy: 0.9923 - val_loss: 0.0519 - val_accuracy: 0.9877\n",
            "Epoch 644/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0325 - accuracy: 0.9913 - val_loss: 0.0517 - val_accuracy: 0.9885\n",
            "Epoch 645/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0305 - accuracy: 0.9926 - val_loss: 0.0531 - val_accuracy: 0.9862\n",
            "Epoch 646/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0305 - accuracy: 0.9923 - val_loss: 0.0512 - val_accuracy: 0.9885\n",
            "Epoch 647/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0303 - accuracy: 0.9926 - val_loss: 0.0516 - val_accuracy: 0.9892\n",
            "Epoch 648/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0309 - accuracy: 0.9920 - val_loss: 0.0534 - val_accuracy: 0.9862\n",
            "Epoch 649/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0310 - accuracy: 0.9915 - val_loss: 0.0528 - val_accuracy: 0.9885\n",
            "Epoch 650/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0303 - accuracy: 0.9926 - val_loss: 0.0521 - val_accuracy: 0.9892\n",
            "Epoch 651/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0305 - accuracy: 0.9928 - val_loss: 0.0516 - val_accuracy: 0.9892\n",
            "Epoch 652/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0304 - accuracy: 0.9926 - val_loss: 0.0522 - val_accuracy: 0.9877\n",
            "Epoch 653/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0303 - accuracy: 0.9933 - val_loss: 0.0528 - val_accuracy: 0.9877\n",
            "Epoch 654/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0309 - accuracy: 0.9915 - val_loss: 0.0517 - val_accuracy: 0.9877\n",
            "Epoch 655/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0329 - accuracy: 0.9910 - val_loss: 0.0525 - val_accuracy: 0.9869\n",
            "Epoch 656/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0324 - accuracy: 0.9910 - val_loss: 0.0513 - val_accuracy: 0.9885\n",
            "Epoch 657/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0348 - accuracy: 0.9895 - val_loss: 0.0588 - val_accuracy: 0.9831\n",
            "Epoch 658/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0384 - accuracy: 0.9874 - val_loss: 0.0673 - val_accuracy: 0.9800\n",
            "Epoch 659/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0330 - accuracy: 0.9908 - val_loss: 0.0532 - val_accuracy: 0.9854\n",
            "Epoch 660/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0314 - accuracy: 0.9923 - val_loss: 0.0519 - val_accuracy: 0.9892\n",
            "Epoch 661/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0313 - accuracy: 0.9913 - val_loss: 0.0527 - val_accuracy: 0.9862\n",
            "Epoch 662/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0300 - accuracy: 0.9931 - val_loss: 0.0529 - val_accuracy: 0.9862\n",
            "Epoch 663/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0308 - accuracy: 0.9915 - val_loss: 0.0530 - val_accuracy: 0.9862\n",
            "Epoch 664/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0307 - accuracy: 0.9908 - val_loss: 0.0538 - val_accuracy: 0.9892\n",
            "Epoch 665/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0306 - accuracy: 0.9926 - val_loss: 0.0532 - val_accuracy: 0.9869\n",
            "Epoch 666/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0304 - accuracy: 0.9926 - val_loss: 0.0506 - val_accuracy: 0.9885\n",
            "Epoch 667/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0309 - accuracy: 0.9923 - val_loss: 0.0519 - val_accuracy: 0.9885\n",
            "Epoch 668/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0299 - accuracy: 0.9933 - val_loss: 0.0531 - val_accuracy: 0.9869\n",
            "Epoch 669/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0328 - accuracy: 0.9910 - val_loss: 0.0544 - val_accuracy: 0.9877\n",
            "Epoch 670/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0307 - accuracy: 0.9915 - val_loss: 0.0532 - val_accuracy: 0.9885\n",
            "Epoch 671/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0328 - accuracy: 0.9920 - val_loss: 0.0528 - val_accuracy: 0.9869\n",
            "Epoch 672/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0309 - accuracy: 0.9915 - val_loss: 0.0535 - val_accuracy: 0.9885\n",
            "Epoch 673/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0320 - accuracy: 0.9910 - val_loss: 0.0520 - val_accuracy: 0.9885\n",
            "Epoch 674/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0301 - accuracy: 0.9926 - val_loss: 0.0527 - val_accuracy: 0.9869\n",
            "Epoch 675/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0296 - accuracy: 0.9923 - val_loss: 0.0521 - val_accuracy: 0.9885\n",
            "Epoch 676/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0297 - accuracy: 0.9928 - val_loss: 0.0516 - val_accuracy: 0.9892\n",
            "Epoch 677/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0316 - accuracy: 0.9918 - val_loss: 0.0565 - val_accuracy: 0.9862\n",
            "Epoch 678/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0314 - accuracy: 0.9915 - val_loss: 0.0531 - val_accuracy: 0.9869\n",
            "Epoch 679/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0305 - accuracy: 0.9913 - val_loss: 0.0524 - val_accuracy: 0.9885\n",
            "Epoch 680/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0306 - accuracy: 0.9918 - val_loss: 0.0544 - val_accuracy: 0.9854\n",
            "Epoch 681/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0304 - accuracy: 0.9918 - val_loss: 0.0540 - val_accuracy: 0.9862\n",
            "Epoch 682/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0359 - accuracy: 0.9900 - val_loss: 0.0578 - val_accuracy: 0.9846\n",
            "Epoch 683/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0342 - accuracy: 0.9902 - val_loss: 0.0595 - val_accuracy: 0.9831\n",
            "Epoch 684/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0327 - accuracy: 0.9918 - val_loss: 0.0521 - val_accuracy: 0.9877\n",
            "Epoch 685/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0302 - accuracy: 0.9926 - val_loss: 0.0514 - val_accuracy: 0.9892\n",
            "Epoch 686/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0297 - accuracy: 0.9915 - val_loss: 0.0524 - val_accuracy: 0.9877\n",
            "Epoch 687/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0310 - accuracy: 0.9920 - val_loss: 0.0580 - val_accuracy: 0.9823\n",
            "Epoch 688/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0320 - accuracy: 0.9915 - val_loss: 0.0571 - val_accuracy: 0.9846\n",
            "Epoch 689/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0347 - accuracy: 0.9900 - val_loss: 0.0522 - val_accuracy: 0.9877\n",
            "Epoch 690/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0333 - accuracy: 0.9913 - val_loss: 0.0592 - val_accuracy: 0.9815\n",
            "Epoch 691/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0317 - accuracy: 0.9931 - val_loss: 0.0529 - val_accuracy: 0.9846\n",
            "Epoch 692/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0303 - accuracy: 0.9923 - val_loss: 0.0510 - val_accuracy: 0.9892\n",
            "Epoch 693/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0301 - accuracy: 0.9918 - val_loss: 0.0548 - val_accuracy: 0.9854\n",
            "Epoch 694/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0297 - accuracy: 0.9933 - val_loss: 0.0531 - val_accuracy: 0.9862\n",
            "Epoch 695/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0308 - accuracy: 0.9920 - val_loss: 0.0519 - val_accuracy: 0.9877\n",
            "Epoch 696/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0308 - accuracy: 0.9926 - val_loss: 0.0523 - val_accuracy: 0.9900\n",
            "Epoch 697/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0302 - accuracy: 0.9933 - val_loss: 0.0527 - val_accuracy: 0.9885\n",
            "Epoch 698/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0301 - accuracy: 0.9923 - val_loss: 0.0549 - val_accuracy: 0.9854\n",
            "Epoch 699/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0318 - accuracy: 0.9915 - val_loss: 0.0539 - val_accuracy: 0.9862\n",
            "Epoch 700/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0306 - accuracy: 0.9923 - val_loss: 0.0511 - val_accuracy: 0.9885\n",
            "Epoch 701/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0305 - accuracy: 0.9918 - val_loss: 0.0534 - val_accuracy: 0.9869\n",
            "Epoch 702/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0341 - accuracy: 0.9905 - val_loss: 0.0524 - val_accuracy: 0.9854\n",
            "Epoch 703/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0318 - accuracy: 0.9920 - val_loss: 0.0560 - val_accuracy: 0.9846\n",
            "Epoch 704/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0318 - accuracy: 0.9908 - val_loss: 0.0560 - val_accuracy: 0.9831\n",
            "Epoch 705/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0310 - accuracy: 0.9908 - val_loss: 0.0540 - val_accuracy: 0.9838\n",
            "Epoch 706/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0317 - accuracy: 0.9913 - val_loss: 0.0539 - val_accuracy: 0.9869\n",
            "Epoch 707/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0313 - accuracy: 0.9918 - val_loss: 0.0516 - val_accuracy: 0.9885\n",
            "Epoch 708/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0293 - accuracy: 0.9936 - val_loss: 0.0516 - val_accuracy: 0.9885\n",
            "Epoch 709/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0294 - accuracy: 0.9926 - val_loss: 0.0512 - val_accuracy: 0.9877\n",
            "Epoch 710/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0295 - accuracy: 0.9931 - val_loss: 0.0551 - val_accuracy: 0.9869\n",
            "Epoch 711/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0319 - accuracy: 0.9910 - val_loss: 0.0559 - val_accuracy: 0.9862\n",
            "Epoch 712/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0308 - accuracy: 0.9926 - val_loss: 0.0516 - val_accuracy: 0.9877\n",
            "Epoch 713/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0308 - accuracy: 0.9931 - val_loss: 0.0548 - val_accuracy: 0.9862\n",
            "Epoch 714/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0317 - accuracy: 0.9910 - val_loss: 0.0536 - val_accuracy: 0.9869\n",
            "Epoch 715/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0308 - accuracy: 0.9926 - val_loss: 0.0544 - val_accuracy: 0.9877\n",
            "Epoch 716/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0306 - accuracy: 0.9918 - val_loss: 0.0539 - val_accuracy: 0.9862\n",
            "Epoch 717/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0305 - accuracy: 0.9918 - val_loss: 0.0514 - val_accuracy: 0.9885\n",
            "Epoch 718/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0292 - accuracy: 0.9926 - val_loss: 0.0518 - val_accuracy: 0.9892\n",
            "Epoch 719/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0295 - accuracy: 0.9923 - val_loss: 0.0525 - val_accuracy: 0.9877\n",
            "Epoch 720/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0297 - accuracy: 0.9926 - val_loss: 0.0523 - val_accuracy: 0.9885\n",
            "Epoch 721/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0304 - accuracy: 0.9920 - val_loss: 0.0567 - val_accuracy: 0.9862\n",
            "Epoch 722/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0312 - accuracy: 0.9918 - val_loss: 0.0515 - val_accuracy: 0.9877\n",
            "Epoch 723/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0295 - accuracy: 0.9931 - val_loss: 0.0518 - val_accuracy: 0.9885\n",
            "Epoch 724/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0298 - accuracy: 0.9926 - val_loss: 0.0533 - val_accuracy: 0.9862\n",
            "Epoch 725/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0302 - accuracy: 0.9926 - val_loss: 0.0532 - val_accuracy: 0.9869\n",
            "Epoch 726/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0295 - accuracy: 0.9931 - val_loss: 0.0525 - val_accuracy: 0.9877\n",
            "Epoch 727/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0288 - accuracy: 0.9941 - val_loss: 0.0524 - val_accuracy: 0.9885\n",
            "Epoch 728/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0294 - accuracy: 0.9926 - val_loss: 0.0523 - val_accuracy: 0.9862\n",
            "Epoch 729/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0311 - accuracy: 0.9915 - val_loss: 0.0534 - val_accuracy: 0.9877\n",
            "Epoch 730/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0296 - accuracy: 0.9926 - val_loss: 0.0516 - val_accuracy: 0.9877\n",
            "Epoch 731/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0295 - accuracy: 0.9931 - val_loss: 0.0577 - val_accuracy: 0.9846\n",
            "Epoch 732/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0309 - accuracy: 0.9915 - val_loss: 0.0551 - val_accuracy: 0.9869\n",
            "Epoch 733/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0300 - accuracy: 0.9918 - val_loss: 0.0511 - val_accuracy: 0.9877\n",
            "Epoch 734/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0345 - accuracy: 0.9908 - val_loss: 0.0532 - val_accuracy: 0.9862\n",
            "Epoch 735/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0299 - accuracy: 0.9910 - val_loss: 0.0526 - val_accuracy: 0.9877\n",
            "Epoch 736/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0299 - accuracy: 0.9920 - val_loss: 0.0509 - val_accuracy: 0.9892\n",
            "Epoch 737/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0293 - accuracy: 0.9933 - val_loss: 0.0515 - val_accuracy: 0.9885\n",
            "Epoch 738/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0288 - accuracy: 0.9931 - val_loss: 0.0514 - val_accuracy: 0.9885\n",
            "Epoch 739/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0292 - accuracy: 0.9923 - val_loss: 0.0548 - val_accuracy: 0.9854\n",
            "Epoch 740/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0319 - accuracy: 0.9913 - val_loss: 0.0549 - val_accuracy: 0.9838\n",
            "Epoch 741/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0297 - accuracy: 0.9928 - val_loss: 0.0534 - val_accuracy: 0.9892\n",
            "Epoch 742/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0290 - accuracy: 0.9928 - val_loss: 0.0507 - val_accuracy: 0.9892\n",
            "Epoch 743/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0285 - accuracy: 0.9933 - val_loss: 0.0513 - val_accuracy: 0.9892\n",
            "Epoch 744/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0284 - accuracy: 0.9938 - val_loss: 0.0641 - val_accuracy: 0.9800\n",
            "Epoch 745/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0321 - accuracy: 0.9910 - val_loss: 0.0576 - val_accuracy: 0.9854\n",
            "Epoch 746/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0323 - accuracy: 0.9918 - val_loss: 0.0508 - val_accuracy: 0.9885\n",
            "Epoch 747/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0293 - accuracy: 0.9923 - val_loss: 0.0520 - val_accuracy: 0.9892\n",
            "Epoch 748/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0290 - accuracy: 0.9931 - val_loss: 0.0516 - val_accuracy: 0.9892\n",
            "Epoch 749/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0294 - accuracy: 0.9920 - val_loss: 0.0522 - val_accuracy: 0.9869\n",
            "Epoch 750/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0291 - accuracy: 0.9931 - val_loss: 0.0519 - val_accuracy: 0.9892\n",
            "Epoch 751/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0288 - accuracy: 0.9931 - val_loss: 0.0544 - val_accuracy: 0.9838\n",
            "Epoch 752/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0295 - accuracy: 0.9920 - val_loss: 0.0528 - val_accuracy: 0.9877\n",
            "Epoch 753/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0298 - accuracy: 0.9928 - val_loss: 0.0517 - val_accuracy: 0.9885\n",
            "Epoch 754/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0303 - accuracy: 0.9918 - val_loss: 0.0524 - val_accuracy: 0.9885\n",
            "Epoch 755/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0314 - accuracy: 0.9915 - val_loss: 0.0522 - val_accuracy: 0.9869\n",
            "Epoch 756/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0305 - accuracy: 0.9926 - val_loss: 0.0507 - val_accuracy: 0.9885\n",
            "Epoch 757/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0322 - accuracy: 0.9900 - val_loss: 0.0525 - val_accuracy: 0.9877\n",
            "Epoch 758/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0351 - accuracy: 0.9910 - val_loss: 0.0529 - val_accuracy: 0.9885\n",
            "Epoch 759/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0336 - accuracy: 0.9895 - val_loss: 0.0511 - val_accuracy: 0.9892\n",
            "Epoch 760/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0301 - accuracy: 0.9923 - val_loss: 0.0520 - val_accuracy: 0.9885\n",
            "Epoch 761/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0287 - accuracy: 0.9944 - val_loss: 0.0552 - val_accuracy: 0.9854\n",
            "Epoch 762/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0316 - accuracy: 0.9915 - val_loss: 0.0516 - val_accuracy: 0.9869\n",
            "Epoch 763/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0287 - accuracy: 0.9933 - val_loss: 0.0520 - val_accuracy: 0.9885\n",
            "Epoch 764/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0289 - accuracy: 0.9933 - val_loss: 0.0526 - val_accuracy: 0.9877\n",
            "Epoch 765/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0283 - accuracy: 0.9938 - val_loss: 0.0555 - val_accuracy: 0.9854\n",
            "Epoch 766/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0299 - accuracy: 0.9913 - val_loss: 0.0532 - val_accuracy: 0.9862\n",
            "Epoch 767/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0313 - accuracy: 0.9923 - val_loss: 0.0562 - val_accuracy: 0.9838\n",
            "Epoch 768/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0310 - accuracy: 0.9915 - val_loss: 0.0553 - val_accuracy: 0.9846\n",
            "Epoch 769/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0300 - accuracy: 0.9918 - val_loss: 0.0531 - val_accuracy: 0.9854\n",
            "Epoch 770/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0290 - accuracy: 0.9926 - val_loss: 0.0532 - val_accuracy: 0.9862\n",
            "Epoch 771/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0287 - accuracy: 0.9933 - val_loss: 0.0540 - val_accuracy: 0.9862\n",
            "Epoch 772/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0316 - accuracy: 0.9910 - val_loss: 0.0589 - val_accuracy: 0.9846\n",
            "Epoch 773/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0307 - accuracy: 0.9920 - val_loss: 0.0562 - val_accuracy: 0.9854\n",
            "Epoch 774/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0301 - accuracy: 0.9920 - val_loss: 0.0527 - val_accuracy: 0.9885\n",
            "Epoch 775/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0306 - accuracy: 0.9910 - val_loss: 0.0504 - val_accuracy: 0.9869\n",
            "Epoch 776/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0371 - accuracy: 0.9892 - val_loss: 0.0529 - val_accuracy: 0.9854\n",
            "Epoch 777/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0306 - accuracy: 0.9918 - val_loss: 0.0526 - val_accuracy: 0.9877\n",
            "Epoch 778/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0289 - accuracy: 0.9928 - val_loss: 0.0515 - val_accuracy: 0.9877\n",
            "Epoch 779/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0291 - accuracy: 0.9931 - val_loss: 0.0524 - val_accuracy: 0.9869\n",
            "Epoch 780/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0300 - accuracy: 0.9926 - val_loss: 0.0514 - val_accuracy: 0.9892\n",
            "Epoch 781/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0290 - accuracy: 0.9931 - val_loss: 0.0556 - val_accuracy: 0.9877\n",
            "Epoch 782/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0353 - accuracy: 0.9890 - val_loss: 0.0521 - val_accuracy: 0.9877\n",
            "Epoch 783/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0366 - accuracy: 0.9900 - val_loss: 0.0516 - val_accuracy: 0.9892\n",
            "Epoch 784/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0310 - accuracy: 0.9913 - val_loss: 0.0536 - val_accuracy: 0.9862\n",
            "Epoch 785/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0292 - accuracy: 0.9918 - val_loss: 0.0506 - val_accuracy: 0.9892\n",
            "Epoch 786/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0291 - accuracy: 0.9928 - val_loss: 0.0515 - val_accuracy: 0.9885\n",
            "Epoch 787/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0327 - accuracy: 0.9910 - val_loss: 0.0512 - val_accuracy: 0.9877\n",
            "Epoch 788/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0322 - accuracy: 0.9905 - val_loss: 0.0517 - val_accuracy: 0.9869\n",
            "Epoch 789/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0289 - accuracy: 0.9918 - val_loss: 0.0510 - val_accuracy: 0.9892\n",
            "Epoch 790/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0282 - accuracy: 0.9936 - val_loss: 0.0519 - val_accuracy: 0.9885\n",
            "Epoch 791/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0281 - accuracy: 0.9938 - val_loss: 0.0513 - val_accuracy: 0.9885\n",
            "Epoch 792/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0284 - accuracy: 0.9915 - val_loss: 0.0516 - val_accuracy: 0.9885\n",
            "Epoch 793/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0290 - accuracy: 0.9931 - val_loss: 0.0516 - val_accuracy: 0.9885\n",
            "Epoch 794/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0289 - accuracy: 0.9931 - val_loss: 0.0509 - val_accuracy: 0.9885\n",
            "Epoch 795/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0292 - accuracy: 0.9918 - val_loss: 0.0529 - val_accuracy: 0.9877\n",
            "Epoch 796/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0296 - accuracy: 0.9923 - val_loss: 0.0525 - val_accuracy: 0.9862\n",
            "Epoch 797/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0288 - accuracy: 0.9931 - val_loss: 0.0516 - val_accuracy: 0.9892\n",
            "Epoch 798/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0274 - accuracy: 0.9938 - val_loss: 0.0514 - val_accuracy: 0.9877\n",
            "Epoch 799/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0278 - accuracy: 0.9936 - val_loss: 0.0508 - val_accuracy: 0.9892\n",
            "Epoch 800/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0278 - accuracy: 0.9926 - val_loss: 0.0514 - val_accuracy: 0.9885\n",
            "Epoch 801/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0280 - accuracy: 0.9933 - val_loss: 0.0515 - val_accuracy: 0.9869\n",
            "Epoch 802/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0294 - accuracy: 0.9915 - val_loss: 0.0539 - val_accuracy: 0.9854\n",
            "Epoch 803/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0292 - accuracy: 0.9923 - val_loss: 0.0557 - val_accuracy: 0.9838\n",
            "Epoch 804/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0290 - accuracy: 0.9926 - val_loss: 0.0522 - val_accuracy: 0.9892\n",
            "Epoch 805/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0276 - accuracy: 0.9938 - val_loss: 0.0532 - val_accuracy: 0.9869\n",
            "Epoch 806/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0283 - accuracy: 0.9931 - val_loss: 0.0515 - val_accuracy: 0.9885\n",
            "Epoch 807/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0282 - accuracy: 0.9928 - val_loss: 0.0526 - val_accuracy: 0.9869\n",
            "Epoch 808/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0284 - accuracy: 0.9926 - val_loss: 0.0519 - val_accuracy: 0.9885\n",
            "Epoch 809/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0298 - accuracy: 0.9920 - val_loss: 0.0511 - val_accuracy: 0.9892\n",
            "Epoch 810/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0280 - accuracy: 0.9933 - val_loss: 0.0555 - val_accuracy: 0.9831\n",
            "Epoch 811/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0306 - accuracy: 0.9928 - val_loss: 0.0565 - val_accuracy: 0.9846\n",
            "Epoch 812/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0316 - accuracy: 0.9923 - val_loss: 0.0511 - val_accuracy: 0.9877\n",
            "Epoch 813/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0284 - accuracy: 0.9926 - val_loss: 0.0511 - val_accuracy: 0.9885\n",
            "Epoch 814/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0280 - accuracy: 0.9928 - val_loss: 0.0510 - val_accuracy: 0.9877\n",
            "Epoch 815/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0282 - accuracy: 0.9931 - val_loss: 0.0590 - val_accuracy: 0.9838\n",
            "Epoch 816/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0337 - accuracy: 0.9915 - val_loss: 0.0582 - val_accuracy: 0.9854\n",
            "Epoch 817/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0284 - accuracy: 0.9931 - val_loss: 0.0508 - val_accuracy: 0.9892\n",
            "Epoch 818/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0298 - accuracy: 0.9931 - val_loss: 0.0554 - val_accuracy: 0.9854\n",
            "Epoch 819/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0308 - accuracy: 0.9913 - val_loss: 0.0506 - val_accuracy: 0.9892\n",
            "Epoch 820/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0290 - accuracy: 0.9926 - val_loss: 0.0513 - val_accuracy: 0.9885\n",
            "Epoch 821/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0297 - accuracy: 0.9926 - val_loss: 0.0565 - val_accuracy: 0.9838\n",
            "Epoch 822/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0290 - accuracy: 0.9920 - val_loss: 0.0562 - val_accuracy: 0.9846\n",
            "Epoch 823/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0325 - accuracy: 0.9902 - val_loss: 0.0560 - val_accuracy: 0.9846\n",
            "Epoch 824/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0296 - accuracy: 0.9920 - val_loss: 0.0505 - val_accuracy: 0.9885\n",
            "Epoch 825/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0325 - accuracy: 0.9905 - val_loss: 0.0519 - val_accuracy: 0.9877\n",
            "Epoch 826/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0312 - accuracy: 0.9923 - val_loss: 0.0522 - val_accuracy: 0.9862\n",
            "Epoch 827/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0337 - accuracy: 0.9913 - val_loss: 0.0524 - val_accuracy: 0.9877\n",
            "Epoch 828/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0309 - accuracy: 0.9918 - val_loss: 0.0508 - val_accuracy: 0.9877\n",
            "Epoch 829/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0287 - accuracy: 0.9936 - val_loss: 0.0498 - val_accuracy: 0.9900\n",
            "Epoch 830/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0284 - accuracy: 0.9928 - val_loss: 0.0506 - val_accuracy: 0.9892\n",
            "Epoch 831/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0280 - accuracy: 0.9936 - val_loss: 0.0518 - val_accuracy: 0.9885\n",
            "Epoch 832/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0278 - accuracy: 0.9933 - val_loss: 0.0540 - val_accuracy: 0.9846\n",
            "Epoch 833/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0292 - accuracy: 0.9920 - val_loss: 0.0507 - val_accuracy: 0.9892\n",
            "Epoch 834/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0276 - accuracy: 0.9931 - val_loss: 0.0509 - val_accuracy: 0.9885\n",
            "Epoch 835/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0282 - accuracy: 0.9933 - val_loss: 0.0508 - val_accuracy: 0.9892\n",
            "Epoch 836/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0290 - accuracy: 0.9928 - val_loss: 0.0512 - val_accuracy: 0.9885\n",
            "Epoch 837/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0279 - accuracy: 0.9931 - val_loss: 0.0532 - val_accuracy: 0.9877\n",
            "Epoch 838/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0279 - accuracy: 0.9931 - val_loss: 0.0536 - val_accuracy: 0.9862\n",
            "Epoch 839/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0280 - accuracy: 0.9928 - val_loss: 0.0555 - val_accuracy: 0.9846\n",
            "Epoch 840/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0311 - accuracy: 0.9913 - val_loss: 0.0535 - val_accuracy: 0.9877\n",
            "Epoch 841/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0320 - accuracy: 0.9902 - val_loss: 0.0540 - val_accuracy: 0.9831\n",
            "Epoch 842/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0314 - accuracy: 0.9910 - val_loss: 0.0531 - val_accuracy: 0.9854\n",
            "Epoch 843/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0329 - accuracy: 0.9905 - val_loss: 0.0516 - val_accuracy: 0.9877\n",
            "Epoch 844/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0295 - accuracy: 0.9915 - val_loss: 0.0528 - val_accuracy: 0.9869\n",
            "Epoch 845/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0290 - accuracy: 0.9938 - val_loss: 0.0567 - val_accuracy: 0.9854\n",
            "Epoch 846/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0291 - accuracy: 0.9931 - val_loss: 0.0532 - val_accuracy: 0.9869\n",
            "Epoch 847/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0279 - accuracy: 0.9926 - val_loss: 0.0522 - val_accuracy: 0.9885\n",
            "Epoch 848/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0284 - accuracy: 0.9923 - val_loss: 0.0519 - val_accuracy: 0.9877\n",
            "Epoch 849/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0269 - accuracy: 0.9941 - val_loss: 0.0528 - val_accuracy: 0.9877\n",
            "Epoch 850/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0285 - accuracy: 0.9918 - val_loss: 0.0537 - val_accuracy: 0.9885\n",
            "Epoch 851/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0267 - accuracy: 0.9920 - val_loss: 0.0608 - val_accuracy: 0.9831\n",
            "Epoch 852/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0354 - accuracy: 0.9908 - val_loss: 0.0699 - val_accuracy: 0.9792\n",
            "Epoch 853/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0335 - accuracy: 0.9890 - val_loss: 0.0529 - val_accuracy: 0.9877\n",
            "Epoch 854/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0288 - accuracy: 0.9928 - val_loss: 0.0625 - val_accuracy: 0.9823\n",
            "Epoch 855/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0326 - accuracy: 0.9900 - val_loss: 0.0611 - val_accuracy: 0.9831\n",
            "Epoch 856/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0296 - accuracy: 0.9920 - val_loss: 0.0495 - val_accuracy: 0.9885\n",
            "Epoch 857/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0279 - accuracy: 0.9928 - val_loss: 0.0518 - val_accuracy: 0.9885\n",
            "Epoch 858/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0291 - accuracy: 0.9926 - val_loss: 0.0566 - val_accuracy: 0.9869\n",
            "Epoch 859/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0294 - accuracy: 0.9923 - val_loss: 0.0517 - val_accuracy: 0.9892\n",
            "Epoch 860/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0306 - accuracy: 0.9928 - val_loss: 0.0505 - val_accuracy: 0.9892\n",
            "Epoch 861/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0288 - accuracy: 0.9928 - val_loss: 0.0518 - val_accuracy: 0.9869\n",
            "Epoch 862/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0281 - accuracy: 0.9936 - val_loss: 0.0504 - val_accuracy: 0.9885\n",
            "Epoch 863/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0276 - accuracy: 0.9936 - val_loss: 0.0502 - val_accuracy: 0.9900\n",
            "Epoch 864/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0275 - accuracy: 0.9931 - val_loss: 0.0522 - val_accuracy: 0.9885\n",
            "Epoch 865/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0278 - accuracy: 0.9931 - val_loss: 0.0517 - val_accuracy: 0.9877\n",
            "Epoch 866/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0274 - accuracy: 0.9928 - val_loss: 0.0505 - val_accuracy: 0.9892\n",
            "Epoch 867/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0280 - accuracy: 0.9931 - val_loss: 0.0512 - val_accuracy: 0.9892\n",
            "Epoch 868/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0293 - accuracy: 0.9918 - val_loss: 0.0512 - val_accuracy: 0.9885\n",
            "Epoch 869/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0279 - accuracy: 0.9941 - val_loss: 0.0510 - val_accuracy: 0.9885\n",
            "Epoch 870/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0285 - accuracy: 0.9926 - val_loss: 0.0533 - val_accuracy: 0.9877\n",
            "Epoch 871/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0280 - accuracy: 0.9933 - val_loss: 0.0507 - val_accuracy: 0.9877\n",
            "Epoch 872/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0270 - accuracy: 0.9944 - val_loss: 0.0526 - val_accuracy: 0.9885\n",
            "Epoch 873/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0269 - accuracy: 0.9931 - val_loss: 0.0513 - val_accuracy: 0.9885\n",
            "Epoch 874/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0271 - accuracy: 0.9938 - val_loss: 0.0506 - val_accuracy: 0.9892\n",
            "Epoch 875/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0276 - accuracy: 0.9931 - val_loss: 0.0528 - val_accuracy: 0.9869\n",
            "Epoch 876/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0267 - accuracy: 0.9933 - val_loss: 0.0548 - val_accuracy: 0.9854\n",
            "Epoch 877/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0270 - accuracy: 0.9926 - val_loss: 0.0526 - val_accuracy: 0.9877\n",
            "Epoch 878/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0280 - accuracy: 0.9918 - val_loss: 0.0537 - val_accuracy: 0.9862\n",
            "Epoch 879/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0283 - accuracy: 0.9928 - val_loss: 0.0535 - val_accuracy: 0.9862\n",
            "Epoch 880/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0290 - accuracy: 0.9926 - val_loss: 0.0541 - val_accuracy: 0.9854\n",
            "Epoch 881/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0286 - accuracy: 0.9923 - val_loss: 0.0524 - val_accuracy: 0.9885\n",
            "Epoch 882/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0282 - accuracy: 0.9931 - val_loss: 0.0519 - val_accuracy: 0.9892\n",
            "Epoch 883/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0293 - accuracy: 0.9931 - val_loss: 0.0558 - val_accuracy: 0.9869\n",
            "Epoch 884/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0293 - accuracy: 0.9910 - val_loss: 0.0521 - val_accuracy: 0.9862\n",
            "Epoch 885/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0294 - accuracy: 0.9918 - val_loss: 0.0587 - val_accuracy: 0.9838\n",
            "Epoch 886/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0302 - accuracy: 0.9920 - val_loss: 0.0528 - val_accuracy: 0.9862\n",
            "Epoch 887/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0286 - accuracy: 0.9928 - val_loss: 0.0553 - val_accuracy: 0.9869\n",
            "Epoch 888/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0285 - accuracy: 0.9913 - val_loss: 0.0516 - val_accuracy: 0.9885\n",
            "Epoch 889/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0261 - accuracy: 0.9933 - val_loss: 0.0516 - val_accuracy: 0.9869\n",
            "Epoch 890/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0271 - accuracy: 0.9936 - val_loss: 0.0510 - val_accuracy: 0.9869\n",
            "Epoch 891/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0271 - accuracy: 0.9923 - val_loss: 0.0520 - val_accuracy: 0.9877\n",
            "Epoch 892/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0271 - accuracy: 0.9936 - val_loss: 0.0501 - val_accuracy: 0.9885\n",
            "Epoch 893/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0272 - accuracy: 0.9928 - val_loss: 0.0505 - val_accuracy: 0.9885\n",
            "Epoch 894/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0274 - accuracy: 0.9928 - val_loss: 0.0508 - val_accuracy: 0.9892\n",
            "Epoch 895/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0264 - accuracy: 0.9933 - val_loss: 0.0515 - val_accuracy: 0.9885\n",
            "Epoch 896/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0266 - accuracy: 0.9931 - val_loss: 0.0511 - val_accuracy: 0.9892\n",
            "Epoch 897/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0274 - accuracy: 0.9928 - val_loss: 0.0508 - val_accuracy: 0.9892\n",
            "Epoch 898/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0269 - accuracy: 0.9938 - val_loss: 0.0565 - val_accuracy: 0.9831\n",
            "Epoch 899/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0311 - accuracy: 0.9905 - val_loss: 0.0572 - val_accuracy: 0.9831\n",
            "Epoch 900/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0300 - accuracy: 0.9928 - val_loss: 0.0528 - val_accuracy: 0.9877\n",
            "Epoch 901/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0282 - accuracy: 0.9915 - val_loss: 0.0512 - val_accuracy: 0.9869\n",
            "Epoch 902/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0301 - accuracy: 0.9910 - val_loss: 0.0520 - val_accuracy: 0.9900\n",
            "Epoch 903/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0298 - accuracy: 0.9913 - val_loss: 0.0513 - val_accuracy: 0.9877\n",
            "Epoch 904/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0277 - accuracy: 0.9933 - val_loss: 0.0533 - val_accuracy: 0.9862\n",
            "Epoch 905/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0289 - accuracy: 0.9918 - val_loss: 0.0579 - val_accuracy: 0.9815\n",
            "Epoch 906/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0301 - accuracy: 0.9926 - val_loss: 0.0549 - val_accuracy: 0.9854\n",
            "Epoch 907/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0284 - accuracy: 0.9926 - val_loss: 0.0500 - val_accuracy: 0.9892\n",
            "Epoch 908/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0273 - accuracy: 0.9931 - val_loss: 0.0529 - val_accuracy: 0.9877\n",
            "Epoch 909/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0272 - accuracy: 0.9926 - val_loss: 0.0514 - val_accuracy: 0.9892\n",
            "Epoch 910/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0284 - accuracy: 0.9923 - val_loss: 0.0509 - val_accuracy: 0.9885\n",
            "Epoch 911/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0277 - accuracy: 0.9936 - val_loss: 0.0514 - val_accuracy: 0.9885\n",
            "Epoch 912/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0266 - accuracy: 0.9941 - val_loss: 0.0513 - val_accuracy: 0.9900\n",
            "Epoch 913/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0262 - accuracy: 0.9938 - val_loss: 0.0590 - val_accuracy: 0.9854\n",
            "Epoch 914/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0309 - accuracy: 0.9897 - val_loss: 0.0563 - val_accuracy: 0.9854\n",
            "Epoch 915/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0292 - accuracy: 0.9926 - val_loss: 0.0547 - val_accuracy: 0.9869\n",
            "Epoch 916/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0333 - accuracy: 0.9910 - val_loss: 0.0623 - val_accuracy: 0.9846\n",
            "Epoch 917/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0340 - accuracy: 0.9902 - val_loss: 0.0511 - val_accuracy: 0.9892\n",
            "Epoch 918/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0319 - accuracy: 0.9915 - val_loss: 0.0520 - val_accuracy: 0.9885\n",
            "Epoch 919/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0281 - accuracy: 0.9915 - val_loss: 0.0536 - val_accuracy: 0.9854\n",
            "Epoch 920/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0272 - accuracy: 0.9923 - val_loss: 0.0550 - val_accuracy: 0.9877\n",
            "Epoch 921/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0277 - accuracy: 0.9933 - val_loss: 0.0506 - val_accuracy: 0.9877\n",
            "Epoch 922/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0270 - accuracy: 0.9931 - val_loss: 0.0517 - val_accuracy: 0.9885\n",
            "Epoch 923/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0276 - accuracy: 0.9923 - val_loss: 0.0545 - val_accuracy: 0.9862\n",
            "Epoch 924/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0272 - accuracy: 0.9926 - val_loss: 0.0519 - val_accuracy: 0.9869\n",
            "Epoch 925/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0263 - accuracy: 0.9933 - val_loss: 0.0518 - val_accuracy: 0.9885\n",
            "Epoch 926/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0268 - accuracy: 0.9936 - val_loss: 0.0513 - val_accuracy: 0.9892\n",
            "Epoch 927/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0263 - accuracy: 0.9928 - val_loss: 0.0514 - val_accuracy: 0.9892\n",
            "Epoch 928/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0264 - accuracy: 0.9931 - val_loss: 0.0512 - val_accuracy: 0.9885\n",
            "Epoch 929/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0265 - accuracy: 0.9931 - val_loss: 0.0513 - val_accuracy: 0.9892\n",
            "Epoch 930/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0265 - accuracy: 0.9933 - val_loss: 0.0530 - val_accuracy: 0.9877\n",
            "Epoch 931/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0278 - accuracy: 0.9933 - val_loss: 0.0514 - val_accuracy: 0.9877\n",
            "Epoch 932/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0287 - accuracy: 0.9933 - val_loss: 0.0524 - val_accuracy: 0.9869\n",
            "Epoch 933/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0290 - accuracy: 0.9926 - val_loss: 0.0505 - val_accuracy: 0.9885\n",
            "Epoch 934/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0292 - accuracy: 0.9920 - val_loss: 0.0521 - val_accuracy: 0.9885\n",
            "Epoch 935/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0286 - accuracy: 0.9926 - val_loss: 0.0578 - val_accuracy: 0.9823\n",
            "Epoch 936/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0290 - accuracy: 0.9918 - val_loss: 0.0578 - val_accuracy: 0.9846\n",
            "Epoch 937/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0317 - accuracy: 0.9905 - val_loss: 0.0542 - val_accuracy: 0.9846\n",
            "Epoch 938/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0274 - accuracy: 0.9936 - val_loss: 0.0519 - val_accuracy: 0.9892\n",
            "Epoch 939/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0270 - accuracy: 0.9931 - val_loss: 0.0529 - val_accuracy: 0.9869\n",
            "Epoch 940/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0270 - accuracy: 0.9936 - val_loss: 0.0544 - val_accuracy: 0.9869\n",
            "Epoch 941/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0313 - accuracy: 0.9910 - val_loss: 0.0523 - val_accuracy: 0.9892\n",
            "Epoch 942/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0299 - accuracy: 0.9920 - val_loss: 0.0549 - val_accuracy: 0.9854\n",
            "Epoch 943/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0276 - accuracy: 0.9923 - val_loss: 0.0546 - val_accuracy: 0.9854\n",
            "Epoch 944/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0296 - accuracy: 0.9915 - val_loss: 0.0517 - val_accuracy: 0.9885\n",
            "Epoch 945/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0265 - accuracy: 0.9933 - val_loss: 0.0522 - val_accuracy: 0.9885\n",
            "Epoch 946/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0281 - accuracy: 0.9928 - val_loss: 0.0514 - val_accuracy: 0.9892\n",
            "Epoch 947/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0280 - accuracy: 0.9926 - val_loss: 0.0518 - val_accuracy: 0.9877\n",
            "Epoch 948/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0274 - accuracy: 0.9933 - val_loss: 0.0542 - val_accuracy: 0.9862\n",
            "Epoch 949/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0263 - accuracy: 0.9931 - val_loss: 0.0511 - val_accuracy: 0.9892\n",
            "Epoch 950/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0262 - accuracy: 0.9931 - val_loss: 0.0511 - val_accuracy: 0.9885\n",
            "Epoch 951/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9938 - val_loss: 0.0512 - val_accuracy: 0.9892\n",
            "Epoch 952/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0286 - accuracy: 0.9918 - val_loss: 0.0513 - val_accuracy: 0.9892\n",
            "Epoch 953/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0297 - accuracy: 0.9923 - val_loss: 0.0539 - val_accuracy: 0.9862\n",
            "Epoch 954/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0264 - accuracy: 0.9941 - val_loss: 0.0508 - val_accuracy: 0.9877\n",
            "Epoch 955/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9933 - val_loss: 0.0509 - val_accuracy: 0.9877\n",
            "Epoch 956/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0265 - accuracy: 0.9923 - val_loss: 0.0522 - val_accuracy: 0.9885\n",
            "Epoch 957/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0256 - accuracy: 0.9938 - val_loss: 0.0539 - val_accuracy: 0.9869\n",
            "Epoch 958/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0285 - accuracy: 0.9920 - val_loss: 0.0519 - val_accuracy: 0.9877\n",
            "Epoch 959/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0262 - accuracy: 0.9936 - val_loss: 0.0517 - val_accuracy: 0.9877\n",
            "Epoch 960/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9944 - val_loss: 0.0508 - val_accuracy: 0.9892\n",
            "Epoch 961/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0263 - accuracy: 0.9931 - val_loss: 0.0510 - val_accuracy: 0.9892\n",
            "Epoch 962/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0265 - accuracy: 0.9931 - val_loss: 0.0512 - val_accuracy: 0.9885\n",
            "Epoch 963/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9931 - val_loss: 0.0522 - val_accuracy: 0.9892\n",
            "Epoch 964/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0266 - accuracy: 0.9933 - val_loss: 0.0511 - val_accuracy: 0.9885\n",
            "Epoch 965/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9928 - val_loss: 0.0525 - val_accuracy: 0.9877\n",
            "Epoch 966/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9936 - val_loss: 0.0532 - val_accuracy: 0.9877\n",
            "Epoch 967/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0296 - accuracy: 0.9920 - val_loss: 0.0632 - val_accuracy: 0.9823\n",
            "Epoch 968/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0305 - accuracy: 0.9915 - val_loss: 0.0578 - val_accuracy: 0.9862\n",
            "Epoch 969/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0287 - accuracy: 0.9928 - val_loss: 0.0516 - val_accuracy: 0.9862\n",
            "Epoch 970/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0269 - accuracy: 0.9931 - val_loss: 0.0530 - val_accuracy: 0.9854\n",
            "Epoch 971/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0287 - accuracy: 0.9931 - val_loss: 0.0527 - val_accuracy: 0.9862\n",
            "Epoch 972/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0284 - accuracy: 0.9923 - val_loss: 0.0629 - val_accuracy: 0.9815\n",
            "Epoch 973/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0281 - accuracy: 0.9928 - val_loss: 0.0526 - val_accuracy: 0.9892\n",
            "Epoch 974/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0272 - accuracy: 0.9928 - val_loss: 0.0521 - val_accuracy: 0.9885\n",
            "Epoch 975/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0274 - accuracy: 0.9936 - val_loss: 0.0515 - val_accuracy: 0.9869\n",
            "Epoch 976/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0271 - accuracy: 0.9928 - val_loss: 0.0508 - val_accuracy: 0.9892\n",
            "Epoch 977/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0276 - accuracy: 0.9926 - val_loss: 0.0512 - val_accuracy: 0.9877\n",
            "Epoch 978/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0262 - accuracy: 0.9931 - val_loss: 0.0533 - val_accuracy: 0.9877\n",
            "Epoch 979/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0280 - accuracy: 0.9926 - val_loss: 0.0515 - val_accuracy: 0.9885\n",
            "Epoch 980/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0273 - accuracy: 0.9931 - val_loss: 0.0524 - val_accuracy: 0.9869\n",
            "Epoch 981/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0263 - accuracy: 0.9936 - val_loss: 0.0551 - val_accuracy: 0.9846\n",
            "Epoch 982/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0277 - accuracy: 0.9920 - val_loss: 0.0514 - val_accuracy: 0.9885\n",
            "Epoch 983/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0268 - accuracy: 0.9933 - val_loss: 0.0503 - val_accuracy: 0.9900\n",
            "Epoch 984/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0256 - accuracy: 0.9938 - val_loss: 0.0510 - val_accuracy: 0.9892\n",
            "Epoch 985/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0264 - accuracy: 0.9936 - val_loss: 0.0524 - val_accuracy: 0.9877\n",
            "Epoch 986/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0275 - accuracy: 0.9923 - val_loss: 0.0521 - val_accuracy: 0.9877\n",
            "Epoch 987/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0275 - accuracy: 0.9928 - val_loss: 0.0529 - val_accuracy: 0.9869\n",
            "Epoch 988/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0277 - accuracy: 0.9931 - val_loss: 0.0534 - val_accuracy: 0.9854\n",
            "Epoch 989/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0297 - accuracy: 0.9918 - val_loss: 0.0567 - val_accuracy: 0.9862\n",
            "Epoch 990/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0304 - accuracy: 0.9918 - val_loss: 0.0642 - val_accuracy: 0.9785\n",
            "Epoch 991/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0325 - accuracy: 0.9895 - val_loss: 0.0620 - val_accuracy: 0.9831\n",
            "Epoch 992/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0350 - accuracy: 0.9890 - val_loss: 0.0544 - val_accuracy: 0.9862\n",
            "Epoch 993/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0282 - accuracy: 0.9923 - val_loss: 0.0522 - val_accuracy: 0.9869\n",
            "Epoch 994/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0304 - accuracy: 0.9908 - val_loss: 0.0524 - val_accuracy: 0.9869\n",
            "Epoch 995/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9933 - val_loss: 0.0529 - val_accuracy: 0.9869\n",
            "Epoch 996/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0261 - accuracy: 0.9938 - val_loss: 0.0515 - val_accuracy: 0.9885\n",
            "Epoch 997/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9938 - val_loss: 0.0513 - val_accuracy: 0.9885\n",
            "Epoch 998/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0265 - accuracy: 0.9938 - val_loss: 0.0527 - val_accuracy: 0.9877\n",
            "Epoch 999/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0264 - accuracy: 0.9928 - val_loss: 0.0518 - val_accuracy: 0.9885\n",
            "Epoch 1000/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0272 - accuracy: 0.9923 - val_loss: 0.0615 - val_accuracy: 0.9815\n",
            "Epoch 1001/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0295 - accuracy: 0.9920 - val_loss: 0.0548 - val_accuracy: 0.9831\n",
            "Epoch 1002/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0297 - accuracy: 0.9920 - val_loss: 0.0562 - val_accuracy: 0.9838\n",
            "Epoch 1003/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0285 - accuracy: 0.9926 - val_loss: 0.0525 - val_accuracy: 0.9869\n",
            "Epoch 1004/2000\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0253 - accuracy: 0.9944 - val_loss: 0.0541 - val_accuracy: 0.9869\n",
            "Epoch 1005/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0265 - accuracy: 0.9933 - val_loss: 0.0507 - val_accuracy: 0.9869\n",
            "Epoch 1006/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0276 - accuracy: 0.9933 - val_loss: 0.0522 - val_accuracy: 0.9885\n",
            "Epoch 1007/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0256 - accuracy: 0.9941 - val_loss: 0.0509 - val_accuracy: 0.9869\n",
            "Epoch 1008/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0252 - accuracy: 0.9928 - val_loss: 0.0507 - val_accuracy: 0.9877\n",
            "Epoch 1009/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0254 - accuracy: 0.9944 - val_loss: 0.0507 - val_accuracy: 0.9877\n",
            "Epoch 1010/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0259 - accuracy: 0.9933 - val_loss: 0.0507 - val_accuracy: 0.9885\n",
            "Epoch 1011/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0275 - accuracy: 0.9923 - val_loss: 0.0574 - val_accuracy: 0.9838\n",
            "Epoch 1012/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0291 - accuracy: 0.9918 - val_loss: 0.0547 - val_accuracy: 0.9869\n",
            "Epoch 1013/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0279 - accuracy: 0.9923 - val_loss: 0.0508 - val_accuracy: 0.9869\n",
            "Epoch 1014/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0315 - accuracy: 0.9905 - val_loss: 0.0516 - val_accuracy: 0.9877\n",
            "Epoch 1015/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0267 - accuracy: 0.9926 - val_loss: 0.0530 - val_accuracy: 0.9854\n",
            "Epoch 1016/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0284 - accuracy: 0.9918 - val_loss: 0.0551 - val_accuracy: 0.9854\n",
            "Epoch 1017/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0322 - accuracy: 0.9918 - val_loss: 0.0574 - val_accuracy: 0.9815\n",
            "Epoch 1018/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0305 - accuracy: 0.9923 - val_loss: 0.0538 - val_accuracy: 0.9877\n",
            "Epoch 1019/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0266 - accuracy: 0.9931 - val_loss: 0.0507 - val_accuracy: 0.9877\n",
            "Epoch 1020/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0271 - accuracy: 0.9938 - val_loss: 0.0513 - val_accuracy: 0.9877\n",
            "Epoch 1021/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0261 - accuracy: 0.9931 - val_loss: 0.0528 - val_accuracy: 0.9869\n",
            "Epoch 1022/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0279 - accuracy: 0.9926 - val_loss: 0.0569 - val_accuracy: 0.9846\n",
            "Epoch 1023/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0278 - accuracy: 0.9933 - val_loss: 0.0537 - val_accuracy: 0.9862\n",
            "Epoch 1024/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0286 - accuracy: 0.9918 - val_loss: 0.0503 - val_accuracy: 0.9885\n",
            "Epoch 1025/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0300 - accuracy: 0.9926 - val_loss: 0.0515 - val_accuracy: 0.9877\n",
            "Epoch 1026/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0299 - accuracy: 0.9908 - val_loss: 0.0511 - val_accuracy: 0.9885\n",
            "Epoch 1027/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9936 - val_loss: 0.0589 - val_accuracy: 0.9831\n",
            "Epoch 1028/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9931 - val_loss: 0.0576 - val_accuracy: 0.9862\n",
            "Epoch 1029/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0268 - accuracy: 0.9918 - val_loss: 0.0527 - val_accuracy: 0.9869\n",
            "Epoch 1030/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0264 - accuracy: 0.9933 - val_loss: 0.0513 - val_accuracy: 0.9869\n",
            "Epoch 1031/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9933 - val_loss: 0.0508 - val_accuracy: 0.9885\n",
            "Epoch 1032/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0260 - accuracy: 0.9933 - val_loss: 0.0511 - val_accuracy: 0.9885\n",
            "Epoch 1033/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0267 - accuracy: 0.9928 - val_loss: 0.0550 - val_accuracy: 0.9862\n",
            "Epoch 1034/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0262 - accuracy: 0.9946 - val_loss: 0.0511 - val_accuracy: 0.9877\n",
            "Epoch 1035/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0269 - accuracy: 0.9926 - val_loss: 0.0553 - val_accuracy: 0.9854\n",
            "Epoch 1036/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0301 - accuracy: 0.9931 - val_loss: 0.0536 - val_accuracy: 0.9869\n",
            "Epoch 1037/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0275 - accuracy: 0.9913 - val_loss: 0.0518 - val_accuracy: 0.9892\n",
            "Epoch 1038/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9933 - val_loss: 0.0529 - val_accuracy: 0.9877\n",
            "Epoch 1039/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0322 - accuracy: 0.9905 - val_loss: 0.0508 - val_accuracy: 0.9885\n",
            "Epoch 1040/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0282 - accuracy: 0.9923 - val_loss: 0.0552 - val_accuracy: 0.9846\n",
            "Epoch 1041/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0272 - accuracy: 0.9933 - val_loss: 0.0604 - val_accuracy: 0.9823\n",
            "Epoch 1042/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0292 - accuracy: 0.9913 - val_loss: 0.0510 - val_accuracy: 0.9869\n",
            "Epoch 1043/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9938 - val_loss: 0.0511 - val_accuracy: 0.9877\n",
            "Epoch 1044/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0254 - accuracy: 0.9936 - val_loss: 0.0519 - val_accuracy: 0.9877\n",
            "Epoch 1045/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9938 - val_loss: 0.0518 - val_accuracy: 0.9869\n",
            "Epoch 1046/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0248 - accuracy: 0.9941 - val_loss: 0.0510 - val_accuracy: 0.9885\n",
            "Epoch 1047/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0247 - accuracy: 0.9931 - val_loss: 0.0556 - val_accuracy: 0.9823\n",
            "Epoch 1048/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0262 - accuracy: 0.9933 - val_loss: 0.0508 - val_accuracy: 0.9877\n",
            "Epoch 1049/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9941 - val_loss: 0.0510 - val_accuracy: 0.9885\n",
            "Epoch 1050/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0244 - accuracy: 0.9936 - val_loss: 0.0514 - val_accuracy: 0.9869\n",
            "Epoch 1051/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0252 - accuracy: 0.9938 - val_loss: 0.0514 - val_accuracy: 0.9885\n",
            "Epoch 1052/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0254 - accuracy: 0.9931 - val_loss: 0.0523 - val_accuracy: 0.9869\n",
            "Epoch 1053/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0273 - accuracy: 0.9941 - val_loss: 0.0635 - val_accuracy: 0.9815\n",
            "Epoch 1054/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0283 - accuracy: 0.9915 - val_loss: 0.0538 - val_accuracy: 0.9862\n",
            "Epoch 1055/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0293 - accuracy: 0.9913 - val_loss: 0.0503 - val_accuracy: 0.9892\n",
            "Epoch 1056/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0285 - accuracy: 0.9923 - val_loss: 0.0572 - val_accuracy: 0.9846\n",
            "Epoch 1057/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0260 - accuracy: 0.9933 - val_loss: 0.0520 - val_accuracy: 0.9877\n",
            "Epoch 1058/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0251 - accuracy: 0.9928 - val_loss: 0.0516 - val_accuracy: 0.9885\n",
            "Epoch 1059/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0247 - accuracy: 0.9941 - val_loss: 0.0503 - val_accuracy: 0.9885\n",
            "Epoch 1060/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0267 - accuracy: 0.9926 - val_loss: 0.0550 - val_accuracy: 0.9862\n",
            "Epoch 1061/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0246 - accuracy: 0.9938 - val_loss: 0.0513 - val_accuracy: 0.9877\n",
            "Epoch 1062/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9936 - val_loss: 0.0508 - val_accuracy: 0.9885\n",
            "Epoch 1063/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0252 - accuracy: 0.9933 - val_loss: 0.0514 - val_accuracy: 0.9892\n",
            "Epoch 1064/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0250 - accuracy: 0.9936 - val_loss: 0.0509 - val_accuracy: 0.9885\n",
            "Epoch 1065/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9933 - val_loss: 0.0516 - val_accuracy: 0.9869\n",
            "Epoch 1066/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0249 - accuracy: 0.9931 - val_loss: 0.0507 - val_accuracy: 0.9885\n",
            "Epoch 1067/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0246 - accuracy: 0.9941 - val_loss: 0.0502 - val_accuracy: 0.9885\n",
            "Epoch 1068/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0242 - accuracy: 0.9941 - val_loss: 0.0519 - val_accuracy: 0.9885\n",
            "Epoch 1069/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0249 - accuracy: 0.9938 - val_loss: 0.0511 - val_accuracy: 0.9885\n",
            "Epoch 1070/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0251 - accuracy: 0.9933 - val_loss: 0.0537 - val_accuracy: 0.9862\n",
            "Epoch 1071/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0265 - accuracy: 0.9931 - val_loss: 0.0515 - val_accuracy: 0.9877\n",
            "Epoch 1072/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0246 - accuracy: 0.9941 - val_loss: 0.0538 - val_accuracy: 0.9862\n",
            "Epoch 1073/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0272 - accuracy: 0.9928 - val_loss: 0.0532 - val_accuracy: 0.9854\n",
            "Epoch 1074/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0258 - accuracy: 0.9938 - val_loss: 0.0545 - val_accuracy: 0.9854\n",
            "Epoch 1075/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0252 - accuracy: 0.9938 - val_loss: 0.0559 - val_accuracy: 0.9846\n",
            "Epoch 1076/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0289 - accuracy: 0.9915 - val_loss: 0.0587 - val_accuracy: 0.9831\n",
            "Epoch 1077/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0298 - accuracy: 0.9902 - val_loss: 0.0501 - val_accuracy: 0.9877\n",
            "Epoch 1078/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0281 - accuracy: 0.9931 - val_loss: 0.0522 - val_accuracy: 0.9877\n",
            "Epoch 1079/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0264 - accuracy: 0.9928 - val_loss: 0.0515 - val_accuracy: 0.9869\n",
            "Epoch 1080/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0246 - accuracy: 0.9931 - val_loss: 0.0533 - val_accuracy: 0.9846\n",
            "Epoch 1081/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9941 - val_loss: 0.0503 - val_accuracy: 0.9877\n",
            "Epoch 1082/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0246 - accuracy: 0.9944 - val_loss: 0.0512 - val_accuracy: 0.9877\n",
            "Epoch 1083/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0253 - accuracy: 0.9931 - val_loss: 0.0505 - val_accuracy: 0.9885\n",
            "Epoch 1084/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0244 - accuracy: 0.9931 - val_loss: 0.0517 - val_accuracy: 0.9862\n",
            "Epoch 1085/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0263 - accuracy: 0.9933 - val_loss: 0.0526 - val_accuracy: 0.9877\n",
            "Epoch 1086/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0248 - accuracy: 0.9944 - val_loss: 0.0514 - val_accuracy: 0.9885\n",
            "Epoch 1087/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0246 - accuracy: 0.9946 - val_loss: 0.0510 - val_accuracy: 0.9862\n",
            "Epoch 1088/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0274 - accuracy: 0.9918 - val_loss: 0.0509 - val_accuracy: 0.9885\n",
            "Epoch 1089/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0245 - accuracy: 0.9938 - val_loss: 0.0562 - val_accuracy: 0.9846\n",
            "Epoch 1090/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0272 - accuracy: 0.9931 - val_loss: 0.0519 - val_accuracy: 0.9877\n",
            "Epoch 1091/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0249 - accuracy: 0.9941 - val_loss: 0.0578 - val_accuracy: 0.9838\n",
            "Epoch 1092/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0318 - accuracy: 0.9895 - val_loss: 0.0645 - val_accuracy: 0.9815\n",
            "Epoch 1093/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0303 - accuracy: 0.9918 - val_loss: 0.0573 - val_accuracy: 0.9846\n",
            "Epoch 1094/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0318 - accuracy: 0.9902 - val_loss: 0.0556 - val_accuracy: 0.9846\n",
            "Epoch 1095/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0296 - accuracy: 0.9913 - val_loss: 0.0505 - val_accuracy: 0.9862\n",
            "Epoch 1096/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0263 - accuracy: 0.9928 - val_loss: 0.0517 - val_accuracy: 0.9877\n",
            "Epoch 1097/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0281 - accuracy: 0.9926 - val_loss: 0.0509 - val_accuracy: 0.9885\n",
            "Epoch 1098/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0295 - accuracy: 0.9918 - val_loss: 0.0542 - val_accuracy: 0.9854\n",
            "Epoch 1099/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0280 - accuracy: 0.9920 - val_loss: 0.0567 - val_accuracy: 0.9838\n",
            "Epoch 1100/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0291 - accuracy: 0.9933 - val_loss: 0.0556 - val_accuracy: 0.9823\n",
            "Epoch 1101/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0276 - accuracy: 0.9920 - val_loss: 0.0540 - val_accuracy: 0.9862\n",
            "Epoch 1102/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0265 - accuracy: 0.9928 - val_loss: 0.0590 - val_accuracy: 0.9831\n",
            "Epoch 1103/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0282 - accuracy: 0.9938 - val_loss: 0.0513 - val_accuracy: 0.9885\n",
            "Epoch 1104/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0250 - accuracy: 0.9933 - val_loss: 0.0528 - val_accuracy: 0.9869\n",
            "Epoch 1105/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0252 - accuracy: 0.9938 - val_loss: 0.0508 - val_accuracy: 0.9885\n",
            "Epoch 1106/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0261 - accuracy: 0.9941 - val_loss: 0.0504 - val_accuracy: 0.9877\n",
            "Epoch 1107/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0249 - accuracy: 0.9949 - val_loss: 0.0506 - val_accuracy: 0.9885\n",
            "Epoch 1108/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0250 - accuracy: 0.9936 - val_loss: 0.0537 - val_accuracy: 0.9877\n",
            "Epoch 1109/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0259 - accuracy: 0.9928 - val_loss: 0.0501 - val_accuracy: 0.9892\n",
            "Epoch 1110/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0263 - accuracy: 0.9931 - val_loss: 0.0534 - val_accuracy: 0.9869\n",
            "Epoch 1111/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0261 - accuracy: 0.9928 - val_loss: 0.0513 - val_accuracy: 0.9877\n",
            "Epoch 1112/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0267 - accuracy: 0.9936 - val_loss: 0.0508 - val_accuracy: 0.9892\n",
            "Epoch 1113/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0243 - accuracy: 0.9936 - val_loss: 0.0522 - val_accuracy: 0.9877\n",
            "Epoch 1114/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0245 - accuracy: 0.9938 - val_loss: 0.0495 - val_accuracy: 0.9877\n",
            "Epoch 1115/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0253 - accuracy: 0.9928 - val_loss: 0.0515 - val_accuracy: 0.9885\n",
            "Epoch 1116/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0256 - accuracy: 0.9938 - val_loss: 0.0501 - val_accuracy: 0.9885\n",
            "Epoch 1117/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0243 - accuracy: 0.9928 - val_loss: 0.0513 - val_accuracy: 0.9885\n",
            "Epoch 1118/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0256 - accuracy: 0.9926 - val_loss: 0.0501 - val_accuracy: 0.9877\n",
            "Epoch 1119/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0274 - accuracy: 0.9928 - val_loss: 0.0511 - val_accuracy: 0.9885\n",
            "Epoch 1120/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0246 - accuracy: 0.9946 - val_loss: 0.0501 - val_accuracy: 0.9877\n",
            "Epoch 1121/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0243 - accuracy: 0.9946 - val_loss: 0.0511 - val_accuracy: 0.9877\n",
            "Epoch 1122/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0254 - accuracy: 0.9931 - val_loss: 0.0507 - val_accuracy: 0.9877\n",
            "Epoch 1123/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0249 - accuracy: 0.9938 - val_loss: 0.0500 - val_accuracy: 0.9869\n",
            "Epoch 1124/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0246 - accuracy: 0.9933 - val_loss: 0.0529 - val_accuracy: 0.9877\n",
            "Epoch 1125/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0262 - accuracy: 0.9931 - val_loss: 0.0516 - val_accuracy: 0.9869\n",
            "Epoch 1126/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9949 - val_loss: 0.0508 - val_accuracy: 0.9885\n",
            "Epoch 1127/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9933 - val_loss: 0.0520 - val_accuracy: 0.9869\n",
            "Epoch 1128/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0252 - accuracy: 0.9938 - val_loss: 0.0548 - val_accuracy: 0.9846\n",
            "Epoch 1129/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0258 - accuracy: 0.9938 - val_loss: 0.0522 - val_accuracy: 0.9885\n",
            "Epoch 1130/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0306 - accuracy: 0.9885 - val_loss: 0.0520 - val_accuracy: 0.9877\n",
            "Epoch 1131/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0391 - accuracy: 0.9874 - val_loss: 0.0541 - val_accuracy: 0.9869\n",
            "Epoch 1132/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0339 - accuracy: 0.9902 - val_loss: 0.0619 - val_accuracy: 0.9831\n",
            "Epoch 1133/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0295 - accuracy: 0.9915 - val_loss: 0.0576 - val_accuracy: 0.9838\n",
            "Epoch 1134/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0267 - accuracy: 0.9933 - val_loss: 0.0510 - val_accuracy: 0.9869\n",
            "Epoch 1135/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0252 - accuracy: 0.9936 - val_loss: 0.0507 - val_accuracy: 0.9885\n",
            "Epoch 1136/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0242 - accuracy: 0.9938 - val_loss: 0.0533 - val_accuracy: 0.9862\n",
            "Epoch 1137/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0252 - accuracy: 0.9933 - val_loss: 0.0488 - val_accuracy: 0.9877\n",
            "Epoch 1138/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0243 - accuracy: 0.9944 - val_loss: 0.0529 - val_accuracy: 0.9869\n",
            "Epoch 1139/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0273 - accuracy: 0.9920 - val_loss: 0.0542 - val_accuracy: 0.9846\n",
            "Epoch 1140/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0247 - accuracy: 0.9944 - val_loss: 0.0504 - val_accuracy: 0.9885\n",
            "Epoch 1141/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0243 - accuracy: 0.9933 - val_loss: 0.0506 - val_accuracy: 0.9877\n",
            "Epoch 1142/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0241 - accuracy: 0.9938 - val_loss: 0.0495 - val_accuracy: 0.9877\n",
            "Epoch 1143/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0270 - accuracy: 0.9923 - val_loss: 0.0627 - val_accuracy: 0.9808\n",
            "Epoch 1144/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0281 - accuracy: 0.9913 - val_loss: 0.0550 - val_accuracy: 0.9846\n",
            "Epoch 1145/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0252 - accuracy: 0.9923 - val_loss: 0.0501 - val_accuracy: 0.9877\n",
            "Epoch 1146/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0241 - accuracy: 0.9944 - val_loss: 0.0504 - val_accuracy: 0.9885\n",
            "Epoch 1147/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0247 - accuracy: 0.9931 - val_loss: 0.0506 - val_accuracy: 0.9869\n",
            "Epoch 1148/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0242 - accuracy: 0.9936 - val_loss: 0.0518 - val_accuracy: 0.9869\n",
            "Epoch 1149/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0247 - accuracy: 0.9938 - val_loss: 0.0516 - val_accuracy: 0.9877\n",
            "Epoch 1150/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0264 - accuracy: 0.9931 - val_loss: 0.0554 - val_accuracy: 0.9846\n",
            "Epoch 1151/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0285 - accuracy: 0.9913 - val_loss: 0.0502 - val_accuracy: 0.9885\n",
            "Epoch 1152/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0245 - accuracy: 0.9941 - val_loss: 0.0505 - val_accuracy: 0.9869\n",
            "Epoch 1153/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0242 - accuracy: 0.9938 - val_loss: 0.0501 - val_accuracy: 0.9862\n",
            "Epoch 1154/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0252 - accuracy: 0.9933 - val_loss: 0.0506 - val_accuracy: 0.9869\n",
            "Epoch 1155/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0253 - accuracy: 0.9931 - val_loss: 0.0499 - val_accuracy: 0.9885\n",
            "Epoch 1156/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0242 - accuracy: 0.9941 - val_loss: 0.0520 - val_accuracy: 0.9869\n",
            "Epoch 1157/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0244 - accuracy: 0.9941 - val_loss: 0.0507 - val_accuracy: 0.9869\n",
            "Epoch 1158/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0247 - accuracy: 0.9941 - val_loss: 0.0501 - val_accuracy: 0.9877\n",
            "Epoch 1159/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0241 - accuracy: 0.9946 - val_loss: 0.0513 - val_accuracy: 0.9885\n",
            "Epoch 1160/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0261 - accuracy: 0.9923 - val_loss: 0.0584 - val_accuracy: 0.9831\n",
            "Epoch 1161/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0326 - accuracy: 0.9895 - val_loss: 0.0522 - val_accuracy: 0.9877\n",
            "Epoch 1162/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9933 - val_loss: 0.0521 - val_accuracy: 0.9877\n",
            "Epoch 1163/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0247 - accuracy: 0.9941 - val_loss: 0.0506 - val_accuracy: 0.9877\n",
            "Epoch 1164/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0240 - accuracy: 0.9938 - val_loss: 0.0495 - val_accuracy: 0.9877\n",
            "Epoch 1165/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0245 - accuracy: 0.9941 - val_loss: 0.0595 - val_accuracy: 0.9823\n",
            "Epoch 1166/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0261 - accuracy: 0.9933 - val_loss: 0.0508 - val_accuracy: 0.9869\n",
            "Epoch 1167/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0250 - accuracy: 0.9936 - val_loss: 0.0494 - val_accuracy: 0.9877\n",
            "Epoch 1168/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0269 - accuracy: 0.9928 - val_loss: 0.0518 - val_accuracy: 0.9885\n",
            "Epoch 1169/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9923 - val_loss: 0.0630 - val_accuracy: 0.9823\n",
            "Epoch 1170/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0268 - accuracy: 0.9928 - val_loss: 0.0505 - val_accuracy: 0.9877\n",
            "Epoch 1171/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0248 - accuracy: 0.9936 - val_loss: 0.0536 - val_accuracy: 0.9885\n",
            "Epoch 1172/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0233 - accuracy: 0.9938 - val_loss: 0.0511 - val_accuracy: 0.9877\n",
            "Epoch 1173/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0238 - accuracy: 0.9938 - val_loss: 0.0494 - val_accuracy: 0.9869\n",
            "Epoch 1174/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0239 - accuracy: 0.9936 - val_loss: 0.0498 - val_accuracy: 0.9885\n",
            "Epoch 1175/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0269 - accuracy: 0.9915 - val_loss: 0.0507 - val_accuracy: 0.9869\n",
            "Epoch 1176/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0294 - accuracy: 0.9920 - val_loss: 0.0562 - val_accuracy: 0.9838\n",
            "Epoch 1177/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0274 - accuracy: 0.9926 - val_loss: 0.0553 - val_accuracy: 0.9862\n",
            "Epoch 1178/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0261 - accuracy: 0.9933 - val_loss: 0.0514 - val_accuracy: 0.9869\n",
            "Epoch 1179/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0258 - accuracy: 0.9941 - val_loss: 0.0506 - val_accuracy: 0.9877\n",
            "Epoch 1180/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9933 - val_loss: 0.0489 - val_accuracy: 0.9877\n",
            "Epoch 1181/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0245 - accuracy: 0.9941 - val_loss: 0.0517 - val_accuracy: 0.9877\n",
            "Epoch 1182/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0240 - accuracy: 0.9936 - val_loss: 0.0503 - val_accuracy: 0.9892\n",
            "Epoch 1183/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0243 - accuracy: 0.9931 - val_loss: 0.0510 - val_accuracy: 0.9877\n",
            "Epoch 1184/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0258 - accuracy: 0.9928 - val_loss: 0.0527 - val_accuracy: 0.9877\n",
            "Epoch 1185/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0246 - accuracy: 0.9944 - val_loss: 0.0567 - val_accuracy: 0.9823\n",
            "Epoch 1186/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0296 - accuracy: 0.9913 - val_loss: 0.0509 - val_accuracy: 0.9885\n",
            "Epoch 1187/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0283 - accuracy: 0.9923 - val_loss: 0.0528 - val_accuracy: 0.9885\n",
            "Epoch 1188/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0257 - accuracy: 0.9928 - val_loss: 0.0573 - val_accuracy: 0.9854\n",
            "Epoch 1189/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0285 - accuracy: 0.9926 - val_loss: 0.0541 - val_accuracy: 0.9854\n",
            "Epoch 1190/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0279 - accuracy: 0.9915 - val_loss: 0.0530 - val_accuracy: 0.9854\n",
            "Epoch 1191/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0275 - accuracy: 0.9926 - val_loss: 0.0540 - val_accuracy: 0.9869\n",
            "Epoch 1192/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0246 - accuracy: 0.9938 - val_loss: 0.0504 - val_accuracy: 0.9877\n",
            "Epoch 1193/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0261 - accuracy: 0.9926 - val_loss: 0.0506 - val_accuracy: 0.9892\n",
            "Epoch 1194/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0248 - accuracy: 0.9931 - val_loss: 0.0503 - val_accuracy: 0.9869\n",
            "Epoch 1195/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0242 - accuracy: 0.9938 - val_loss: 0.0512 - val_accuracy: 0.9877\n",
            "Epoch 1196/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0251 - accuracy: 0.9923 - val_loss: 0.0521 - val_accuracy: 0.9885\n",
            "Epoch 1197/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0258 - accuracy: 0.9928 - val_loss: 0.0519 - val_accuracy: 0.9892\n",
            "Epoch 1198/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0247 - accuracy: 0.9936 - val_loss: 0.0491 - val_accuracy: 0.9877\n",
            "Epoch 1199/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0241 - accuracy: 0.9944 - val_loss: 0.0508 - val_accuracy: 0.9869\n",
            "Epoch 1200/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0234 - accuracy: 0.9944 - val_loss: 0.0500 - val_accuracy: 0.9885\n",
            "Epoch 1201/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0240 - accuracy: 0.9941 - val_loss: 0.0515 - val_accuracy: 0.9877\n",
            "Epoch 1202/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0235 - accuracy: 0.9941 - val_loss: 0.0522 - val_accuracy: 0.9869\n",
            "Epoch 1203/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0250 - accuracy: 0.9938 - val_loss: 0.0487 - val_accuracy: 0.9877\n",
            "Epoch 1204/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0240 - accuracy: 0.9938 - val_loss: 0.0508 - val_accuracy: 0.9885\n",
            "Epoch 1205/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0251 - accuracy: 0.9938 - val_loss: 0.0508 - val_accuracy: 0.9877\n",
            "Epoch 1206/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0245 - accuracy: 0.9931 - val_loss: 0.0512 - val_accuracy: 0.9892\n",
            "Epoch 1207/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0252 - accuracy: 0.9936 - val_loss: 0.0524 - val_accuracy: 0.9885\n",
            "Epoch 1208/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0260 - accuracy: 0.9926 - val_loss: 0.0581 - val_accuracy: 0.9831\n",
            "Epoch 1209/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0285 - accuracy: 0.9908 - val_loss: 0.0528 - val_accuracy: 0.9877\n",
            "Epoch 1210/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0293 - accuracy: 0.9915 - val_loss: 0.0549 - val_accuracy: 0.9862\n",
            "Epoch 1211/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0248 - accuracy: 0.9928 - val_loss: 0.0504 - val_accuracy: 0.9885\n",
            "Epoch 1212/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9931 - val_loss: 0.0539 - val_accuracy: 0.9862\n",
            "Epoch 1213/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0270 - accuracy: 0.9926 - val_loss: 0.0565 - val_accuracy: 0.9846\n",
            "Epoch 1214/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0339 - accuracy: 0.9895 - val_loss: 0.0666 - val_accuracy: 0.9815\n",
            "Epoch 1215/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0308 - accuracy: 0.9913 - val_loss: 0.0673 - val_accuracy: 0.9823\n",
            "Epoch 1216/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0349 - accuracy: 0.9890 - val_loss: 0.0524 - val_accuracy: 0.9869\n",
            "Epoch 1217/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0349 - accuracy: 0.9897 - val_loss: 0.0511 - val_accuracy: 0.9869\n",
            "Epoch 1218/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0309 - accuracy: 0.9902 - val_loss: 0.0623 - val_accuracy: 0.9808\n",
            "Epoch 1219/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0263 - accuracy: 0.9923 - val_loss: 0.0511 - val_accuracy: 0.9869\n",
            "Epoch 1220/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0237 - accuracy: 0.9944 - val_loss: 0.0537 - val_accuracy: 0.9862\n",
            "Epoch 1221/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0241 - accuracy: 0.9933 - val_loss: 0.0505 - val_accuracy: 0.9877\n",
            "Epoch 1222/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0234 - accuracy: 0.9944 - val_loss: 0.0511 - val_accuracy: 0.9869\n",
            "Epoch 1223/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0240 - accuracy: 0.9938 - val_loss: 0.0506 - val_accuracy: 0.9869\n",
            "Epoch 1224/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0236 - accuracy: 0.9933 - val_loss: 0.0501 - val_accuracy: 0.9877\n",
            "Epoch 1225/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0234 - accuracy: 0.9951 - val_loss: 0.0509 - val_accuracy: 0.9869\n",
            "Epoch 1226/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0238 - accuracy: 0.9941 - val_loss: 0.0528 - val_accuracy: 0.9869\n",
            "Epoch 1227/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0241 - accuracy: 0.9938 - val_loss: 0.0500 - val_accuracy: 0.9877\n",
            "Epoch 1228/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0233 - accuracy: 0.9941 - val_loss: 0.0500 - val_accuracy: 0.9877\n",
            "Epoch 1229/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0242 - accuracy: 0.9941 - val_loss: 0.0519 - val_accuracy: 0.9892\n",
            "Epoch 1230/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0246 - accuracy: 0.9944 - val_loss: 0.0560 - val_accuracy: 0.9854\n",
            "Epoch 1231/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0254 - accuracy: 0.9933 - val_loss: 0.0512 - val_accuracy: 0.9877\n",
            "Epoch 1232/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0236 - accuracy: 0.9938 - val_loss: 0.0505 - val_accuracy: 0.9877\n",
            "Epoch 1233/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0236 - accuracy: 0.9938 - val_loss: 0.0495 - val_accuracy: 0.9877\n",
            "Epoch 1234/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0235 - accuracy: 0.9936 - val_loss: 0.0514 - val_accuracy: 0.9885\n",
            "Epoch 1235/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0237 - accuracy: 0.9944 - val_loss: 0.0502 - val_accuracy: 0.9869\n",
            "Epoch 1236/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0232 - accuracy: 0.9933 - val_loss: 0.0504 - val_accuracy: 0.9869\n",
            "Epoch 1237/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0236 - accuracy: 0.9946 - val_loss: 0.0499 - val_accuracy: 0.9885\n",
            "Epoch 1238/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0236 - accuracy: 0.9941 - val_loss: 0.0507 - val_accuracy: 0.9885\n",
            "Epoch 1239/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0232 - accuracy: 0.9941 - val_loss: 0.0507 - val_accuracy: 0.9877\n",
            "Epoch 1240/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0248 - accuracy: 0.9936 - val_loss: 0.0520 - val_accuracy: 0.9892\n",
            "Epoch 1241/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0255 - accuracy: 0.9915 - val_loss: 0.0526 - val_accuracy: 0.9869\n",
            "Epoch 1242/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0302 - accuracy: 0.9908 - val_loss: 0.0568 - val_accuracy: 0.9846\n",
            "Epoch 1243/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0281 - accuracy: 0.9905 - val_loss: 0.0645 - val_accuracy: 0.9815\n",
            "Epoch 1244/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0277 - accuracy: 0.9923 - val_loss: 0.0514 - val_accuracy: 0.9869\n",
            "Epoch 1245/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0265 - accuracy: 0.9926 - val_loss: 0.0537 - val_accuracy: 0.9854\n",
            "Epoch 1246/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0259 - accuracy: 0.9933 - val_loss: 0.0518 - val_accuracy: 0.9862\n",
            "Epoch 1247/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0298 - accuracy: 0.9913 - val_loss: 0.0518 - val_accuracy: 0.9877\n",
            "Epoch 1248/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0247 - accuracy: 0.9941 - val_loss: 0.0511 - val_accuracy: 0.9877\n",
            "Epoch 1249/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0238 - accuracy: 0.9941 - val_loss: 0.0505 - val_accuracy: 0.9869\n",
            "Epoch 1250/2000\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.0242 - accuracy: 0.9936 - val_loss: 0.0542 - val_accuracy: 0.9862\n",
            "Epoch 1251/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0248 - accuracy: 0.9938 - val_loss: 0.0502 - val_accuracy: 0.9892\n",
            "Epoch 1252/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0235 - accuracy: 0.9938 - val_loss: 0.0512 - val_accuracy: 0.9885\n",
            "Epoch 1253/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0238 - accuracy: 0.9931 - val_loss: 0.0501 - val_accuracy: 0.9877\n",
            "Epoch 1254/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0264 - accuracy: 0.9933 - val_loss: 0.0504 - val_accuracy: 0.9885\n",
            "Epoch 1255/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0267 - accuracy: 0.9920 - val_loss: 0.0517 - val_accuracy: 0.9869\n",
            "Epoch 1256/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0249 - accuracy: 0.9933 - val_loss: 0.0494 - val_accuracy: 0.9885\n",
            "Epoch 1257/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0248 - accuracy: 0.9946 - val_loss: 0.0532 - val_accuracy: 0.9877\n",
            "Epoch 1258/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0248 - accuracy: 0.9936 - val_loss: 0.0538 - val_accuracy: 0.9854\n",
            "Epoch 1259/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0270 - accuracy: 0.9938 - val_loss: 0.0513 - val_accuracy: 0.9892\n",
            "Epoch 1260/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0246 - accuracy: 0.9933 - val_loss: 0.0571 - val_accuracy: 0.9838\n",
            "Epoch 1261/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0266 - accuracy: 0.9928 - val_loss: 0.0534 - val_accuracy: 0.9854\n",
            "Epoch 1262/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0245 - accuracy: 0.9941 - val_loss: 0.0514 - val_accuracy: 0.9862\n",
            "Epoch 1263/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0241 - accuracy: 0.9941 - val_loss: 0.0509 - val_accuracy: 0.9869\n",
            "Epoch 1264/2000\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0237 - accuracy: 0.9926 - val_loss: 0.0518 - val_accuracy: 0.9877\n",
            "Epoch 1265/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0235 - accuracy: 0.9931 - val_loss: 0.0499 - val_accuracy: 0.9877\n",
            "Epoch 1266/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0236 - accuracy: 0.9941 - val_loss: 0.0501 - val_accuracy: 0.9885\n",
            "Epoch 1267/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0252 - accuracy: 0.9933 - val_loss: 0.0620 - val_accuracy: 0.9831\n",
            "Epoch 1268/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0258 - accuracy: 0.9938 - val_loss: 0.0503 - val_accuracy: 0.9869\n",
            "Epoch 1269/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0249 - accuracy: 0.9928 - val_loss: 0.0493 - val_accuracy: 0.9885\n",
            "Epoch 1270/2000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0241 - accuracy: 0.9941 - val_loss: 0.0512 - val_accuracy: 0.9885\n",
            "Epoch 1271/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0238 - accuracy: 0.9938 - val_loss: 0.0515 - val_accuracy: 0.9862\n",
            "Epoch 1272/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0230 - accuracy: 0.9944 - val_loss: 0.0532 - val_accuracy: 0.9838\n",
            "Epoch 1273/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0244 - accuracy: 0.9920 - val_loss: 0.0511 - val_accuracy: 0.9885\n",
            "Epoch 1274/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0249 - accuracy: 0.9938 - val_loss: 0.0499 - val_accuracy: 0.9869\n",
            "Epoch 1275/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0238 - accuracy: 0.9936 - val_loss: 0.0502 - val_accuracy: 0.9877\n",
            "Epoch 1276/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0244 - accuracy: 0.9936 - val_loss: 0.0510 - val_accuracy: 0.9885\n",
            "Epoch 1277/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0255 - accuracy: 0.9933 - val_loss: 0.0541 - val_accuracy: 0.9854\n",
            "Epoch 1278/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0241 - accuracy: 0.9933 - val_loss: 0.0519 - val_accuracy: 0.9854\n",
            "Epoch 1279/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0265 - accuracy: 0.9923 - val_loss: 0.0509 - val_accuracy: 0.9885\n",
            "Epoch 1280/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9931 - val_loss: 0.0506 - val_accuracy: 0.9892\n",
            "Epoch 1281/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0236 - accuracy: 0.9938 - val_loss: 0.0521 - val_accuracy: 0.9885\n",
            "Epoch 1282/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0242 - accuracy: 0.9944 - val_loss: 0.0532 - val_accuracy: 0.9892\n",
            "Epoch 1283/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0289 - accuracy: 0.9910 - val_loss: 0.0545 - val_accuracy: 0.9869\n",
            "Epoch 1284/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0328 - accuracy: 0.9900 - val_loss: 0.0546 - val_accuracy: 0.9854\n",
            "Epoch 1285/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0302 - accuracy: 0.9913 - val_loss: 0.0533 - val_accuracy: 0.9869\n",
            "Epoch 1286/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0248 - accuracy: 0.9928 - val_loss: 0.0542 - val_accuracy: 0.9846\n",
            "Epoch 1287/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0257 - accuracy: 0.9933 - val_loss: 0.0503 - val_accuracy: 0.9885\n",
            "Epoch 1288/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0238 - accuracy: 0.9936 - val_loss: 0.0496 - val_accuracy: 0.9885\n",
            "Epoch 1289/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0241 - accuracy: 0.9946 - val_loss: 0.0496 - val_accuracy: 0.9892\n",
            "Epoch 1290/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0232 - accuracy: 0.9944 - val_loss: 0.0505 - val_accuracy: 0.9885\n",
            "Epoch 1291/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0225 - accuracy: 0.9946 - val_loss: 0.0493 - val_accuracy: 0.9869\n",
            "Epoch 1292/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0231 - accuracy: 0.9949 - val_loss: 0.0524 - val_accuracy: 0.9862\n",
            "Epoch 1293/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0239 - accuracy: 0.9938 - val_loss: 0.0514 - val_accuracy: 0.9877\n",
            "Epoch 1294/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0245 - accuracy: 0.9928 - val_loss: 0.0520 - val_accuracy: 0.9862\n",
            "Epoch 1295/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0241 - accuracy: 0.9936 - val_loss: 0.0531 - val_accuracy: 0.9869\n",
            "Epoch 1296/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0234 - accuracy: 0.9944 - val_loss: 0.0497 - val_accuracy: 0.9885\n",
            "Epoch 1297/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0238 - accuracy: 0.9949 - val_loss: 0.0498 - val_accuracy: 0.9877\n",
            "Epoch 1298/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0236 - accuracy: 0.9933 - val_loss: 0.0508 - val_accuracy: 0.9885\n",
            "Epoch 1299/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0236 - accuracy: 0.9944 - val_loss: 0.0498 - val_accuracy: 0.9869\n",
            "Epoch 1300/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0236 - accuracy: 0.9941 - val_loss: 0.0510 - val_accuracy: 0.9885\n",
            "Epoch 1301/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0237 - accuracy: 0.9933 - val_loss: 0.0502 - val_accuracy: 0.9877\n",
            "Epoch 1302/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0242 - accuracy: 0.9936 - val_loss: 0.0540 - val_accuracy: 0.9877\n",
            "Epoch 1303/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0249 - accuracy: 0.9933 - val_loss: 0.0495 - val_accuracy: 0.9885\n",
            "Epoch 1304/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0235 - accuracy: 0.9941 - val_loss: 0.0525 - val_accuracy: 0.9869\n",
            "Epoch 1305/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0240 - accuracy: 0.9938 - val_loss: 0.0502 - val_accuracy: 0.9877\n",
            "Epoch 1306/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0236 - accuracy: 0.9941 - val_loss: 0.0527 - val_accuracy: 0.9869\n",
            "Epoch 1307/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0234 - accuracy: 0.9938 - val_loss: 0.0503 - val_accuracy: 0.9877\n",
            "Epoch 1308/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0236 - accuracy: 0.9936 - val_loss: 0.0540 - val_accuracy: 0.9877\n",
            "Epoch 1309/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0242 - accuracy: 0.9938 - val_loss: 0.0503 - val_accuracy: 0.9877\n",
            "Epoch 1310/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0238 - accuracy: 0.9944 - val_loss: 0.0584 - val_accuracy: 0.9823\n",
            "Epoch 1311/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0267 - accuracy: 0.9926 - val_loss: 0.0566 - val_accuracy: 0.9846\n",
            "Epoch 1312/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0324 - accuracy: 0.9908 - val_loss: 0.0655 - val_accuracy: 0.9800\n",
            "Epoch 1313/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0306 - accuracy: 0.9895 - val_loss: 0.0582 - val_accuracy: 0.9808\n",
            "Epoch 1314/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9918 - val_loss: 0.0519 - val_accuracy: 0.9877\n",
            "Epoch 1315/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0243 - accuracy: 0.9944 - val_loss: 0.0505 - val_accuracy: 0.9854\n",
            "Epoch 1316/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0242 - accuracy: 0.9928 - val_loss: 0.0501 - val_accuracy: 0.9877\n",
            "Epoch 1317/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0232 - accuracy: 0.9944 - val_loss: 0.0514 - val_accuracy: 0.9862\n",
            "Epoch 1318/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0277 - accuracy: 0.9926 - val_loss: 0.0507 - val_accuracy: 0.9877\n",
            "Epoch 1319/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0276 - accuracy: 0.9915 - val_loss: 0.0633 - val_accuracy: 0.9808\n",
            "Epoch 1320/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0249 - accuracy: 0.9926 - val_loss: 0.0546 - val_accuracy: 0.9862\n",
            "Epoch 1321/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0243 - accuracy: 0.9941 - val_loss: 0.0518 - val_accuracy: 0.9869\n",
            "Epoch 1322/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0244 - accuracy: 0.9941 - val_loss: 0.0487 - val_accuracy: 0.9885\n",
            "Epoch 1323/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0276 - accuracy: 0.9910 - val_loss: 0.0514 - val_accuracy: 0.9877\n",
            "Epoch 1324/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0269 - accuracy: 0.9918 - val_loss: 0.0601 - val_accuracy: 0.9823\n",
            "Epoch 1325/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0265 - accuracy: 0.9936 - val_loss: 0.0520 - val_accuracy: 0.9885\n",
            "Epoch 1326/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0250 - accuracy: 0.9931 - val_loss: 0.0519 - val_accuracy: 0.9854\n",
            "Epoch 1327/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0243 - accuracy: 0.9936 - val_loss: 0.0508 - val_accuracy: 0.9869\n",
            "Epoch 1328/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0227 - accuracy: 0.9941 - val_loss: 0.0517 - val_accuracy: 0.9869\n",
            "Epoch 1329/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9920 - val_loss: 0.0529 - val_accuracy: 0.9862\n",
            "Epoch 1330/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0274 - accuracy: 0.9918 - val_loss: 0.0541 - val_accuracy: 0.9846\n",
            "Epoch 1331/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0248 - accuracy: 0.9941 - val_loss: 0.0577 - val_accuracy: 0.9838\n",
            "Epoch 1332/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0237 - accuracy: 0.9949 - val_loss: 0.0499 - val_accuracy: 0.9885\n",
            "Epoch 1333/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0229 - accuracy: 0.9944 - val_loss: 0.0559 - val_accuracy: 0.9846\n",
            "Epoch 1334/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0232 - accuracy: 0.9931 - val_loss: 0.0524 - val_accuracy: 0.9892\n",
            "Epoch 1335/2000\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0238 - accuracy: 0.9936 - val_loss: 0.0498 - val_accuracy: 0.9885\n",
            "Epoch 1336/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0234 - accuracy: 0.9938 - val_loss: 0.0517 - val_accuracy: 0.9862\n",
            "Epoch 1337/2000\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.0245 - accuracy: 0.9936 - val_loss: 0.0494 - val_accuracy: 0.9885\n",
            "Epoch 1338/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0247 - accuracy: 0.9936 - val_loss: 0.0525 - val_accuracy: 0.9862\n",
            "Epoch 1339/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0254 - accuracy: 0.9923 - val_loss: 0.0541 - val_accuracy: 0.9846\n",
            "Epoch 1340/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0253 - accuracy: 0.9938 - val_loss: 0.0609 - val_accuracy: 0.9831\n",
            "Epoch 1341/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0280 - accuracy: 0.9915 - val_loss: 0.0558 - val_accuracy: 0.9846\n",
            "Epoch 1342/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0253 - accuracy: 0.9933 - val_loss: 0.0506 - val_accuracy: 0.9885\n",
            "Epoch 1343/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0234 - accuracy: 0.9941 - val_loss: 0.0509 - val_accuracy: 0.9877\n",
            "Epoch 1344/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0250 - accuracy: 0.9928 - val_loss: 0.0532 - val_accuracy: 0.9862\n",
            "Epoch 1345/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0237 - accuracy: 0.9941 - val_loss: 0.0538 - val_accuracy: 0.9862\n",
            "Epoch 1346/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0260 - accuracy: 0.9926 - val_loss: 0.0525 - val_accuracy: 0.9862\n",
            "Epoch 1347/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0239 - accuracy: 0.9938 - val_loss: 0.0516 - val_accuracy: 0.9869\n",
            "Epoch 1348/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0237 - accuracy: 0.9933 - val_loss: 0.0502 - val_accuracy: 0.9877\n",
            "Epoch 1349/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0234 - accuracy: 0.9938 - val_loss: 0.0505 - val_accuracy: 0.9885\n",
            "Epoch 1350/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0242 - accuracy: 0.9933 - val_loss: 0.0500 - val_accuracy: 0.9869\n",
            "Epoch 1351/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0251 - accuracy: 0.9944 - val_loss: 0.0517 - val_accuracy: 0.9885\n",
            "Epoch 1352/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0244 - accuracy: 0.9931 - val_loss: 0.0518 - val_accuracy: 0.9885\n",
            "Epoch 1353/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0235 - accuracy: 0.9941 - val_loss: 0.0510 - val_accuracy: 0.9877\n",
            "Epoch 1354/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0236 - accuracy: 0.9938 - val_loss: 0.0495 - val_accuracy: 0.9885\n",
            "Epoch 1355/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0244 - accuracy: 0.9936 - val_loss: 0.0545 - val_accuracy: 0.9869\n",
            "Epoch 1356/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0243 - accuracy: 0.9936 - val_loss: 0.0518 - val_accuracy: 0.9869\n",
            "Epoch 1357/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0227 - accuracy: 0.9941 - val_loss: 0.0500 - val_accuracy: 0.9877\n",
            "Epoch 1358/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0229 - accuracy: 0.9941 - val_loss: 0.0510 - val_accuracy: 0.9885\n",
            "Epoch 1359/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0231 - accuracy: 0.9928 - val_loss: 0.0514 - val_accuracy: 0.9877\n",
            "Epoch 1360/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0230 - accuracy: 0.9944 - val_loss: 0.0502 - val_accuracy: 0.9869\n",
            "Epoch 1361/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0240 - accuracy: 0.9944 - val_loss: 0.0589 - val_accuracy: 0.9846\n",
            "Epoch 1362/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0268 - accuracy: 0.9928 - val_loss: 0.0517 - val_accuracy: 0.9885\n",
            "Epoch 1363/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0299 - accuracy: 0.9902 - val_loss: 0.0593 - val_accuracy: 0.9838\n",
            "Epoch 1364/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0272 - accuracy: 0.9944 - val_loss: 0.0549 - val_accuracy: 0.9854\n",
            "Epoch 1365/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0258 - accuracy: 0.9926 - val_loss: 0.0537 - val_accuracy: 0.9862\n",
            "Epoch 1366/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0256 - accuracy: 0.9936 - val_loss: 0.0540 - val_accuracy: 0.9854\n",
            "Epoch 1367/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0251 - accuracy: 0.9926 - val_loss: 0.0493 - val_accuracy: 0.9885\n",
            "Epoch 1368/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0234 - accuracy: 0.9926 - val_loss: 0.0504 - val_accuracy: 0.9877\n",
            "Epoch 1369/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0229 - accuracy: 0.9941 - val_loss: 0.0512 - val_accuracy: 0.9877\n",
            "Epoch 1370/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0236 - accuracy: 0.9946 - val_loss: 0.0504 - val_accuracy: 0.9892\n",
            "Epoch 1371/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0229 - accuracy: 0.9936 - val_loss: 0.0523 - val_accuracy: 0.9869\n",
            "Epoch 1372/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0234 - accuracy: 0.9949 - val_loss: 0.0541 - val_accuracy: 0.9862\n",
            "Epoch 1373/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0232 - accuracy: 0.9938 - val_loss: 0.0519 - val_accuracy: 0.9885\n",
            "Epoch 1374/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0239 - accuracy: 0.9933 - val_loss: 0.0505 - val_accuracy: 0.9885\n",
            "Epoch 1375/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0255 - accuracy: 0.9928 - val_loss: 0.0499 - val_accuracy: 0.9900\n",
            "Epoch 1376/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0252 - accuracy: 0.9931 - val_loss: 0.0517 - val_accuracy: 0.9877\n",
            "Epoch 1377/2000\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.0237 - accuracy: 0.9936 - val_loss: 0.0533 - val_accuracy: 0.9862\n",
            "Epoch 1378/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0248 - accuracy: 0.9933 - val_loss: 0.0586 - val_accuracy: 0.9838\n",
            "Epoch 1379/2000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0276 - accuracy: 0.9920 - val_loss: 0.0544 - val_accuracy: 0.9854\n",
            "Epoch 1380/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0259 - accuracy: 0.9923 - val_loss: 0.0503 - val_accuracy: 0.9892\n",
            "Epoch 1381/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0262 - accuracy: 0.9923 - val_loss: 0.0511 - val_accuracy: 0.9869\n",
            "Epoch 1382/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0275 - accuracy: 0.9923 - val_loss: 0.0514 - val_accuracy: 0.9869\n",
            "Epoch 1383/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0235 - accuracy: 0.9938 - val_loss: 0.0528 - val_accuracy: 0.9869\n",
            "Epoch 1384/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0242 - accuracy: 0.9936 - val_loss: 0.0524 - val_accuracy: 0.9885\n",
            "Epoch 1385/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0251 - accuracy: 0.9915 - val_loss: 0.0507 - val_accuracy: 0.9877\n",
            "Epoch 1386/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9923 - val_loss: 0.0510 - val_accuracy: 0.9885\n",
            "Epoch 1387/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0264 - accuracy: 0.9918 - val_loss: 0.0505 - val_accuracy: 0.9877\n",
            "Epoch 1388/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0248 - accuracy: 0.9946 - val_loss: 0.0516 - val_accuracy: 0.9892\n",
            "Epoch 1389/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0247 - accuracy: 0.9931 - val_loss: 0.0495 - val_accuracy: 0.9885\n",
            "Epoch 1390/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0234 - accuracy: 0.9946 - val_loss: 0.0502 - val_accuracy: 0.9885\n",
            "Epoch 1391/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0228 - accuracy: 0.9941 - val_loss: 0.0509 - val_accuracy: 0.9885\n",
            "Epoch 1392/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0225 - accuracy: 0.9938 - val_loss: 0.0509 - val_accuracy: 0.9877\n",
            "Epoch 1393/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0225 - accuracy: 0.9938 - val_loss: 0.0510 - val_accuracy: 0.9885\n",
            "Epoch 1394/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0226 - accuracy: 0.9946 - val_loss: 0.0507 - val_accuracy: 0.9877\n",
            "Epoch 1395/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0237 - accuracy: 0.9936 - val_loss: 0.0501 - val_accuracy: 0.9877\n",
            "Epoch 1396/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0230 - accuracy: 0.9938 - val_loss: 0.0498 - val_accuracy: 0.9877\n",
            "Epoch 1397/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0223 - accuracy: 0.9944 - val_loss: 0.0542 - val_accuracy: 0.9862\n",
            "Epoch 1398/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0240 - accuracy: 0.9926 - val_loss: 0.0513 - val_accuracy: 0.9869\n",
            "Epoch 1399/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0250 - accuracy: 0.9928 - val_loss: 0.0534 - val_accuracy: 0.9869\n",
            "Epoch 1400/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0252 - accuracy: 0.9938 - val_loss: 0.0558 - val_accuracy: 0.9862\n",
            "Epoch 1401/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0248 - accuracy: 0.9933 - val_loss: 0.0528 - val_accuracy: 0.9877\n",
            "Epoch 1402/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0235 - accuracy: 0.9944 - val_loss: 0.0504 - val_accuracy: 0.9885\n",
            "Epoch 1403/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0247 - accuracy: 0.9938 - val_loss: 0.0539 - val_accuracy: 0.9854\n",
            "Epoch 1404/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0237 - accuracy: 0.9931 - val_loss: 0.0586 - val_accuracy: 0.9838\n",
            "Epoch 1405/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0226 - accuracy: 0.9941 - val_loss: 0.0521 - val_accuracy: 0.9885\n",
            "Epoch 1406/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0239 - accuracy: 0.9941 - val_loss: 0.0494 - val_accuracy: 0.9885\n",
            "Epoch 1407/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0240 - accuracy: 0.9931 - val_loss: 0.0518 - val_accuracy: 0.9892\n",
            "Epoch 1408/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0253 - accuracy: 0.9933 - val_loss: 0.0521 - val_accuracy: 0.9877\n",
            "Epoch 1409/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0243 - accuracy: 0.9938 - val_loss: 0.0502 - val_accuracy: 0.9877\n",
            "Epoch 1410/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0248 - accuracy: 0.9928 - val_loss: 0.0521 - val_accuracy: 0.9869\n",
            "Epoch 1411/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0238 - accuracy: 0.9933 - val_loss: 0.0507 - val_accuracy: 0.9885\n",
            "Epoch 1412/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0237 - accuracy: 0.9946 - val_loss: 0.0556 - val_accuracy: 0.9854\n",
            "Epoch 1413/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0228 - accuracy: 0.9944 - val_loss: 0.0497 - val_accuracy: 0.9885\n",
            "Epoch 1414/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0229 - accuracy: 0.9941 - val_loss: 0.0506 - val_accuracy: 0.9877\n",
            "Epoch 1415/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0228 - accuracy: 0.9936 - val_loss: 0.0505 - val_accuracy: 0.9885\n",
            "Epoch 1416/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0229 - accuracy: 0.9941 - val_loss: 0.0515 - val_accuracy: 0.9885\n",
            "Epoch 1417/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0234 - accuracy: 0.9936 - val_loss: 0.0516 - val_accuracy: 0.9892\n",
            "Epoch 1418/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0224 - accuracy: 0.9936 - val_loss: 0.0516 - val_accuracy: 0.9885\n",
            "Epoch 1419/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0224 - accuracy: 0.9944 - val_loss: 0.0503 - val_accuracy: 0.9877\n",
            "Epoch 1420/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0228 - accuracy: 0.9938 - val_loss: 0.0517 - val_accuracy: 0.9877\n",
            "Epoch 1421/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0242 - accuracy: 0.9941 - val_loss: 0.0555 - val_accuracy: 0.9854\n",
            "Epoch 1422/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0246 - accuracy: 0.9923 - val_loss: 0.0590 - val_accuracy: 0.9831\n",
            "Epoch 1423/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9931 - val_loss: 0.0520 - val_accuracy: 0.9877\n",
            "Epoch 1424/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0256 - accuracy: 0.9915 - val_loss: 0.0508 - val_accuracy: 0.9877\n",
            "Epoch 1425/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0263 - accuracy: 0.9918 - val_loss: 0.0515 - val_accuracy: 0.9869\n",
            "Epoch 1426/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0240 - accuracy: 0.9933 - val_loss: 0.0505 - val_accuracy: 0.9869\n",
            "Epoch 1427/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0230 - accuracy: 0.9946 - val_loss: 0.0529 - val_accuracy: 0.9885\n",
            "Epoch 1428/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0234 - accuracy: 0.9936 - val_loss: 0.0522 - val_accuracy: 0.9869\n",
            "Epoch 1429/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0244 - accuracy: 0.9931 - val_loss: 0.0525 - val_accuracy: 0.9885\n",
            "Epoch 1430/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0255 - accuracy: 0.9923 - val_loss: 0.0510 - val_accuracy: 0.9877\n",
            "Epoch 1431/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0273 - accuracy: 0.9920 - val_loss: 0.0503 - val_accuracy: 0.9877\n",
            "Epoch 1432/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0234 - accuracy: 0.9941 - val_loss: 0.0518 - val_accuracy: 0.9877\n",
            "Epoch 1433/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0223 - accuracy: 0.9946 - val_loss: 0.0500 - val_accuracy: 0.9885\n",
            "Epoch 1434/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0234 - accuracy: 0.9944 - val_loss: 0.0500 - val_accuracy: 0.9885\n",
            "Epoch 1435/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0227 - accuracy: 0.9936 - val_loss: 0.0505 - val_accuracy: 0.9877\n",
            "Epoch 1436/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0239 - accuracy: 0.9928 - val_loss: 0.0520 - val_accuracy: 0.9877\n",
            "Epoch 1437/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0243 - accuracy: 0.9936 - val_loss: 0.0502 - val_accuracy: 0.9892\n",
            "Epoch 1438/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0227 - accuracy: 0.9938 - val_loss: 0.0508 - val_accuracy: 0.9877\n",
            "Epoch 1439/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0228 - accuracy: 0.9946 - val_loss: 0.0500 - val_accuracy: 0.9877\n",
            "Epoch 1440/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0230 - accuracy: 0.9933 - val_loss: 0.0539 - val_accuracy: 0.9846\n",
            "Epoch 1441/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0243 - accuracy: 0.9933 - val_loss: 0.0509 - val_accuracy: 0.9885\n",
            "Epoch 1442/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0222 - accuracy: 0.9946 - val_loss: 0.0511 - val_accuracy: 0.9877\n",
            "Epoch 1443/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0226 - accuracy: 0.9941 - val_loss: 0.0507 - val_accuracy: 0.9869\n",
            "Epoch 1444/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0252 - accuracy: 0.9931 - val_loss: 0.0516 - val_accuracy: 0.9877\n",
            "Epoch 1445/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9926 - val_loss: 0.0521 - val_accuracy: 0.9877\n",
            "Epoch 1446/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0244 - accuracy: 0.9928 - val_loss: 0.0542 - val_accuracy: 0.9854\n",
            "Epoch 1447/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0228 - accuracy: 0.9941 - val_loss: 0.0513 - val_accuracy: 0.9877\n",
            "Epoch 1448/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0226 - accuracy: 0.9933 - val_loss: 0.0507 - val_accuracy: 0.9877\n",
            "Epoch 1449/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0231 - accuracy: 0.9938 - val_loss: 0.0549 - val_accuracy: 0.9877\n",
            "Epoch 1450/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0245 - accuracy: 0.9931 - val_loss: 0.0511 - val_accuracy: 0.9885\n",
            "Epoch 1451/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0226 - accuracy: 0.9951 - val_loss: 0.0512 - val_accuracy: 0.9877\n",
            "Epoch 1452/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0224 - accuracy: 0.9938 - val_loss: 0.0518 - val_accuracy: 0.9892\n",
            "Epoch 1453/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0230 - accuracy: 0.9941 - val_loss: 0.0523 - val_accuracy: 0.9869\n",
            "Epoch 1454/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0223 - accuracy: 0.9936 - val_loss: 0.0517 - val_accuracy: 0.9862\n",
            "Epoch 1455/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0223 - accuracy: 0.9946 - val_loss: 0.0519 - val_accuracy: 0.9877\n",
            "Epoch 1456/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0226 - accuracy: 0.9938 - val_loss: 0.0524 - val_accuracy: 0.9877\n",
            "Epoch 1457/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0279 - accuracy: 0.9910 - val_loss: 0.0527 - val_accuracy: 0.9877\n",
            "Epoch 1458/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0303 - accuracy: 0.9910 - val_loss: 0.0535 - val_accuracy: 0.9885\n",
            "Epoch 1459/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0239 - accuracy: 0.9941 - val_loss: 0.0546 - val_accuracy: 0.9869\n",
            "Epoch 1460/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0237 - accuracy: 0.9931 - val_loss: 0.0517 - val_accuracy: 0.9877\n",
            "Epoch 1461/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0233 - accuracy: 0.9931 - val_loss: 0.0520 - val_accuracy: 0.9869\n",
            "Epoch 1462/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0231 - accuracy: 0.9936 - val_loss: 0.0511 - val_accuracy: 0.9885\n",
            "Epoch 1463/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0225 - accuracy: 0.9941 - val_loss: 0.0504 - val_accuracy: 0.9885\n",
            "Epoch 1464/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0232 - accuracy: 0.9941 - val_loss: 0.0527 - val_accuracy: 0.9869\n",
            "Epoch 1465/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0233 - accuracy: 0.9944 - val_loss: 0.0530 - val_accuracy: 0.9862\n",
            "Epoch 1466/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0233 - accuracy: 0.9936 - val_loss: 0.0524 - val_accuracy: 0.9877\n",
            "Epoch 1467/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0254 - accuracy: 0.9936 - val_loss: 0.0547 - val_accuracy: 0.9854\n",
            "Epoch 1468/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0244 - accuracy: 0.9936 - val_loss: 0.0523 - val_accuracy: 0.9892\n",
            "Epoch 1469/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0249 - accuracy: 0.9936 - val_loss: 0.0516 - val_accuracy: 0.9869\n",
            "Epoch 1470/2000\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0220 - accuracy: 0.9944 - val_loss: 0.0504 - val_accuracy: 0.9885\n",
            "Epoch 1471/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0238 - accuracy: 0.9936 - val_loss: 0.0515 - val_accuracy: 0.9877\n",
            "Epoch 1472/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0235 - accuracy: 0.9946 - val_loss: 0.0524 - val_accuracy: 0.9862\n",
            "Epoch 1473/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0246 - accuracy: 0.9926 - val_loss: 0.0544 - val_accuracy: 0.9885\n",
            "Epoch 1474/2000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0244 - accuracy: 0.9938 - val_loss: 0.0517 - val_accuracy: 0.9862\n",
            "Epoch 1475/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0231 - accuracy: 0.9938 - val_loss: 0.0516 - val_accuracy: 0.9877\n",
            "Epoch 1476/2000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0241 - accuracy: 0.9918 - val_loss: 0.0549 - val_accuracy: 0.9862\n",
            "Epoch 1477/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0232 - accuracy: 0.9933 - val_loss: 0.0513 - val_accuracy: 0.9877\n",
            "Epoch 1478/2000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0225 - accuracy: 0.9946 - val_loss: 0.0502 - val_accuracy: 0.9869\n",
            "Epoch 1479/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0222 - accuracy: 0.9946 - val_loss: 0.0499 - val_accuracy: 0.9877\n",
            "Epoch 1480/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0225 - accuracy: 0.9946 - val_loss: 0.0556 - val_accuracy: 0.9838\n",
            "Epoch 1481/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0232 - accuracy: 0.9931 - val_loss: 0.0516 - val_accuracy: 0.9869\n",
            "Epoch 1482/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0221 - accuracy: 0.9944 - val_loss: 0.0528 - val_accuracy: 0.9877\n",
            "Epoch 1483/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0233 - accuracy: 0.9938 - val_loss: 0.0508 - val_accuracy: 0.9877\n",
            "Epoch 1484/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0237 - accuracy: 0.9933 - val_loss: 0.0508 - val_accuracy: 0.9869\n",
            "Epoch 1485/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0246 - accuracy: 0.9936 - val_loss: 0.0548 - val_accuracy: 0.9854\n",
            "Epoch 1486/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0248 - accuracy: 0.9936 - val_loss: 0.0696 - val_accuracy: 0.9808\n",
            "Epoch 1487/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0335 - accuracy: 0.9900 - val_loss: 0.0513 - val_accuracy: 0.9877\n",
            "Epoch 1488/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0260 - accuracy: 0.9928 - val_loss: 0.0564 - val_accuracy: 0.9838\n",
            "Epoch 1489/2000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0226 - accuracy: 0.9931 - val_loss: 0.0501 - val_accuracy: 0.9892\n",
            "Epoch 1490/2000\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.0226 - accuracy: 0.9938 - val_loss: 0.0528 - val_accuracy: 0.9846\n",
            "Epoch 1491/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0234 - accuracy: 0.9946 - val_loss: 0.0520 - val_accuracy: 0.9885\n",
            "Epoch 1492/2000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0230 - accuracy: 0.9938 - val_loss: 0.0518 - val_accuracy: 0.9885\n",
            "Epoch 1493/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0243 - accuracy: 0.9938 - val_loss: 0.0525 - val_accuracy: 0.9892\n",
            "Epoch 1494/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0222 - accuracy: 0.9944 - val_loss: 0.0546 - val_accuracy: 0.9838\n",
            "Epoch 1495/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0234 - accuracy: 0.9936 - val_loss: 0.0514 - val_accuracy: 0.9877\n",
            "Epoch 1496/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0232 - accuracy: 0.9938 - val_loss: 0.0516 - val_accuracy: 0.9892\n",
            "Epoch 1497/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0228 - accuracy: 0.9941 - val_loss: 0.0516 - val_accuracy: 0.9885\n",
            "Epoch 1498/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0224 - accuracy: 0.9951 - val_loss: 0.0509 - val_accuracy: 0.9877\n",
            "Epoch 1499/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0233 - accuracy: 0.9941 - val_loss: 0.0528 - val_accuracy: 0.9869\n",
            "Epoch 1500/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0228 - accuracy: 0.9941 - val_loss: 0.0514 - val_accuracy: 0.9854\n",
            "Epoch 1501/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0226 - accuracy: 0.9941 - val_loss: 0.0522 - val_accuracy: 0.9885\n",
            "Epoch 1502/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0226 - accuracy: 0.9944 - val_loss: 0.0507 - val_accuracy: 0.9877\n",
            "Epoch 1503/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0218 - accuracy: 0.9944 - val_loss: 0.0508 - val_accuracy: 0.9877\n",
            "Epoch 1504/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0218 - accuracy: 0.9936 - val_loss: 0.0511 - val_accuracy: 0.9877\n",
            "Epoch 1505/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0220 - accuracy: 0.9941 - val_loss: 0.0533 - val_accuracy: 0.9862\n",
            "Epoch 1506/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0227 - accuracy: 0.9949 - val_loss: 0.0509 - val_accuracy: 0.9869\n",
            "Epoch 1507/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0253 - accuracy: 0.9928 - val_loss: 0.0552 - val_accuracy: 0.9854\n",
            "Epoch 1508/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0241 - accuracy: 0.9933 - val_loss: 0.0522 - val_accuracy: 0.9869\n",
            "Epoch 1509/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0224 - accuracy: 0.9941 - val_loss: 0.0558 - val_accuracy: 0.9838\n",
            "Epoch 1510/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9928 - val_loss: 0.0622 - val_accuracy: 0.9823\n",
            "Epoch 1511/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0253 - accuracy: 0.9931 - val_loss: 0.0534 - val_accuracy: 0.9869\n",
            "Epoch 1512/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0294 - accuracy: 0.9918 - val_loss: 0.0532 - val_accuracy: 0.9869\n",
            "Epoch 1513/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0313 - accuracy: 0.9918 - val_loss: 0.0575 - val_accuracy: 0.9846\n",
            "Epoch 1514/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0321 - accuracy: 0.9913 - val_loss: 0.0540 - val_accuracy: 0.9854\n",
            "Epoch 1515/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0369 - accuracy: 0.9895 - val_loss: 0.0570 - val_accuracy: 0.9854\n",
            "Epoch 1516/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0281 - accuracy: 0.9908 - val_loss: 0.0636 - val_accuracy: 0.9831\n",
            "Epoch 1517/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0308 - accuracy: 0.9905 - val_loss: 0.0580 - val_accuracy: 0.9838\n",
            "Epoch 1518/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0277 - accuracy: 0.9923 - val_loss: 0.0551 - val_accuracy: 0.9854\n",
            "Epoch 1519/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0250 - accuracy: 0.9928 - val_loss: 0.0516 - val_accuracy: 0.9885\n",
            "Epoch 1520/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0235 - accuracy: 0.9931 - val_loss: 0.0552 - val_accuracy: 0.9862\n",
            "Epoch 1521/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0230 - accuracy: 0.9944 - val_loss: 0.0521 - val_accuracy: 0.9869\n",
            "Epoch 1522/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0225 - accuracy: 0.9941 - val_loss: 0.0588 - val_accuracy: 0.9838\n",
            "Epoch 1523/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0262 - accuracy: 0.9915 - val_loss: 0.0546 - val_accuracy: 0.9846\n",
            "Epoch 1524/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0257 - accuracy: 0.9920 - val_loss: 0.0637 - val_accuracy: 0.9800\n",
            "Epoch 1525/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0250 - accuracy: 0.9923 - val_loss: 0.0511 - val_accuracy: 0.9885\n",
            "Epoch 1526/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0230 - accuracy: 0.9938 - val_loss: 0.0503 - val_accuracy: 0.9869\n",
            "Epoch 1527/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0243 - accuracy: 0.9936 - val_loss: 0.0536 - val_accuracy: 0.9854\n",
            "Epoch 1528/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0227 - accuracy: 0.9944 - val_loss: 0.0504 - val_accuracy: 0.9885\n",
            "Epoch 1529/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0232 - accuracy: 0.9941 - val_loss: 0.0554 - val_accuracy: 0.9846\n",
            "Epoch 1530/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0237 - accuracy: 0.9936 - val_loss: 0.0509 - val_accuracy: 0.9869\n",
            "Epoch 1531/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0223 - accuracy: 0.9946 - val_loss: 0.0514 - val_accuracy: 0.9885\n",
            "Epoch 1532/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0220 - accuracy: 0.9951 - val_loss: 0.0564 - val_accuracy: 0.9831\n",
            "Epoch 1533/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0234 - accuracy: 0.9941 - val_loss: 0.0528 - val_accuracy: 0.9869\n",
            "Epoch 1534/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0237 - accuracy: 0.9926 - val_loss: 0.0510 - val_accuracy: 0.9877\n",
            "Epoch 1535/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0227 - accuracy: 0.9936 - val_loss: 0.0551 - val_accuracy: 0.9831\n",
            "Epoch 1536/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0255 - accuracy: 0.9933 - val_loss: 0.0527 - val_accuracy: 0.9885\n",
            "Epoch 1537/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0241 - accuracy: 0.9928 - val_loss: 0.0572 - val_accuracy: 0.9846\n",
            "Epoch 1538/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0269 - accuracy: 0.9908 - val_loss: 0.0515 - val_accuracy: 0.9877\n",
            "Epoch 1539/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0255 - accuracy: 0.9926 - val_loss: 0.0539 - val_accuracy: 0.9862\n",
            "Epoch 1540/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0238 - accuracy: 0.9923 - val_loss: 0.0578 - val_accuracy: 0.9838\n",
            "Epoch 1541/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0246 - accuracy: 0.9938 - val_loss: 0.0523 - val_accuracy: 0.9869\n",
            "Epoch 1542/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0230 - accuracy: 0.9933 - val_loss: 0.0509 - val_accuracy: 0.9877\n",
            "Epoch 1543/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0228 - accuracy: 0.9936 - val_loss: 0.0531 - val_accuracy: 0.9869\n",
            "Epoch 1544/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0229 - accuracy: 0.9938 - val_loss: 0.0513 - val_accuracy: 0.9877\n",
            "Epoch 1545/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0246 - accuracy: 0.9926 - val_loss: 0.0509 - val_accuracy: 0.9885\n",
            "Epoch 1546/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0236 - accuracy: 0.9928 - val_loss: 0.0658 - val_accuracy: 0.9808\n",
            "Epoch 1547/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0251 - accuracy: 0.9920 - val_loss: 0.0516 - val_accuracy: 0.9869\n",
            "Epoch 1548/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0233 - accuracy: 0.9944 - val_loss: 0.0514 - val_accuracy: 0.9885\n",
            "Epoch 1549/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0221 - accuracy: 0.9941 - val_loss: 0.0521 - val_accuracy: 0.9877\n",
            "Epoch 1550/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0226 - accuracy: 0.9938 - val_loss: 0.0517 - val_accuracy: 0.9877\n",
            "Epoch 1551/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0230 - accuracy: 0.9941 - val_loss: 0.0643 - val_accuracy: 0.9815\n",
            "Epoch 1552/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0269 - accuracy: 0.9928 - val_loss: 0.0617 - val_accuracy: 0.9823\n",
            "Epoch 1553/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0282 - accuracy: 0.9908 - val_loss: 0.0614 - val_accuracy: 0.9815\n",
            "Epoch 1554/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0239 - accuracy: 0.9928 - val_loss: 0.0575 - val_accuracy: 0.9869\n",
            "Epoch 1555/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0252 - accuracy: 0.9928 - val_loss: 0.0568 - val_accuracy: 0.9862\n",
            "Epoch 1556/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0267 - accuracy: 0.9918 - val_loss: 0.0510 - val_accuracy: 0.9885\n",
            "Epoch 1557/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0221 - accuracy: 0.9941 - val_loss: 0.0494 - val_accuracy: 0.9877\n",
            "Epoch 1558/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0228 - accuracy: 0.9931 - val_loss: 0.0542 - val_accuracy: 0.9869\n",
            "Epoch 1559/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0237 - accuracy: 0.9936 - val_loss: 0.0524 - val_accuracy: 0.9869\n",
            "Epoch 1560/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0219 - accuracy: 0.9946 - val_loss: 0.0515 - val_accuracy: 0.9877\n",
            "Epoch 1561/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0214 - accuracy: 0.9941 - val_loss: 0.0514 - val_accuracy: 0.9885\n",
            "Epoch 1562/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0232 - accuracy: 0.9941 - val_loss: 0.0533 - val_accuracy: 0.9854\n",
            "Epoch 1563/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0225 - accuracy: 0.9938 - val_loss: 0.0513 - val_accuracy: 0.9877\n",
            "Epoch 1564/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0229 - accuracy: 0.9936 - val_loss: 0.0507 - val_accuracy: 0.9885\n",
            "Epoch 1565/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0231 - accuracy: 0.9933 - val_loss: 0.0557 - val_accuracy: 0.9854\n",
            "Epoch 1566/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0282 - accuracy: 0.9923 - val_loss: 0.0544 - val_accuracy: 0.9892\n",
            "Epoch 1567/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0255 - accuracy: 0.9923 - val_loss: 0.0508 - val_accuracy: 0.9877\n",
            "Epoch 1568/2000\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0229 - accuracy: 0.9936 - val_loss: 0.0572 - val_accuracy: 0.9869\n",
            "Epoch 1569/2000\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0232 - accuracy: 0.9941 - val_loss: 0.0559 - val_accuracy: 0.9831\n",
            "Epoch 1570/2000\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.0230 - accuracy: 0.9944 - val_loss: 0.0538 - val_accuracy: 0.9885\n",
            "Epoch 1571/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0228 - accuracy: 0.9941 - val_loss: 0.0522 - val_accuracy: 0.9877\n",
            "Epoch 1572/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0257 - accuracy: 0.9926 - val_loss: 0.0589 - val_accuracy: 0.9838\n",
            "Epoch 1573/2000\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0259 - accuracy: 0.9915 - val_loss: 0.0523 - val_accuracy: 0.9869\n",
            "Epoch 1574/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0248 - accuracy: 0.9923 - val_loss: 0.0580 - val_accuracy: 0.9831\n",
            "Epoch 1575/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0255 - accuracy: 0.9931 - val_loss: 0.0561 - val_accuracy: 0.9823\n",
            "Epoch 1576/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0257 - accuracy: 0.9938 - val_loss: 0.0524 - val_accuracy: 0.9862\n",
            "Epoch 1577/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0236 - accuracy: 0.9936 - val_loss: 0.0518 - val_accuracy: 0.9869\n",
            "Epoch 1578/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0220 - accuracy: 0.9941 - val_loss: 0.0506 - val_accuracy: 0.9885\n",
            "Epoch 1579/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0224 - accuracy: 0.9949 - val_loss: 0.0572 - val_accuracy: 0.9846\n",
            "Epoch 1580/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0248 - accuracy: 0.9926 - val_loss: 0.0535 - val_accuracy: 0.9854\n",
            "Epoch 1581/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0234 - accuracy: 0.9933 - val_loss: 0.0508 - val_accuracy: 0.9869\n",
            "Epoch 1582/2000\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.0222 - accuracy: 0.9941 - val_loss: 0.0517 - val_accuracy: 0.9869\n",
            "Epoch 1583/2000\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.0225 - accuracy: 0.9936 - val_loss: 0.0509 - val_accuracy: 0.9885\n",
            "Epoch 1584/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0221 - accuracy: 0.9951 - val_loss: 0.0496 - val_accuracy: 0.9885\n",
            "Epoch 1585/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0221 - accuracy: 0.9946 - val_loss: 0.0505 - val_accuracy: 0.9877\n",
            "Epoch 1586/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0219 - accuracy: 0.9946 - val_loss: 0.0509 - val_accuracy: 0.9869\n",
            "Epoch 1587/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0223 - accuracy: 0.9946 - val_loss: 0.0521 - val_accuracy: 0.9877\n",
            "Epoch 1588/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0229 - accuracy: 0.9941 - val_loss: 0.0543 - val_accuracy: 0.9869\n",
            "Epoch 1589/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0236 - accuracy: 0.9928 - val_loss: 0.0535 - val_accuracy: 0.9854\n",
            "Epoch 1590/2000\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0231 - accuracy: 0.9933 - val_loss: 0.0564 - val_accuracy: 0.9831\n",
            "Epoch 1591/2000\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0230 - accuracy: 0.9941 - val_loss: 0.0527 - val_accuracy: 0.9877\n",
            "Epoch 1592/2000\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.0233 - accuracy: 0.9936 - val_loss: 0.0511 - val_accuracy: 0.9877\n",
            "Epoch 1593/2000\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0228 - accuracy: 0.9941 - val_loss: 0.0519 - val_accuracy: 0.9885\n",
            "Epoch 1594/2000\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.0222 - accuracy: 0.9941 - val_loss: 0.0525 - val_accuracy: 0.9892\n",
            "Epoch 1595/2000\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0232 - accuracy: 0.9946 - val_loss: 0.0505 - val_accuracy: 0.9869\n",
            "Epoch 1596/2000\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.0217 - accuracy: 0.9931 - val_loss: 0.0511 - val_accuracy: 0.9885\n",
            "Epoch 1597/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0218 - accuracy: 0.9946 - val_loss: 0.0506 - val_accuracy: 0.9885\n",
            "Epoch 1598/2000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0216 - accuracy: 0.9946 - val_loss: 0.0541 - val_accuracy: 0.9854\n",
            "Epoch 1599/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0222 - accuracy: 0.9944 - val_loss: 0.0521 - val_accuracy: 0.9877\n",
            "Epoch 1600/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0230 - accuracy: 0.9938 - val_loss: 0.0526 - val_accuracy: 0.9862\n",
            "Epoch 1601/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0231 - accuracy: 0.9933 - val_loss: 0.0497 - val_accuracy: 0.9885\n",
            "Epoch 1602/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0240 - accuracy: 0.9933 - val_loss: 0.0514 - val_accuracy: 0.9877\n",
            "Epoch 1603/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0240 - accuracy: 0.9923 - val_loss: 0.0526 - val_accuracy: 0.9869\n",
            "Epoch 1604/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0226 - accuracy: 0.9941 - val_loss: 0.0520 - val_accuracy: 0.9869\n",
            "Epoch 1605/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0230 - accuracy: 0.9944 - val_loss: 0.0527 - val_accuracy: 0.9877\n",
            "Epoch 1606/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0219 - accuracy: 0.9941 - val_loss: 0.0514 - val_accuracy: 0.9885\n",
            "Epoch 1607/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0220 - accuracy: 0.9944 - val_loss: 0.0514 - val_accuracy: 0.9869\n",
            "Epoch 1608/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0218 - accuracy: 0.9941 - val_loss: 0.0507 - val_accuracy: 0.9885\n",
            "Epoch 1609/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0225 - accuracy: 0.9938 - val_loss: 0.0520 - val_accuracy: 0.9877\n",
            "Epoch 1610/2000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0218 - accuracy: 0.9933 - val_loss: 0.0540 - val_accuracy: 0.9877\n",
            "Epoch 1611/2000\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.0228 - accuracy: 0.9941 - val_loss: 0.0503 - val_accuracy: 0.9900\n",
            "Epoch 1612/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0231 - accuracy: 0.9931 - val_loss: 0.0515 - val_accuracy: 0.9885\n",
            "Epoch 1613/2000\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0221 - accuracy: 0.9938 - val_loss: 0.0539 - val_accuracy: 0.9846\n",
            "Epoch 1614/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0230 - accuracy: 0.9941 - val_loss: 0.0538 - val_accuracy: 0.9869\n",
            "Epoch 1615/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0236 - accuracy: 0.9941 - val_loss: 0.0516 - val_accuracy: 0.9862\n",
            "Epoch 1616/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0235 - accuracy: 0.9938 - val_loss: 0.0521 - val_accuracy: 0.9885\n",
            "Epoch 1617/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0237 - accuracy: 0.9938 - val_loss: 0.0535 - val_accuracy: 0.9862\n",
            "Epoch 1618/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0226 - accuracy: 0.9946 - val_loss: 0.0518 - val_accuracy: 0.9877\n",
            "Epoch 1619/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0228 - accuracy: 0.9951 - val_loss: 0.0515 - val_accuracy: 0.9885\n",
            "Epoch 1620/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0243 - accuracy: 0.9949 - val_loss: 0.0516 - val_accuracy: 0.9885\n",
            "Epoch 1621/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0237 - accuracy: 0.9941 - val_loss: 0.0508 - val_accuracy: 0.9885\n",
            "Epoch 1622/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0246 - accuracy: 0.9931 - val_loss: 0.0518 - val_accuracy: 0.9877\n",
            "Epoch 1623/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0240 - accuracy: 0.9936 - val_loss: 0.0522 - val_accuracy: 0.9885\n",
            "Epoch 1624/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0228 - accuracy: 0.9933 - val_loss: 0.0510 - val_accuracy: 0.9869\n",
            "Epoch 1625/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0216 - accuracy: 0.9938 - val_loss: 0.0518 - val_accuracy: 0.9877\n",
            "Epoch 1626/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0233 - accuracy: 0.9933 - val_loss: 0.0523 - val_accuracy: 0.9877\n",
            "Epoch 1627/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0215 - accuracy: 0.9944 - val_loss: 0.0554 - val_accuracy: 0.9831\n",
            "Epoch 1628/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0224 - accuracy: 0.9949 - val_loss: 0.0504 - val_accuracy: 0.9892\n",
            "Epoch 1629/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0218 - accuracy: 0.9941 - val_loss: 0.0503 - val_accuracy: 0.9885\n",
            "Epoch 1630/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0225 - accuracy: 0.9944 - val_loss: 0.0541 - val_accuracy: 0.9869\n",
            "Epoch 1631/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0270 - accuracy: 0.9926 - val_loss: 0.0671 - val_accuracy: 0.9815\n",
            "Epoch 1632/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0305 - accuracy: 0.9897 - val_loss: 0.0708 - val_accuracy: 0.9800\n",
            "Epoch 1633/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0311 - accuracy: 0.9900 - val_loss: 0.0562 - val_accuracy: 0.9846\n",
            "Epoch 1634/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0264 - accuracy: 0.9931 - val_loss: 0.0535 - val_accuracy: 0.9862\n",
            "Epoch 1635/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0250 - accuracy: 0.9931 - val_loss: 0.0528 - val_accuracy: 0.9877\n",
            "Epoch 1636/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0239 - accuracy: 0.9931 - val_loss: 0.0558 - val_accuracy: 0.9877\n",
            "Epoch 1637/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0227 - accuracy: 0.9951 - val_loss: 0.0549 - val_accuracy: 0.9846\n",
            "Epoch 1638/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0233 - accuracy: 0.9938 - val_loss: 0.0542 - val_accuracy: 0.9854\n",
            "Epoch 1639/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0227 - accuracy: 0.9949 - val_loss: 0.0511 - val_accuracy: 0.9877\n",
            "Epoch 1640/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0225 - accuracy: 0.9938 - val_loss: 0.0519 - val_accuracy: 0.9877\n",
            "Epoch 1641/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0230 - accuracy: 0.9944 - val_loss: 0.0522 - val_accuracy: 0.9885\n",
            "Epoch 1642/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0221 - accuracy: 0.9944 - val_loss: 0.0511 - val_accuracy: 0.9885\n",
            "Epoch 1643/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0214 - accuracy: 0.9946 - val_loss: 0.0571 - val_accuracy: 0.9838\n",
            "Epoch 1644/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0229 - accuracy: 0.9944 - val_loss: 0.0523 - val_accuracy: 0.9885\n",
            "Epoch 1645/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0230 - accuracy: 0.9936 - val_loss: 0.0539 - val_accuracy: 0.9869\n",
            "Epoch 1646/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0249 - accuracy: 0.9933 - val_loss: 0.0567 - val_accuracy: 0.9831\n",
            "Epoch 1647/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0282 - accuracy: 0.9910 - val_loss: 0.0614 - val_accuracy: 0.9838\n",
            "Epoch 1648/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0258 - accuracy: 0.9926 - val_loss: 0.0629 - val_accuracy: 0.9815\n",
            "Epoch 1649/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0238 - accuracy: 0.9920 - val_loss: 0.0527 - val_accuracy: 0.9885\n",
            "Epoch 1650/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0217 - accuracy: 0.9944 - val_loss: 0.0519 - val_accuracy: 0.9892\n",
            "Epoch 1651/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0216 - accuracy: 0.9949 - val_loss: 0.0567 - val_accuracy: 0.9831\n",
            "Epoch 1652/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0238 - accuracy: 0.9928 - val_loss: 0.0520 - val_accuracy: 0.9877\n",
            "Epoch 1653/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0272 - accuracy: 0.9920 - val_loss: 0.0545 - val_accuracy: 0.9854\n",
            "Epoch 1654/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0292 - accuracy: 0.9918 - val_loss: 0.0527 - val_accuracy: 0.9862\n",
            "Epoch 1655/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0261 - accuracy: 0.9918 - val_loss: 0.0521 - val_accuracy: 0.9877\n",
            "Epoch 1656/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0239 - accuracy: 0.9936 - val_loss: 0.0519 - val_accuracy: 0.9877\n",
            "Epoch 1657/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0217 - accuracy: 0.9938 - val_loss: 0.0520 - val_accuracy: 0.9877\n",
            "Epoch 1658/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0224 - accuracy: 0.9944 - val_loss: 0.0506 - val_accuracy: 0.9892\n",
            "Epoch 1659/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0217 - accuracy: 0.9954 - val_loss: 0.0511 - val_accuracy: 0.9885\n",
            "Epoch 1660/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0224 - accuracy: 0.9944 - val_loss: 0.0532 - val_accuracy: 0.9862\n",
            "Epoch 1661/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0224 - accuracy: 0.9938 - val_loss: 0.0534 - val_accuracy: 0.9869\n",
            "Epoch 1662/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0226 - accuracy: 0.9941 - val_loss: 0.0518 - val_accuracy: 0.9885\n",
            "Epoch 1663/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0218 - accuracy: 0.9941 - val_loss: 0.0507 - val_accuracy: 0.9885\n",
            "Epoch 1664/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0221 - accuracy: 0.9944 - val_loss: 0.0506 - val_accuracy: 0.9892\n",
            "Epoch 1665/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0226 - accuracy: 0.9933 - val_loss: 0.0594 - val_accuracy: 0.9831\n",
            "Epoch 1666/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0242 - accuracy: 0.9931 - val_loss: 0.0534 - val_accuracy: 0.9869\n",
            "Epoch 1667/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0218 - accuracy: 0.9954 - val_loss: 0.0518 - val_accuracy: 0.9877\n",
            "Epoch 1668/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0234 - accuracy: 0.9933 - val_loss: 0.0529 - val_accuracy: 0.9869\n",
            "Epoch 1669/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0221 - accuracy: 0.9944 - val_loss: 0.0528 - val_accuracy: 0.9869\n",
            "Epoch 1670/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0221 - accuracy: 0.9933 - val_loss: 0.0507 - val_accuracy: 0.9885\n",
            "Epoch 1671/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0224 - accuracy: 0.9938 - val_loss: 0.0521 - val_accuracy: 0.9869\n",
            "Epoch 1672/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0211 - accuracy: 0.9949 - val_loss: 0.0525 - val_accuracy: 0.9869\n",
            "Epoch 1673/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0225 - accuracy: 0.9941 - val_loss: 0.0508 - val_accuracy: 0.9885\n",
            "Epoch 1674/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0216 - accuracy: 0.9946 - val_loss: 0.0505 - val_accuracy: 0.9877\n",
            "Epoch 1675/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0212 - accuracy: 0.9951 - val_loss: 0.0505 - val_accuracy: 0.9892\n",
            "Epoch 1676/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0215 - accuracy: 0.9944 - val_loss: 0.0529 - val_accuracy: 0.9877\n",
            "Epoch 1677/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0244 - accuracy: 0.9936 - val_loss: 0.0516 - val_accuracy: 0.9892\n",
            "Epoch 1678/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0227 - accuracy: 0.9933 - val_loss: 0.0525 - val_accuracy: 0.9877\n",
            "Epoch 1679/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0221 - accuracy: 0.9944 - val_loss: 0.0523 - val_accuracy: 0.9877\n",
            "Epoch 1680/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0229 - accuracy: 0.9931 - val_loss: 0.0570 - val_accuracy: 0.9823\n",
            "Epoch 1681/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0227 - accuracy: 0.9938 - val_loss: 0.0522 - val_accuracy: 0.9892\n",
            "Epoch 1682/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0236 - accuracy: 0.9936 - val_loss: 0.0531 - val_accuracy: 0.9892\n",
            "Epoch 1683/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0234 - accuracy: 0.9931 - val_loss: 0.0525 - val_accuracy: 0.9862\n",
            "Epoch 1684/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9928 - val_loss: 0.0529 - val_accuracy: 0.9869\n",
            "Epoch 1685/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0232 - accuracy: 0.9926 - val_loss: 0.0522 - val_accuracy: 0.9869\n",
            "Epoch 1686/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0242 - accuracy: 0.9936 - val_loss: 0.0529 - val_accuracy: 0.9877\n",
            "Epoch 1687/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0239 - accuracy: 0.9938 - val_loss: 0.0518 - val_accuracy: 0.9869\n",
            "Epoch 1688/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0221 - accuracy: 0.9936 - val_loss: 0.0509 - val_accuracy: 0.9877\n",
            "Epoch 1689/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0211 - accuracy: 0.9949 - val_loss: 0.0527 - val_accuracy: 0.9877\n",
            "Epoch 1690/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0224 - accuracy: 0.9944 - val_loss: 0.0510 - val_accuracy: 0.9892\n",
            "Epoch 1691/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0215 - accuracy: 0.9941 - val_loss: 0.0511 - val_accuracy: 0.9885\n",
            "Epoch 1692/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0215 - accuracy: 0.9941 - val_loss: 0.0539 - val_accuracy: 0.9846\n",
            "Epoch 1693/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0216 - accuracy: 0.9936 - val_loss: 0.0510 - val_accuracy: 0.9885\n",
            "Epoch 1694/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0218 - accuracy: 0.9938 - val_loss: 0.0510 - val_accuracy: 0.9885\n",
            "Epoch 1695/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0214 - accuracy: 0.9949 - val_loss: 0.0506 - val_accuracy: 0.9885\n",
            "Epoch 1696/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0219 - accuracy: 0.9941 - val_loss: 0.0514 - val_accuracy: 0.9892\n",
            "Epoch 1697/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0220 - accuracy: 0.9936 - val_loss: 0.0528 - val_accuracy: 0.9885\n",
            "Epoch 1698/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0221 - accuracy: 0.9941 - val_loss: 0.0617 - val_accuracy: 0.9808\n",
            "Epoch 1699/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0217 - accuracy: 0.9941 - val_loss: 0.0512 - val_accuracy: 0.9877\n",
            "Epoch 1700/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0215 - accuracy: 0.9944 - val_loss: 0.0507 - val_accuracy: 0.9877\n",
            "Epoch 1701/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0213 - accuracy: 0.9944 - val_loss: 0.0508 - val_accuracy: 0.9869\n",
            "Epoch 1702/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0237 - accuracy: 0.9933 - val_loss: 0.0530 - val_accuracy: 0.9869\n",
            "Epoch 1703/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0227 - accuracy: 0.9933 - val_loss: 0.0581 - val_accuracy: 0.9846\n",
            "Epoch 1704/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0235 - accuracy: 0.9941 - val_loss: 0.0512 - val_accuracy: 0.9877\n",
            "Epoch 1705/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0223 - accuracy: 0.9938 - val_loss: 0.0531 - val_accuracy: 0.9869\n",
            "Epoch 1706/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0232 - accuracy: 0.9933 - val_loss: 0.0507 - val_accuracy: 0.9877\n",
            "Epoch 1707/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0239 - accuracy: 0.9928 - val_loss: 0.0531 - val_accuracy: 0.9877\n",
            "Epoch 1708/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0238 - accuracy: 0.9936 - val_loss: 0.0497 - val_accuracy: 0.9892\n",
            "Epoch 1709/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0221 - accuracy: 0.9941 - val_loss: 0.0514 - val_accuracy: 0.9869\n",
            "Epoch 1710/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0214 - accuracy: 0.9941 - val_loss: 0.0500 - val_accuracy: 0.9877\n",
            "Epoch 1711/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0212 - accuracy: 0.9944 - val_loss: 0.0509 - val_accuracy: 0.9892\n",
            "Epoch 1712/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0221 - accuracy: 0.9944 - val_loss: 0.0534 - val_accuracy: 0.9862\n",
            "Epoch 1713/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0222 - accuracy: 0.9946 - val_loss: 0.0527 - val_accuracy: 0.9877\n",
            "Epoch 1714/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0221 - accuracy: 0.9938 - val_loss: 0.0510 - val_accuracy: 0.9877\n",
            "Epoch 1715/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0214 - accuracy: 0.9949 - val_loss: 0.0551 - val_accuracy: 0.9854\n",
            "Epoch 1716/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0233 - accuracy: 0.9941 - val_loss: 0.0571 - val_accuracy: 0.9846\n",
            "Epoch 1717/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0249 - accuracy: 0.9920 - val_loss: 0.0576 - val_accuracy: 0.9846\n",
            "Epoch 1718/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0239 - accuracy: 0.9936 - val_loss: 0.0639 - val_accuracy: 0.9831\n",
            "Epoch 1719/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0259 - accuracy: 0.9920 - val_loss: 0.0547 - val_accuracy: 0.9831\n",
            "Epoch 1720/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0240 - accuracy: 0.9931 - val_loss: 0.0522 - val_accuracy: 0.9869\n",
            "Epoch 1721/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0213 - accuracy: 0.9938 - val_loss: 0.0543 - val_accuracy: 0.9862\n",
            "Epoch 1722/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0217 - accuracy: 0.9944 - val_loss: 0.0549 - val_accuracy: 0.9862\n",
            "Epoch 1723/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0221 - accuracy: 0.9941 - val_loss: 0.0529 - val_accuracy: 0.9862\n",
            "Epoch 1724/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0222 - accuracy: 0.9941 - val_loss: 0.0500 - val_accuracy: 0.9885\n",
            "Epoch 1725/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0236 - accuracy: 0.9941 - val_loss: 0.0505 - val_accuracy: 0.9885\n",
            "Epoch 1726/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0218 - accuracy: 0.9944 - val_loss: 0.0503 - val_accuracy: 0.9892\n",
            "Epoch 1727/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0225 - accuracy: 0.9931 - val_loss: 0.0655 - val_accuracy: 0.9831\n",
            "Epoch 1728/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0267 - accuracy: 0.9920 - val_loss: 0.0752 - val_accuracy: 0.9777\n",
            "Epoch 1729/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0284 - accuracy: 0.9926 - val_loss: 0.0591 - val_accuracy: 0.9846\n",
            "Epoch 1730/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0252 - accuracy: 0.9938 - val_loss: 0.0521 - val_accuracy: 0.9877\n",
            "Epoch 1731/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0245 - accuracy: 0.9933 - val_loss: 0.0522 - val_accuracy: 0.9892\n",
            "Epoch 1732/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0234 - accuracy: 0.9944 - val_loss: 0.0518 - val_accuracy: 0.9877\n",
            "Epoch 1733/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0228 - accuracy: 0.9944 - val_loss: 0.0511 - val_accuracy: 0.9900\n",
            "Epoch 1734/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0215 - accuracy: 0.9949 - val_loss: 0.0509 - val_accuracy: 0.9900\n",
            "Epoch 1735/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0227 - accuracy: 0.9938 - val_loss: 0.0525 - val_accuracy: 0.9869\n",
            "Epoch 1736/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0213 - accuracy: 0.9944 - val_loss: 0.0506 - val_accuracy: 0.9877\n",
            "Epoch 1737/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0215 - accuracy: 0.9946 - val_loss: 0.0513 - val_accuracy: 0.9885\n",
            "Epoch 1738/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0223 - accuracy: 0.9944 - val_loss: 0.0512 - val_accuracy: 0.9885\n",
            "Epoch 1739/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0213 - accuracy: 0.9941 - val_loss: 0.0520 - val_accuracy: 0.9869\n",
            "Epoch 1740/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0219 - accuracy: 0.9944 - val_loss: 0.0514 - val_accuracy: 0.9885\n",
            "Epoch 1741/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0236 - accuracy: 0.9936 - val_loss: 0.0517 - val_accuracy: 0.9877\n",
            "Epoch 1742/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0216 - accuracy: 0.9941 - val_loss: 0.0536 - val_accuracy: 0.9869\n",
            "Epoch 1743/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0214 - accuracy: 0.9941 - val_loss: 0.0519 - val_accuracy: 0.9885\n",
            "Epoch 1744/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0223 - accuracy: 0.9941 - val_loss: 0.0506 - val_accuracy: 0.9885\n",
            "Epoch 1745/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0218 - accuracy: 0.9938 - val_loss: 0.0535 - val_accuracy: 0.9877\n",
            "Epoch 1746/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0220 - accuracy: 0.9931 - val_loss: 0.0510 - val_accuracy: 0.9877\n",
            "Epoch 1747/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0238 - accuracy: 0.9931 - val_loss: 0.0651 - val_accuracy: 0.9823\n",
            "Epoch 1748/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0236 - accuracy: 0.9928 - val_loss: 0.0511 - val_accuracy: 0.9869\n",
            "Epoch 1749/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0226 - accuracy: 0.9944 - val_loss: 0.0503 - val_accuracy: 0.9877\n",
            "Epoch 1750/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0207 - accuracy: 0.9944 - val_loss: 0.0519 - val_accuracy: 0.9885\n",
            "Epoch 1751/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0219 - accuracy: 0.9933 - val_loss: 0.0520 - val_accuracy: 0.9877\n",
            "Epoch 1752/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0231 - accuracy: 0.9933 - val_loss: 0.0587 - val_accuracy: 0.9808\n",
            "Epoch 1753/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0238 - accuracy: 0.9933 - val_loss: 0.0580 - val_accuracy: 0.9846\n",
            "Epoch 1754/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0239 - accuracy: 0.9920 - val_loss: 0.0516 - val_accuracy: 0.9877\n",
            "Epoch 1755/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0219 - accuracy: 0.9944 - val_loss: 0.0524 - val_accuracy: 0.9877\n",
            "Epoch 1756/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0221 - accuracy: 0.9941 - val_loss: 0.0546 - val_accuracy: 0.9854\n",
            "Epoch 1757/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0240 - accuracy: 0.9938 - val_loss: 0.0564 - val_accuracy: 0.9854\n",
            "Epoch 1758/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0239 - accuracy: 0.9938 - val_loss: 0.0515 - val_accuracy: 0.9885\n",
            "Epoch 1759/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0220 - accuracy: 0.9941 - val_loss: 0.0516 - val_accuracy: 0.9885\n",
            "Epoch 1760/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0216 - accuracy: 0.9946 - val_loss: 0.0519 - val_accuracy: 0.9885\n",
            "Epoch 1761/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0225 - accuracy: 0.9938 - val_loss: 0.0516 - val_accuracy: 0.9885\n",
            "Epoch 1762/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0212 - accuracy: 0.9949 - val_loss: 0.0515 - val_accuracy: 0.9877\n",
            "Epoch 1763/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0218 - accuracy: 0.9944 - val_loss: 0.0524 - val_accuracy: 0.9877\n",
            "Epoch 1764/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0211 - accuracy: 0.9946 - val_loss: 0.0501 - val_accuracy: 0.9869\n",
            "Epoch 1765/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0214 - accuracy: 0.9949 - val_loss: 0.0523 - val_accuracy: 0.9862\n",
            "Epoch 1766/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0218 - accuracy: 0.9944 - val_loss: 0.0565 - val_accuracy: 0.9838\n",
            "Epoch 1767/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0237 - accuracy: 0.9931 - val_loss: 0.0583 - val_accuracy: 0.9838\n",
            "Epoch 1768/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0237 - accuracy: 0.9936 - val_loss: 0.0542 - val_accuracy: 0.9846\n",
            "Epoch 1769/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0239 - accuracy: 0.9933 - val_loss: 0.0521 - val_accuracy: 0.9877\n",
            "Epoch 1770/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0235 - accuracy: 0.9933 - val_loss: 0.0539 - val_accuracy: 0.9869\n",
            "Epoch 1771/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0229 - accuracy: 0.9936 - val_loss: 0.0528 - val_accuracy: 0.9892\n",
            "Epoch 1772/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0247 - accuracy: 0.9913 - val_loss: 0.0508 - val_accuracy: 0.9877\n",
            "Epoch 1773/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0236 - accuracy: 0.9928 - val_loss: 0.0514 - val_accuracy: 0.9877\n",
            "Epoch 1774/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0217 - accuracy: 0.9949 - val_loss: 0.0520 - val_accuracy: 0.9892\n",
            "Epoch 1775/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0227 - accuracy: 0.9933 - val_loss: 0.0520 - val_accuracy: 0.9877\n",
            "Epoch 1776/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0215 - accuracy: 0.9946 - val_loss: 0.0506 - val_accuracy: 0.9892\n",
            "Epoch 1777/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0223 - accuracy: 0.9938 - val_loss: 0.0524 - val_accuracy: 0.9854\n",
            "Epoch 1778/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0233 - accuracy: 0.9933 - val_loss: 0.0550 - val_accuracy: 0.9838\n",
            "Epoch 1779/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0215 - accuracy: 0.9949 - val_loss: 0.0515 - val_accuracy: 0.9885\n",
            "Epoch 1780/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0211 - accuracy: 0.9951 - val_loss: 0.0519 - val_accuracy: 0.9885\n",
            "Epoch 1781/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0223 - accuracy: 0.9933 - val_loss: 0.0518 - val_accuracy: 0.9885\n",
            "Epoch 1782/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0271 - accuracy: 0.9918 - val_loss: 0.0594 - val_accuracy: 0.9831\n",
            "Epoch 1783/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0261 - accuracy: 0.9915 - val_loss: 0.0525 - val_accuracy: 0.9869\n",
            "Epoch 1784/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0254 - accuracy: 0.9933 - val_loss: 0.0597 - val_accuracy: 0.9808\n",
            "Epoch 1785/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0236 - accuracy: 0.9923 - val_loss: 0.0545 - val_accuracy: 0.9862\n",
            "Epoch 1786/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0238 - accuracy: 0.9933 - val_loss: 0.0512 - val_accuracy: 0.9885\n",
            "Epoch 1787/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0223 - accuracy: 0.9946 - val_loss: 0.0508 - val_accuracy: 0.9877\n",
            "Epoch 1788/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0217 - accuracy: 0.9949 - val_loss: 0.0506 - val_accuracy: 0.9869\n",
            "Epoch 1789/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0248 - accuracy: 0.9933 - val_loss: 0.0568 - val_accuracy: 0.9862\n",
            "Epoch 1790/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0252 - accuracy: 0.9926 - val_loss: 0.0525 - val_accuracy: 0.9885\n",
            "Epoch 1791/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0228 - accuracy: 0.9936 - val_loss: 0.0535 - val_accuracy: 0.9885\n",
            "Epoch 1792/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0228 - accuracy: 0.9936 - val_loss: 0.0550 - val_accuracy: 0.9854\n",
            "Epoch 1793/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0216 - accuracy: 0.9946 - val_loss: 0.0536 - val_accuracy: 0.9877\n",
            "Epoch 1794/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0225 - accuracy: 0.9931 - val_loss: 0.0511 - val_accuracy: 0.9892\n",
            "Epoch 1795/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0233 - accuracy: 0.9949 - val_loss: 0.0557 - val_accuracy: 0.9862\n",
            "Epoch 1796/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0212 - accuracy: 0.9941 - val_loss: 0.0519 - val_accuracy: 0.9869\n",
            "Epoch 1797/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0214 - accuracy: 0.9944 - val_loss: 0.0508 - val_accuracy: 0.9885\n",
            "Epoch 1798/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0249 - accuracy: 0.9933 - val_loss: 0.0592 - val_accuracy: 0.9823\n",
            "Epoch 1799/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0289 - accuracy: 0.9895 - val_loss: 0.0651 - val_accuracy: 0.9815\n",
            "Epoch 1800/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0290 - accuracy: 0.9923 - val_loss: 0.0551 - val_accuracy: 0.9862\n",
            "Epoch 1801/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0345 - accuracy: 0.9885 - val_loss: 0.0576 - val_accuracy: 0.9838\n",
            "Epoch 1802/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0346 - accuracy: 0.9895 - val_loss: 0.0612 - val_accuracy: 0.9846\n",
            "Epoch 1803/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0308 - accuracy: 0.9905 - val_loss: 0.0881 - val_accuracy: 0.9692\n",
            "Epoch 1804/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0341 - accuracy: 0.9885 - val_loss: 0.0627 - val_accuracy: 0.9862\n",
            "Epoch 1805/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0241 - accuracy: 0.9941 - val_loss: 0.0569 - val_accuracy: 0.9869\n",
            "Epoch 1806/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0247 - accuracy: 0.9931 - val_loss: 0.0569 - val_accuracy: 0.9854\n",
            "Epoch 1807/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0247 - accuracy: 0.9926 - val_loss: 0.0589 - val_accuracy: 0.9815\n",
            "Epoch 1808/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0229 - accuracy: 0.9926 - val_loss: 0.0582 - val_accuracy: 0.9869\n",
            "Epoch 1809/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0270 - accuracy: 0.9933 - val_loss: 0.0552 - val_accuracy: 0.9877\n",
            "Epoch 1810/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0245 - accuracy: 0.9936 - val_loss: 0.0551 - val_accuracy: 0.9862\n",
            "Epoch 1811/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0220 - accuracy: 0.9938 - val_loss: 0.0593 - val_accuracy: 0.9831\n",
            "Epoch 1812/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0223 - accuracy: 0.9949 - val_loss: 0.0536 - val_accuracy: 0.9869\n",
            "Epoch 1813/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0210 - accuracy: 0.9946 - val_loss: 0.0525 - val_accuracy: 0.9885\n",
            "Epoch 1814/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0215 - accuracy: 0.9944 - val_loss: 0.0532 - val_accuracy: 0.9846\n",
            "Epoch 1815/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0219 - accuracy: 0.9936 - val_loss: 0.0544 - val_accuracy: 0.9846\n",
            "Epoch 1816/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0241 - accuracy: 0.9926 - val_loss: 0.0521 - val_accuracy: 0.9862\n",
            "Epoch 1817/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0249 - accuracy: 0.9936 - val_loss: 0.0545 - val_accuracy: 0.9877\n",
            "Epoch 1818/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0224 - accuracy: 0.9926 - val_loss: 0.0525 - val_accuracy: 0.9877\n",
            "Epoch 1819/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0220 - accuracy: 0.9944 - val_loss: 0.0507 - val_accuracy: 0.9877\n",
            "Epoch 1820/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0211 - accuracy: 0.9946 - val_loss: 0.0517 - val_accuracy: 0.9877\n",
            "Epoch 1821/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0237 - accuracy: 0.9931 - val_loss: 0.0531 - val_accuracy: 0.9854\n",
            "Epoch 1822/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0260 - accuracy: 0.9918 - val_loss: 0.0626 - val_accuracy: 0.9831\n",
            "Epoch 1823/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0252 - accuracy: 0.9920 - val_loss: 0.0555 - val_accuracy: 0.9846\n",
            "Epoch 1824/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0244 - accuracy: 0.9931 - val_loss: 0.0585 - val_accuracy: 0.9838\n",
            "Epoch 1825/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0248 - accuracy: 0.9926 - val_loss: 0.0546 - val_accuracy: 0.9869\n",
            "Epoch 1826/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0283 - accuracy: 0.9928 - val_loss: 0.0528 - val_accuracy: 0.9869\n",
            "Epoch 1827/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0238 - accuracy: 0.9944 - val_loss: 0.0534 - val_accuracy: 0.9854\n",
            "Epoch 1828/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0232 - accuracy: 0.9938 - val_loss: 0.0627 - val_accuracy: 0.9831\n",
            "Epoch 1829/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0240 - accuracy: 0.9928 - val_loss: 0.0514 - val_accuracy: 0.9892\n",
            "Epoch 1830/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0208 - accuracy: 0.9944 - val_loss: 0.0517 - val_accuracy: 0.9885\n",
            "Epoch 1831/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0214 - accuracy: 0.9938 - val_loss: 0.0490 - val_accuracy: 0.9885\n",
            "Epoch 1832/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0215 - accuracy: 0.9946 - val_loss: 0.0548 - val_accuracy: 0.9846\n",
            "Epoch 1833/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0234 - accuracy: 0.9920 - val_loss: 0.0499 - val_accuracy: 0.9885\n",
            "Epoch 1834/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0238 - accuracy: 0.9933 - val_loss: 0.0540 - val_accuracy: 0.9862\n",
            "Epoch 1835/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0204 - accuracy: 0.9938 - val_loss: 0.0571 - val_accuracy: 0.9808\n",
            "Epoch 1836/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0220 - accuracy: 0.9936 - val_loss: 0.0528 - val_accuracy: 0.9877\n",
            "Epoch 1837/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0218 - accuracy: 0.9941 - val_loss: 0.0513 - val_accuracy: 0.9869\n",
            "Epoch 1838/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0230 - accuracy: 0.9938 - val_loss: 0.0526 - val_accuracy: 0.9885\n",
            "Epoch 1839/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0218 - accuracy: 0.9946 - val_loss: 0.0508 - val_accuracy: 0.9877\n",
            "Epoch 1840/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0221 - accuracy: 0.9936 - val_loss: 0.0539 - val_accuracy: 0.9846\n",
            "Epoch 1841/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0215 - accuracy: 0.9944 - val_loss: 0.0527 - val_accuracy: 0.9877\n",
            "Epoch 1842/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0221 - accuracy: 0.9949 - val_loss: 0.0512 - val_accuracy: 0.9885\n",
            "Epoch 1843/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0212 - accuracy: 0.9946 - val_loss: 0.0506 - val_accuracy: 0.9892\n",
            "Epoch 1844/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0225 - accuracy: 0.9936 - val_loss: 0.0524 - val_accuracy: 0.9877\n",
            "Epoch 1845/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0212 - accuracy: 0.9944 - val_loss: 0.0556 - val_accuracy: 0.9862\n",
            "Epoch 1846/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0219 - accuracy: 0.9946 - val_loss: 0.0550 - val_accuracy: 0.9862\n",
            "Epoch 1847/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0226 - accuracy: 0.9946 - val_loss: 0.0568 - val_accuracy: 0.9838\n",
            "Epoch 1848/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0220 - accuracy: 0.9941 - val_loss: 0.0510 - val_accuracy: 0.9885\n",
            "Epoch 1849/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0214 - accuracy: 0.9944 - val_loss: 0.0532 - val_accuracy: 0.9877\n",
            "Epoch 1850/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0212 - accuracy: 0.9949 - val_loss: 0.0526 - val_accuracy: 0.9877\n",
            "Epoch 1851/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0228 - accuracy: 0.9938 - val_loss: 0.0507 - val_accuracy: 0.9885\n",
            "Epoch 1852/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0223 - accuracy: 0.9941 - val_loss: 0.0509 - val_accuracy: 0.9892\n",
            "Epoch 1853/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0218 - accuracy: 0.9946 - val_loss: 0.0530 - val_accuracy: 0.9885\n",
            "Epoch 1854/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0218 - accuracy: 0.9936 - val_loss: 0.0507 - val_accuracy: 0.9885\n",
            "Epoch 1855/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0212 - accuracy: 0.9944 - val_loss: 0.0510 - val_accuracy: 0.9877\n",
            "Epoch 1856/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0209 - accuracy: 0.9949 - val_loss: 0.0497 - val_accuracy: 0.9877\n",
            "Epoch 1857/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0208 - accuracy: 0.9949 - val_loss: 0.0514 - val_accuracy: 0.9892\n",
            "Epoch 1858/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0210 - accuracy: 0.9946 - val_loss: 0.0516 - val_accuracy: 0.9885\n",
            "Epoch 1859/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0212 - accuracy: 0.9944 - val_loss: 0.0513 - val_accuracy: 0.9877\n",
            "Epoch 1860/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0208 - accuracy: 0.9951 - val_loss: 0.0503 - val_accuracy: 0.9885\n",
            "Epoch 1861/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0211 - accuracy: 0.9944 - val_loss: 0.0505 - val_accuracy: 0.9892\n",
            "Epoch 1862/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0218 - accuracy: 0.9941 - val_loss: 0.0532 - val_accuracy: 0.9869\n",
            "Epoch 1863/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0221 - accuracy: 0.9941 - val_loss: 0.0549 - val_accuracy: 0.9846\n",
            "Epoch 1864/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0223 - accuracy: 0.9938 - val_loss: 0.0496 - val_accuracy: 0.9885\n",
            "Epoch 1865/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0228 - accuracy: 0.9941 - val_loss: 0.0508 - val_accuracy: 0.9892\n",
            "Epoch 1866/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0222 - accuracy: 0.9938 - val_loss: 0.0528 - val_accuracy: 0.9885\n",
            "Epoch 1867/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0218 - accuracy: 0.9933 - val_loss: 0.0533 - val_accuracy: 0.9877\n",
            "Epoch 1868/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0245 - accuracy: 0.9915 - val_loss: 0.0582 - val_accuracy: 0.9846\n",
            "Epoch 1869/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0251 - accuracy: 0.9926 - val_loss: 0.0522 - val_accuracy: 0.9846\n",
            "Epoch 1870/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0244 - accuracy: 0.9928 - val_loss: 0.0547 - val_accuracy: 0.9877\n",
            "Epoch 1871/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0210 - accuracy: 0.9949 - val_loss: 0.0515 - val_accuracy: 0.9900\n",
            "Epoch 1872/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0233 - accuracy: 0.9933 - val_loss: 0.0522 - val_accuracy: 0.9885\n",
            "Epoch 1873/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0220 - accuracy: 0.9944 - val_loss: 0.0532 - val_accuracy: 0.9846\n",
            "Epoch 1874/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0215 - accuracy: 0.9946 - val_loss: 0.0539 - val_accuracy: 0.9862\n",
            "Epoch 1875/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0222 - accuracy: 0.9936 - val_loss: 0.0540 - val_accuracy: 0.9854\n",
            "Epoch 1876/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0233 - accuracy: 0.9920 - val_loss: 0.0525 - val_accuracy: 0.9869\n",
            "Epoch 1877/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0260 - accuracy: 0.9923 - val_loss: 0.0520 - val_accuracy: 0.9869\n",
            "Epoch 1878/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0218 - accuracy: 0.9944 - val_loss: 0.0533 - val_accuracy: 0.9877\n",
            "Epoch 1879/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0231 - accuracy: 0.9946 - val_loss: 0.0518 - val_accuracy: 0.9862\n",
            "Epoch 1880/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0222 - accuracy: 0.9944 - val_loss: 0.0512 - val_accuracy: 0.9885\n",
            "Epoch 1881/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0214 - accuracy: 0.9946 - val_loss: 0.0499 - val_accuracy: 0.9892\n",
            "Epoch 1882/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0225 - accuracy: 0.9931 - val_loss: 0.0570 - val_accuracy: 0.9838\n",
            "Epoch 1883/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0230 - accuracy: 0.9923 - val_loss: 0.0517 - val_accuracy: 0.9877\n",
            "Epoch 1884/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0235 - accuracy: 0.9931 - val_loss: 0.0547 - val_accuracy: 0.9869\n",
            "Epoch 1885/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0234 - accuracy: 0.9936 - val_loss: 0.0513 - val_accuracy: 0.9877\n",
            "Epoch 1886/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0251 - accuracy: 0.9920 - val_loss: 0.0501 - val_accuracy: 0.9892\n",
            "Epoch 1887/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0210 - accuracy: 0.9951 - val_loss: 0.0534 - val_accuracy: 0.9869\n",
            "Epoch 1888/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0223 - accuracy: 0.9941 - val_loss: 0.0528 - val_accuracy: 0.9869\n",
            "Epoch 1889/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0260 - accuracy: 0.9918 - val_loss: 0.0578 - val_accuracy: 0.9838\n",
            "Epoch 1890/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0241 - accuracy: 0.9931 - val_loss: 0.0621 - val_accuracy: 0.9800\n",
            "Epoch 1891/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0228 - accuracy: 0.9941 - val_loss: 0.0543 - val_accuracy: 0.9862\n",
            "Epoch 1892/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0212 - accuracy: 0.9946 - val_loss: 0.0547 - val_accuracy: 0.9846\n",
            "Epoch 1893/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0215 - accuracy: 0.9941 - val_loss: 0.0567 - val_accuracy: 0.9838\n",
            "Epoch 1894/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0216 - accuracy: 0.9944 - val_loss: 0.0556 - val_accuracy: 0.9846\n",
            "Epoch 1895/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0245 - accuracy: 0.9926 - val_loss: 0.0512 - val_accuracy: 0.9877\n",
            "Epoch 1896/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0208 - accuracy: 0.9946 - val_loss: 0.0499 - val_accuracy: 0.9885\n",
            "Epoch 1897/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0218 - accuracy: 0.9928 - val_loss: 0.0545 - val_accuracy: 0.9838\n",
            "Epoch 1898/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0239 - accuracy: 0.9938 - val_loss: 0.0527 - val_accuracy: 0.9885\n",
            "Epoch 1899/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0232 - accuracy: 0.9944 - val_loss: 0.0622 - val_accuracy: 0.9831\n",
            "Epoch 1900/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0249 - accuracy: 0.9931 - val_loss: 0.0502 - val_accuracy: 0.9892\n",
            "Epoch 1901/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0237 - accuracy: 0.9926 - val_loss: 0.0515 - val_accuracy: 0.9885\n",
            "Epoch 1902/2000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0219 - accuracy: 0.9941 - val_loss: 0.0597 - val_accuracy: 0.9808\n",
            "Epoch 1903/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0216 - accuracy: 0.9928 - val_loss: 0.0517 - val_accuracy: 0.9885\n",
            "Epoch 1904/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0217 - accuracy: 0.9946 - val_loss: 0.0504 - val_accuracy: 0.9885\n",
            "Epoch 1905/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0209 - accuracy: 0.9954 - val_loss: 0.0538 - val_accuracy: 0.9838\n",
            "Epoch 1906/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0236 - accuracy: 0.9944 - val_loss: 0.0554 - val_accuracy: 0.9838\n",
            "Epoch 1907/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0240 - accuracy: 0.9938 - val_loss: 0.0516 - val_accuracy: 0.9869\n",
            "Epoch 1908/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0216 - accuracy: 0.9949 - val_loss: 0.0518 - val_accuracy: 0.9885\n",
            "Epoch 1909/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0212 - accuracy: 0.9946 - val_loss: 0.0506 - val_accuracy: 0.9877\n",
            "Epoch 1910/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0210 - accuracy: 0.9938 - val_loss: 0.0508 - val_accuracy: 0.9885\n",
            "Epoch 1911/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0230 - accuracy: 0.9944 - val_loss: 0.0505 - val_accuracy: 0.9885\n",
            "Epoch 1912/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0215 - accuracy: 0.9941 - val_loss: 0.0522 - val_accuracy: 0.9885\n",
            "Epoch 1913/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0239 - accuracy: 0.9928 - val_loss: 0.0537 - val_accuracy: 0.9885\n",
            "Epoch 1914/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0219 - accuracy: 0.9941 - val_loss: 0.0572 - val_accuracy: 0.9846\n",
            "Epoch 1915/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0207 - accuracy: 0.9941 - val_loss: 0.0503 - val_accuracy: 0.9877\n",
            "Epoch 1916/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0212 - accuracy: 0.9946 - val_loss: 0.0502 - val_accuracy: 0.9885\n",
            "Epoch 1917/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0220 - accuracy: 0.9936 - val_loss: 0.0527 - val_accuracy: 0.9869\n",
            "Epoch 1918/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0207 - accuracy: 0.9951 - val_loss: 0.0540 - val_accuracy: 0.9869\n",
            "Epoch 1919/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0225 - accuracy: 0.9944 - val_loss: 0.0518 - val_accuracy: 0.9862\n",
            "Epoch 1920/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0254 - accuracy: 0.9928 - val_loss: 0.0524 - val_accuracy: 0.9869\n",
            "Epoch 1921/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0281 - accuracy: 0.9915 - val_loss: 0.0513 - val_accuracy: 0.9900\n",
            "Epoch 1922/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0247 - accuracy: 0.9928 - val_loss: 0.0556 - val_accuracy: 0.9854\n",
            "Epoch 1923/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0210 - accuracy: 0.9938 - val_loss: 0.0521 - val_accuracy: 0.9877\n",
            "Epoch 1924/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0212 - accuracy: 0.9956 - val_loss: 0.0536 - val_accuracy: 0.9862\n",
            "Epoch 1925/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0213 - accuracy: 0.9944 - val_loss: 0.0534 - val_accuracy: 0.9869\n",
            "Epoch 1926/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0215 - accuracy: 0.9933 - val_loss: 0.0525 - val_accuracy: 0.9885\n",
            "Epoch 1927/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0209 - accuracy: 0.9951 - val_loss: 0.0518 - val_accuracy: 0.9877\n",
            "Epoch 1928/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0227 - accuracy: 0.9936 - val_loss: 0.0500 - val_accuracy: 0.9877\n",
            "Epoch 1929/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0220 - accuracy: 0.9938 - val_loss: 0.0528 - val_accuracy: 0.9869\n",
            "Epoch 1930/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0216 - accuracy: 0.9936 - val_loss: 0.0592 - val_accuracy: 0.9823\n",
            "Epoch 1931/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0234 - accuracy: 0.9933 - val_loss: 0.0512 - val_accuracy: 0.9885\n",
            "Epoch 1932/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0231 - accuracy: 0.9931 - val_loss: 0.0608 - val_accuracy: 0.9831\n",
            "Epoch 1933/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0274 - accuracy: 0.9918 - val_loss: 0.0563 - val_accuracy: 0.9854\n",
            "Epoch 1934/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0229 - accuracy: 0.9941 - val_loss: 0.0523 - val_accuracy: 0.9854\n",
            "Epoch 1935/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0216 - accuracy: 0.9936 - val_loss: 0.0516 - val_accuracy: 0.9877\n",
            "Epoch 1936/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0219 - accuracy: 0.9949 - val_loss: 0.0516 - val_accuracy: 0.9869\n",
            "Epoch 1937/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0228 - accuracy: 0.9938 - val_loss: 0.0569 - val_accuracy: 0.9846\n",
            "Epoch 1938/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0234 - accuracy: 0.9923 - val_loss: 0.0558 - val_accuracy: 0.9831\n",
            "Epoch 1939/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0211 - accuracy: 0.9938 - val_loss: 0.0546 - val_accuracy: 0.9854\n",
            "Epoch 1940/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0218 - accuracy: 0.9933 - val_loss: 0.0520 - val_accuracy: 0.9885\n",
            "Epoch 1941/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0210 - accuracy: 0.9941 - val_loss: 0.0534 - val_accuracy: 0.9869\n",
            "Epoch 1942/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0217 - accuracy: 0.9946 - val_loss: 0.0508 - val_accuracy: 0.9877\n",
            "Epoch 1943/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0205 - accuracy: 0.9949 - val_loss: 0.0511 - val_accuracy: 0.9885\n",
            "Epoch 1944/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0201 - accuracy: 0.9954 - val_loss: 0.0521 - val_accuracy: 0.9877\n",
            "Epoch 1945/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0209 - accuracy: 0.9946 - val_loss: 0.0513 - val_accuracy: 0.9877\n",
            "Epoch 1946/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0211 - accuracy: 0.9944 - val_loss: 0.0502 - val_accuracy: 0.9869\n",
            "Epoch 1947/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0210 - accuracy: 0.9941 - val_loss: 0.0523 - val_accuracy: 0.9892\n",
            "Epoch 1948/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0227 - accuracy: 0.9946 - val_loss: 0.0515 - val_accuracy: 0.9885\n",
            "Epoch 1949/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0219 - accuracy: 0.9936 - val_loss: 0.0528 - val_accuracy: 0.9877\n",
            "Epoch 1950/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0208 - accuracy: 0.9938 - val_loss: 0.0518 - val_accuracy: 0.9846\n",
            "Epoch 1951/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0217 - accuracy: 0.9944 - val_loss: 0.0524 - val_accuracy: 0.9869\n",
            "Epoch 1952/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0214 - accuracy: 0.9946 - val_loss: 0.0528 - val_accuracy: 0.9877\n",
            "Epoch 1953/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0212 - accuracy: 0.9949 - val_loss: 0.0517 - val_accuracy: 0.9900\n",
            "Epoch 1954/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0207 - accuracy: 0.9944 - val_loss: 0.0525 - val_accuracy: 0.9877\n",
            "Epoch 1955/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0224 - accuracy: 0.9941 - val_loss: 0.0500 - val_accuracy: 0.9869\n",
            "Epoch 1956/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0209 - accuracy: 0.9949 - val_loss: 0.0508 - val_accuracy: 0.9877\n",
            "Epoch 1957/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0204 - accuracy: 0.9946 - val_loss: 0.0513 - val_accuracy: 0.9877\n",
            "Epoch 1958/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0208 - accuracy: 0.9951 - val_loss: 0.0528 - val_accuracy: 0.9862\n",
            "Epoch 1959/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0212 - accuracy: 0.9949 - val_loss: 0.0517 - val_accuracy: 0.9885\n",
            "Epoch 1960/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0214 - accuracy: 0.9941 - val_loss: 0.0507 - val_accuracy: 0.9885\n",
            "Epoch 1961/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0223 - accuracy: 0.9936 - val_loss: 0.0554 - val_accuracy: 0.9846\n",
            "Epoch 1962/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0223 - accuracy: 0.9931 - val_loss: 0.0581 - val_accuracy: 0.9823\n",
            "Epoch 1963/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0227 - accuracy: 0.9944 - val_loss: 0.0513 - val_accuracy: 0.9877\n",
            "Epoch 1964/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0226 - accuracy: 0.9946 - val_loss: 0.0501 - val_accuracy: 0.9877\n",
            "Epoch 1965/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0246 - accuracy: 0.9931 - val_loss: 0.0528 - val_accuracy: 0.9869\n",
            "Epoch 1966/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0215 - accuracy: 0.9951 - val_loss: 0.0519 - val_accuracy: 0.9877\n",
            "Epoch 1967/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0223 - accuracy: 0.9941 - val_loss: 0.0533 - val_accuracy: 0.9869\n",
            "Epoch 1968/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0226 - accuracy: 0.9933 - val_loss: 0.0536 - val_accuracy: 0.9854\n",
            "Epoch 1969/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0211 - accuracy: 0.9938 - val_loss: 0.0513 - val_accuracy: 0.9885\n",
            "Epoch 1970/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0217 - accuracy: 0.9941 - val_loss: 0.0519 - val_accuracy: 0.9877\n",
            "Epoch 1971/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0213 - accuracy: 0.9949 - val_loss: 0.0519 - val_accuracy: 0.9892\n",
            "Epoch 1972/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0212 - accuracy: 0.9946 - val_loss: 0.0497 - val_accuracy: 0.9892\n",
            "Epoch 1973/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0205 - accuracy: 0.9941 - val_loss: 0.0540 - val_accuracy: 0.9854\n",
            "Epoch 1974/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0210 - accuracy: 0.9949 - val_loss: 0.0510 - val_accuracy: 0.9877\n",
            "Epoch 1975/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0210 - accuracy: 0.9949 - val_loss: 0.0508 - val_accuracy: 0.9892\n",
            "Epoch 1976/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0219 - accuracy: 0.9936 - val_loss: 0.0622 - val_accuracy: 0.9838\n",
            "Epoch 1977/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0235 - accuracy: 0.9928 - val_loss: 0.0535 - val_accuracy: 0.9885\n",
            "Epoch 1978/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0213 - accuracy: 0.9951 - val_loss: 0.0532 - val_accuracy: 0.9877\n",
            "Epoch 1979/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0220 - accuracy: 0.9933 - val_loss: 0.0507 - val_accuracy: 0.9892\n",
            "Epoch 1980/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0215 - accuracy: 0.9946 - val_loss: 0.0526 - val_accuracy: 0.9885\n",
            "Epoch 1981/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0205 - accuracy: 0.9951 - val_loss: 0.0515 - val_accuracy: 0.9885\n",
            "Epoch 1982/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0217 - accuracy: 0.9941 - val_loss: 0.0508 - val_accuracy: 0.9892\n",
            "Epoch 1983/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0209 - accuracy: 0.9941 - val_loss: 0.0511 - val_accuracy: 0.9877\n",
            "Epoch 1984/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0203 - accuracy: 0.9949 - val_loss: 0.0514 - val_accuracy: 0.9885\n",
            "Epoch 1985/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0210 - accuracy: 0.9946 - val_loss: 0.0498 - val_accuracy: 0.9877\n",
            "Epoch 1986/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0214 - accuracy: 0.9946 - val_loss: 0.0535 - val_accuracy: 0.9846\n",
            "Epoch 1987/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0218 - accuracy: 0.9938 - val_loss: 0.0537 - val_accuracy: 0.9869\n",
            "Epoch 1988/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0223 - accuracy: 0.9936 - val_loss: 0.0550 - val_accuracy: 0.9846\n",
            "Epoch 1989/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0228 - accuracy: 0.9933 - val_loss: 0.0528 - val_accuracy: 0.9862\n",
            "Epoch 1990/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0214 - accuracy: 0.9938 - val_loss: 0.0544 - val_accuracy: 0.9877\n",
            "Epoch 1991/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0214 - accuracy: 0.9944 - val_loss: 0.0543 - val_accuracy: 0.9885\n",
            "Epoch 1992/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0211 - accuracy: 0.9946 - val_loss: 0.0514 - val_accuracy: 0.9877\n",
            "Epoch 1993/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0206 - accuracy: 0.9941 - val_loss: 0.0528 - val_accuracy: 0.9869\n",
            "Epoch 1994/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0215 - accuracy: 0.9946 - val_loss: 0.0574 - val_accuracy: 0.9838\n",
            "Epoch 1995/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0209 - accuracy: 0.9931 - val_loss: 0.0520 - val_accuracy: 0.9877\n",
            "Epoch 1996/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0212 - accuracy: 0.9949 - val_loss: 0.0517 - val_accuracy: 0.9885\n",
            "Epoch 1997/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0218 - accuracy: 0.9946 - val_loss: 0.0508 - val_accuracy: 0.9900\n",
            "Epoch 1998/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0212 - accuracy: 0.9944 - val_loss: 0.0537 - val_accuracy: 0.9869\n",
            "Epoch 1999/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0228 - accuracy: 0.9949 - val_loss: 0.0530 - val_accuracy: 0.9885\n",
            "Epoch 2000/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0216 - accuracy: 0.9941 - val_loss: 0.0534 - val_accuracy: 0.9869\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score=model.evaluate(X_test, y_test)\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4CqtaW54TSO",
        "outputId": "c7c8f6f0-c9ba-40b4-eec9-00d2af47c5cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 0s 1ms/step - loss: 0.0707 - accuracy: 0.9885\n",
            "Test accuracy: 0.9884615540504456\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "BGtXeOiu6ebF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/deeplearning/data/house_train.csv')"
      ],
      "metadata": {
        "id": "a2GMgByx6eYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[데이터 정보](http://jse.amstat.org/v19n3/decock/DataDocumentation.txt)"
      ],
      "metadata": {
        "id": "M3lov-Ku7tBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "j-nv3jZm6eRV",
        "outputId": "44b3a9b6-122f-49b9-9457-36e399f5d846"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
              "0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
              "1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
              "2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
              "3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
              "4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
              "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
              "1455  1456          60       RL         62.0     7917   Pave   NaN      Reg   \n",
              "1456  1457          20       RL         85.0    13175   Pave   NaN      Reg   \n",
              "1457  1458          70       RL         66.0     9042   Pave   NaN      Reg   \n",
              "1458  1459          20       RL         68.0     9717   Pave   NaN      Reg   \n",
              "1459  1460          20       RL         75.0     9937   Pave   NaN      Reg   \n",
              "\n",
              "     LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
              "0            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
              "1            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
              "2            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
              "3            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
              "4            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
              "...          ...       ...  ...      ...    ...    ...         ...     ...   \n",
              "1455         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
              "1456         Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n",
              "1457         Lvl    AllPub  ...        0    NaN  GdPrv        Shed    2500   \n",
              "1458         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
              "1459         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
              "\n",
              "     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
              "0         2   2008        WD         Normal     208500  \n",
              "1         5   2007        WD         Normal     181500  \n",
              "2         9   2008        WD         Normal     223500  \n",
              "3         2   2006        WD        Abnorml     140000  \n",
              "4        12   2008        WD         Normal     250000  \n",
              "...     ...    ...       ...            ...        ...  \n",
              "1455      8   2007        WD         Normal     175000  \n",
              "1456      2   2010        WD         Normal     210000  \n",
              "1457      5   2010        WD         Normal     266500  \n",
              "1458      4   2010        WD         Normal     142125  \n",
              "1459      6   2008        WD         Normal     147500  \n",
              "\n",
              "[1460 rows x 81 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-321703a3-3fb2-475f-8273-a6d867e720f6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>...</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1455</th>\n",
              "      <td>1456</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>62.0</td>\n",
              "      <td>7917</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>175000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1456</th>\n",
              "      <td>1457</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>85.0</td>\n",
              "      <td>13175</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MnPrv</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>210000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1457</th>\n",
              "      <td>1458</td>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>66.0</td>\n",
              "      <td>9042</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>GdPrv</td>\n",
              "      <td>Shed</td>\n",
              "      <td>2500</td>\n",
              "      <td>5</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>266500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1458</th>\n",
              "      <td>1459</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>9717</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>142125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1459</th>\n",
              "      <td>1460</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>75.0</td>\n",
              "      <td>9937</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>147500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1460 rows × 81 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-321703a3-3fb2-475f-8273-a6d867e720f6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-321703a3-3fb2-475f-8273-a6d867e720f6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-321703a3-3fb2-475f-8273-a6d867e720f6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAZy_vc17oHs",
        "outputId": "ebdc7319-795c-4db4-c4dd-fdb9463895a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Id                 int64\n",
              "MSSubClass         int64\n",
              "MSZoning          object\n",
              "LotFrontage      float64\n",
              "LotArea            int64\n",
              "                  ...   \n",
              "MoSold             int64\n",
              "YrSold             int64\n",
              "SaleType          object\n",
              "SaleCondition     object\n",
              "SalePrice          int64\n",
              "Length: 81, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHwR5cbW8BSL",
        "outputId": "0f602e99-15d7-41b8-8988-b9bd917da7c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1460 entries, 0 to 1459\n",
            "Data columns (total 81 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Id             1460 non-null   int64  \n",
            " 1   MSSubClass     1460 non-null   int64  \n",
            " 2   MSZoning       1460 non-null   object \n",
            " 3   LotFrontage    1201 non-null   float64\n",
            " 4   LotArea        1460 non-null   int64  \n",
            " 5   Street         1460 non-null   object \n",
            " 6   Alley          91 non-null     object \n",
            " 7   LotShape       1460 non-null   object \n",
            " 8   LandContour    1460 non-null   object \n",
            " 9   Utilities      1460 non-null   object \n",
            " 10  LotConfig      1460 non-null   object \n",
            " 11  LandSlope      1460 non-null   object \n",
            " 12  Neighborhood   1460 non-null   object \n",
            " 13  Condition1     1460 non-null   object \n",
            " 14  Condition2     1460 non-null   object \n",
            " 15  BldgType       1460 non-null   object \n",
            " 16  HouseStyle     1460 non-null   object \n",
            " 17  OverallQual    1460 non-null   int64  \n",
            " 18  OverallCond    1460 non-null   int64  \n",
            " 19  YearBuilt      1460 non-null   int64  \n",
            " 20  YearRemodAdd   1460 non-null   int64  \n",
            " 21  RoofStyle      1460 non-null   object \n",
            " 22  RoofMatl       1460 non-null   object \n",
            " 23  Exterior1st    1460 non-null   object \n",
            " 24  Exterior2nd    1460 non-null   object \n",
            " 25  MasVnrType     1452 non-null   object \n",
            " 26  MasVnrArea     1452 non-null   float64\n",
            " 27  ExterQual      1460 non-null   object \n",
            " 28  ExterCond      1460 non-null   object \n",
            " 29  Foundation     1460 non-null   object \n",
            " 30  BsmtQual       1423 non-null   object \n",
            " 31  BsmtCond       1423 non-null   object \n",
            " 32  BsmtExposure   1422 non-null   object \n",
            " 33  BsmtFinType1   1423 non-null   object \n",
            " 34  BsmtFinSF1     1460 non-null   int64  \n",
            " 35  BsmtFinType2   1422 non-null   object \n",
            " 36  BsmtFinSF2     1460 non-null   int64  \n",
            " 37  BsmtUnfSF      1460 non-null   int64  \n",
            " 38  TotalBsmtSF    1460 non-null   int64  \n",
            " 39  Heating        1460 non-null   object \n",
            " 40  HeatingQC      1460 non-null   object \n",
            " 41  CentralAir     1460 non-null   object \n",
            " 42  Electrical     1459 non-null   object \n",
            " 43  1stFlrSF       1460 non-null   int64  \n",
            " 44  2ndFlrSF       1460 non-null   int64  \n",
            " 45  LowQualFinSF   1460 non-null   int64  \n",
            " 46  GrLivArea      1460 non-null   int64  \n",
            " 47  BsmtFullBath   1460 non-null   int64  \n",
            " 48  BsmtHalfBath   1460 non-null   int64  \n",
            " 49  FullBath       1460 non-null   int64  \n",
            " 50  HalfBath       1460 non-null   int64  \n",
            " 51  BedroomAbvGr   1460 non-null   int64  \n",
            " 52  KitchenAbvGr   1460 non-null   int64  \n",
            " 53  KitchenQual    1460 non-null   object \n",
            " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
            " 55  Functional     1460 non-null   object \n",
            " 56  Fireplaces     1460 non-null   int64  \n",
            " 57  FireplaceQu    770 non-null    object \n",
            " 58  GarageType     1379 non-null   object \n",
            " 59  GarageYrBlt    1379 non-null   float64\n",
            " 60  GarageFinish   1379 non-null   object \n",
            " 61  GarageCars     1460 non-null   int64  \n",
            " 62  GarageArea     1460 non-null   int64  \n",
            " 63  GarageQual     1379 non-null   object \n",
            " 64  GarageCond     1379 non-null   object \n",
            " 65  PavedDrive     1460 non-null   object \n",
            " 66  WoodDeckSF     1460 non-null   int64  \n",
            " 67  OpenPorchSF    1460 non-null   int64  \n",
            " 68  EnclosedPorch  1460 non-null   int64  \n",
            " 69  3SsnPorch      1460 non-null   int64  \n",
            " 70  ScreenPorch    1460 non-null   int64  \n",
            " 71  PoolArea       1460 non-null   int64  \n",
            " 72  PoolQC         7 non-null      object \n",
            " 73  Fence          281 non-null    object \n",
            " 74  MiscFeature    54 non-null     object \n",
            " 75  MiscVal        1460 non-null   int64  \n",
            " 76  MoSold         1460 non-null   int64  \n",
            " 77  YrSold         1460 non-null   int64  \n",
            " 78  SaleType       1460 non-null   object \n",
            " 79  SaleCondition  1460 non-null   object \n",
            " 80  SalePrice      1460 non-null   int64  \n",
            "dtypes: float64(3), int64(35), object(43)\n",
            "memory usage: 924.0+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GepQuHnP8DDN",
        "outputId": "6e66ef9a-032f-4c20-fc07-7bbfdc419e07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def info_df(df):\n",
        "    info_df = pd.DataFrame({\n",
        "        'isna': df.isna().sum(),\n",
        "        'isnull': df.isnull().sum()})\n",
        "    return info_df"
      ],
      "metadata": {
        "id": "URjauYVC8UYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.get_dummies(df)\n",
        "df = df.fillna(df.mean())\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "qqSzNjBK9CvL",
        "outputId": "e1e6fd8d-8bfd-46fa-e76e-35b4c6874e47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Id  MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  \\\n",
              "0        1          60         65.0     8450            7            5   \n",
              "1        2          20         80.0     9600            6            8   \n",
              "2        3          60         68.0    11250            7            5   \n",
              "3        4          70         60.0     9550            7            5   \n",
              "4        5          60         84.0    14260            8            5   \n",
              "...    ...         ...          ...      ...          ...          ...   \n",
              "1455  1456          60         62.0     7917            6            5   \n",
              "1456  1457          20         85.0    13175            6            6   \n",
              "1457  1458          70         66.0     9042            7            9   \n",
              "1458  1459          20         68.0     9717            5            6   \n",
              "1459  1460          20         75.0     9937            5            6   \n",
              "\n",
              "      YearBuilt  YearRemodAdd  MasVnrArea  BsmtFinSF1  ...  SaleType_ConLw  \\\n",
              "0          2003          2003       196.0         706  ...               0   \n",
              "1          1976          1976         0.0         978  ...               0   \n",
              "2          2001          2002       162.0         486  ...               0   \n",
              "3          1915          1970         0.0         216  ...               0   \n",
              "4          2000          2000       350.0         655  ...               0   \n",
              "...         ...           ...         ...         ...  ...             ...   \n",
              "1455       1999          2000         0.0           0  ...               0   \n",
              "1456       1978          1988       119.0         790  ...               0   \n",
              "1457       1941          2006         0.0         275  ...               0   \n",
              "1458       1950          1996         0.0          49  ...               0   \n",
              "1459       1965          1965         0.0         830  ...               0   \n",
              "\n",
              "      SaleType_New  SaleType_Oth  SaleType_WD  SaleCondition_Abnorml  \\\n",
              "0                0             0            1                      0   \n",
              "1                0             0            1                      0   \n",
              "2                0             0            1                      0   \n",
              "3                0             0            1                      1   \n",
              "4                0             0            1                      0   \n",
              "...            ...           ...          ...                    ...   \n",
              "1455             0             0            1                      0   \n",
              "1456             0             0            1                      0   \n",
              "1457             0             0            1                      0   \n",
              "1458             0             0            1                      0   \n",
              "1459             0             0            1                      0   \n",
              "\n",
              "      SaleCondition_AdjLand  SaleCondition_Alloca  SaleCondition_Family  \\\n",
              "0                         0                     0                     0   \n",
              "1                         0                     0                     0   \n",
              "2                         0                     0                     0   \n",
              "3                         0                     0                     0   \n",
              "4                         0                     0                     0   \n",
              "...                     ...                   ...                   ...   \n",
              "1455                      0                     0                     0   \n",
              "1456                      0                     0                     0   \n",
              "1457                      0                     0                     0   \n",
              "1458                      0                     0                     0   \n",
              "1459                      0                     0                     0   \n",
              "\n",
              "      SaleCondition_Normal  SaleCondition_Partial  \n",
              "0                        1                      0  \n",
              "1                        1                      0  \n",
              "2                        1                      0  \n",
              "3                        0                      0  \n",
              "4                        1                      0  \n",
              "...                    ...                    ...  \n",
              "1455                     1                      0  \n",
              "1456                     1                      0  \n",
              "1457                     1                      0  \n",
              "1458                     1                      0  \n",
              "1459                     1                      0  \n",
              "\n",
              "[1460 rows x 290 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-07285e02-d922-4da6-a188-cf9b2ddf91b8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>...</th>\n",
              "      <th>SaleType_ConLw</th>\n",
              "      <th>SaleType_New</th>\n",
              "      <th>SaleType_Oth</th>\n",
              "      <th>SaleType_WD</th>\n",
              "      <th>SaleCondition_Abnorml</th>\n",
              "      <th>SaleCondition_AdjLand</th>\n",
              "      <th>SaleCondition_Alloca</th>\n",
              "      <th>SaleCondition_Family</th>\n",
              "      <th>SaleCondition_Normal</th>\n",
              "      <th>SaleCondition_Partial</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>196.0</td>\n",
              "      <td>706</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>1976</td>\n",
              "      <td>1976</td>\n",
              "      <td>0.0</td>\n",
              "      <td>978</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2001</td>\n",
              "      <td>2002</td>\n",
              "      <td>162.0</td>\n",
              "      <td>486</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1915</td>\n",
              "      <td>1970</td>\n",
              "      <td>0.0</td>\n",
              "      <td>216</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>350.0</td>\n",
              "      <td>655</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1455</th>\n",
              "      <td>1456</td>\n",
              "      <td>60</td>\n",
              "      <td>62.0</td>\n",
              "      <td>7917</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>1999</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1456</th>\n",
              "      <td>1457</td>\n",
              "      <td>20</td>\n",
              "      <td>85.0</td>\n",
              "      <td>13175</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1978</td>\n",
              "      <td>1988</td>\n",
              "      <td>119.0</td>\n",
              "      <td>790</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1457</th>\n",
              "      <td>1458</td>\n",
              "      <td>70</td>\n",
              "      <td>66.0</td>\n",
              "      <td>9042</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>1941</td>\n",
              "      <td>2006</td>\n",
              "      <td>0.0</td>\n",
              "      <td>275</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1458</th>\n",
              "      <td>1459</td>\n",
              "      <td>20</td>\n",
              "      <td>68.0</td>\n",
              "      <td>9717</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>1950</td>\n",
              "      <td>1996</td>\n",
              "      <td>0.0</td>\n",
              "      <td>49</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1459</th>\n",
              "      <td>1460</td>\n",
              "      <td>20</td>\n",
              "      <td>75.0</td>\n",
              "      <td>9937</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>1965</td>\n",
              "      <td>1965</td>\n",
              "      <td>0.0</td>\n",
              "      <td>830</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1460 rows × 290 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07285e02-d922-4da6-a188-cf9b2ddf91b8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-07285e02-d922-4da6-a188-cf9b2ddf91b8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-07285e02-d922-4da6-a188-cf9b2ddf91b8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_corr = df.corr()\n",
        "df_corr_sort = df_corr.sort_values('SalePrice', ascending=False)\n",
        "df_corr_sort['SalePrice'].head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGcEbrMn9uFK",
        "outputId": "05e91bcd-c604-4f85-e49f-d7302bedfd1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SalePrice       1.000000\n",
              "OverallQual     0.790982\n",
              "GrLivArea       0.708624\n",
              "GarageCars      0.640409\n",
              "GarageArea      0.623431\n",
              "TotalBsmtSF     0.613581\n",
              "1stFlrSF        0.605852\n",
              "FullBath        0.560664\n",
              "BsmtQual_Ex     0.553105\n",
              "TotRmsAbvGrd    0.533723\n",
              "Name: SalePrice, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "cols=['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea', 'TotalBsmtSF']\n",
        "sns.pairplot(df[cols])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IWGGi_J_95xy",
        "outputId": "3b18520f-8efb-4c81-98f1-6190f5b16e86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x1080 with 42 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 주택가격 예측"
      ],
      "metadata": {
        "id": "jZSdh0Ah_AMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols_train=['OverallQual','GrLivArea','GarageCars','GarageArea','TotalBsmtSF']\n",
        "X_train_pre = df[cols_train]\n",
        "y = df['SalePrice'].values"
      ],
      "metadata": {
        "id": "HMoLDRnz-S_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_train_pre, y, test_size=0.2)"
      ],
      "metadata": {
        "id": "3q84tKzz_gdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(30, activation='relu'))\n",
        "model.add(Dense(40, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer ='adam', loss = 'mean_squared_error')\n",
        "\n",
        "# 20회 이상 결과가 향상되지 않으면 자동으로 중단\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)\n",
        "\n",
        "# 모델의 이름 설정\n",
        "modelpath=\"Ch15-house.hdf5\"\n",
        "\n",
        "# 최적화 모델을 업데이트하고 저장합니다.\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=0, save_best_only=True)\n",
        "\n",
        "#실행 관련 설정을 하는 부분입니다. 전체의 20%를 검증셋으로 설정. \n",
        "history = model.fit(X_train, y_train, validation_split=0.25, epochs=2000, batch_size=32, callbacks=[early_stopping_callback, checkpointer])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zB_j7XcD_gUj",
        "outputId": "c068245d-cf99-4fce-bfe9-85915107f885"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 10)                60        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 30)                330       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 40)                1240      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,671\n",
            "Trainable params: 1,671\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2000\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 38738931712.0000 - val_loss: 38295388160.0000\n",
            "Epoch 2/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 38578556928.0000 - val_loss: 38050115584.0000\n",
            "Epoch 3/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 38130483200.0000 - val_loss: 37282197504.0000\n",
            "Epoch 4/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 36769423360.0000 - val_loss: 35083591680.0000\n",
            "Epoch 5/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 33353244672.0000 - val_loss: 29978343424.0000\n",
            "Epoch 6/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 26470559744.0000 - val_loss: 21117079552.0000\n",
            "Epoch 7/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 16302180352.0000 - val_loss: 10471068672.0000\n",
            "Epoch 8/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 6898322944.0000 - val_loss: 3499428352.0000\n",
            "Epoch 9/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2894434048.0000 - val_loss: 2222525696.0000\n",
            "Epoch 10/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2463391744.0000 - val_loss: 2211852800.0000\n",
            "Epoch 11/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2448257792.0000 - val_loss: 2208108288.0000\n",
            "Epoch 12/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2450650368.0000 - val_loss: 2204849920.0000\n",
            "Epoch 13/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2446537472.0000 - val_loss: 2201625088.0000\n",
            "Epoch 14/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2437119488.0000 - val_loss: 2197086720.0000\n",
            "Epoch 15/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2430851328.0000 - val_loss: 2193641472.0000\n",
            "Epoch 16/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2448288768.0000 - val_loss: 2189696768.0000\n",
            "Epoch 17/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2422361344.0000 - val_loss: 2186510336.0000\n",
            "Epoch 18/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2415505152.0000 - val_loss: 2183070720.0000\n",
            "Epoch 19/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2408525568.0000 - val_loss: 2179768832.0000\n",
            "Epoch 20/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2409770752.0000 - val_loss: 2178029824.0000\n",
            "Epoch 21/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2411354112.0000 - val_loss: 2176581376.0000\n",
            "Epoch 22/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2400495360.0000 - val_loss: 2174010112.0000\n",
            "Epoch 23/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2402843648.0000 - val_loss: 2174860032.0000\n",
            "Epoch 24/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2389705728.0000 - val_loss: 2166909952.0000\n",
            "Epoch 25/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2390258688.0000 - val_loss: 2168061696.0000\n",
            "Epoch 26/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2445419264.0000 - val_loss: 2171558400.0000\n",
            "Epoch 27/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2372236288.0000 - val_loss: 2156864256.0000\n",
            "Epoch 28/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2374159616.0000 - val_loss: 2156104448.0000\n",
            "Epoch 29/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2359900672.0000 - val_loss: 2154216448.0000\n",
            "Epoch 30/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2365195776.0000 - val_loss: 2150129664.0000\n",
            "Epoch 31/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2370537728.0000 - val_loss: 2148056064.0000\n",
            "Epoch 32/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2363495424.0000 - val_loss: 2146216448.0000\n",
            "Epoch 33/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2352875264.0000 - val_loss: 2144512128.0000\n",
            "Epoch 34/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2353576960.0000 - val_loss: 2142338176.0000\n",
            "Epoch 35/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2347451904.0000 - val_loss: 2141179008.0000\n",
            "Epoch 36/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2349916416.0000 - val_loss: 2139854976.0000\n",
            "Epoch 37/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2342934784.0000 - val_loss: 2140490112.0000\n",
            "Epoch 38/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2332521728.0000 - val_loss: 2136332032.0000\n",
            "Epoch 39/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2357516032.0000 - val_loss: 2142621824.0000\n",
            "Epoch 40/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2345188608.0000 - val_loss: 2133404800.0000\n",
            "Epoch 41/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2350091520.0000 - val_loss: 2133098752.0000\n",
            "Epoch 42/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2342083328.0000 - val_loss: 2130264320.0000\n",
            "Epoch 43/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2323250176.0000 - val_loss: 2129788928.0000\n",
            "Epoch 44/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2341112832.0000 - val_loss: 2127866368.0000\n",
            "Epoch 45/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2359634688.0000 - val_loss: 2138377344.0000\n",
            "Epoch 46/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2312222208.0000 - val_loss: 2127464704.0000\n",
            "Epoch 47/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2327128064.0000 - val_loss: 2125604736.0000\n",
            "Epoch 48/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2312097280.0000 - val_loss: 2125165440.0000\n",
            "Epoch 49/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2310566144.0000 - val_loss: 2123274368.0000\n",
            "Epoch 50/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2321660672.0000 - val_loss: 2124775424.0000\n",
            "Epoch 51/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2320697600.0000 - val_loss: 2121622528.0000\n",
            "Epoch 52/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2315215360.0000 - val_loss: 2125498368.0000\n",
            "Epoch 53/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2310149632.0000 - val_loss: 2120072704.0000\n",
            "Epoch 54/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2300259072.0000 - val_loss: 2119096192.0000\n",
            "Epoch 55/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2306392064.0000 - val_loss: 2118257024.0000\n",
            "Epoch 56/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2310219520.0000 - val_loss: 2119091072.0000\n",
            "Epoch 57/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2301221888.0000 - val_loss: 2116965376.0000\n",
            "Epoch 58/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2296884736.0000 - val_loss: 2116838400.0000\n",
            "Epoch 59/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2311954944.0000 - val_loss: 2116838400.0000\n",
            "Epoch 60/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2297025536.0000 - val_loss: 2114905344.0000\n",
            "Epoch 61/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2316410880.0000 - val_loss: 2116799104.0000\n",
            "Epoch 62/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2308762880.0000 - val_loss: 2114181888.0000\n",
            "Epoch 63/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2298439936.0000 - val_loss: 2114191360.0000\n",
            "Epoch 64/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2289087232.0000 - val_loss: 2113409920.0000\n",
            "Epoch 65/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2303245056.0000 - val_loss: 2116264704.0000\n",
            "Epoch 66/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2297689856.0000 - val_loss: 2118650112.0000\n",
            "Epoch 67/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2292627456.0000 - val_loss: 2115127680.0000\n",
            "Epoch 68/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2367424000.0000 - val_loss: 2131563392.0000\n",
            "Epoch 69/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2281912576.0000 - val_loss: 2119779200.0000\n",
            "Epoch 70/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2297782272.0000 - val_loss: 2111168640.0000\n",
            "Epoch 71/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2298122240.0000 - val_loss: 2116670336.0000\n",
            "Epoch 72/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2313453312.0000 - val_loss: 2110082560.0000\n",
            "Epoch 73/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2280246016.0000 - val_loss: 2110992384.0000\n",
            "Epoch 74/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2292307200.0000 - val_loss: 2118727040.0000\n",
            "Epoch 75/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2271632896.0000 - val_loss: 2112815744.0000\n",
            "Epoch 76/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2309725440.0000 - val_loss: 2110302464.0000\n",
            "Epoch 77/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2284888832.0000 - val_loss: 2108667264.0000\n",
            "Epoch 78/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2279545344.0000 - val_loss: 2108456960.0000\n",
            "Epoch 79/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2279316224.0000 - val_loss: 2113500288.0000\n",
            "Epoch 80/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2276517376.0000 - val_loss: 2110765568.0000\n",
            "Epoch 81/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2283165952.0000 - val_loss: 2107943424.0000\n",
            "Epoch 82/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2274438144.0000 - val_loss: 2109457536.0000\n",
            "Epoch 83/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2278351360.0000 - val_loss: 2113838720.0000\n",
            "Epoch 84/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2291593216.0000 - val_loss: 2107732224.0000\n",
            "Epoch 85/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2271735552.0000 - val_loss: 2112122880.0000\n",
            "Epoch 86/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2276409344.0000 - val_loss: 2107971328.0000\n",
            "Epoch 87/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2280097024.0000 - val_loss: 2109934464.0000\n",
            "Epoch 88/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2267758848.0000 - val_loss: 2107566592.0000\n",
            "Epoch 89/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2278350592.0000 - val_loss: 2108997632.0000\n",
            "Epoch 90/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2281972224.0000 - val_loss: 2114380288.0000\n",
            "Epoch 91/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2285143552.0000 - val_loss: 2107176064.0000\n",
            "Epoch 92/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2294421248.0000 - val_loss: 2106987392.0000\n",
            "Epoch 93/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2271914240.0000 - val_loss: 2107094144.0000\n",
            "Epoch 94/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2273049856.0000 - val_loss: 2106981504.0000\n",
            "Epoch 95/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2268739584.0000 - val_loss: 2106778368.0000\n",
            "Epoch 96/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2264507392.0000 - val_loss: 2107991680.0000\n",
            "Epoch 97/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2273137152.0000 - val_loss: 2109940224.0000\n",
            "Epoch 98/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2290460672.0000 - val_loss: 2112414464.0000\n",
            "Epoch 99/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2265497088.0000 - val_loss: 2107622016.0000\n",
            "Epoch 100/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2326872064.0000 - val_loss: 2129359744.0000\n",
            "Epoch 101/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2260511744.0000 - val_loss: 2121979776.0000\n",
            "Epoch 102/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2275922944.0000 - val_loss: 2107082240.0000\n",
            "Epoch 103/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2264677632.0000 - val_loss: 2111632512.0000\n",
            "Epoch 104/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2271086336.0000 - val_loss: 2107608832.0000\n",
            "Epoch 105/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2266361344.0000 - val_loss: 2106928768.0000\n",
            "Epoch 106/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2276177408.0000 - val_loss: 2106981888.0000\n",
            "Epoch 107/2000\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2285263616.0000 - val_loss: 2111855232.0000\n",
            "Epoch 108/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2270550016.0000 - val_loss: 2108562688.0000\n",
            "Epoch 109/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2266624000.0000 - val_loss: 2107955968.0000\n",
            "Epoch 110/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2268498176.0000 - val_loss: 2108509440.0000\n",
            "Epoch 111/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2269410304.0000 - val_loss: 2107231488.0000\n",
            "Epoch 112/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2263148800.0000 - val_loss: 2110184192.0000\n",
            "Epoch 113/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2266553600.0000 - val_loss: 2111001856.0000\n",
            "Epoch 114/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2276522240.0000 - val_loss: 2108159744.0000\n",
            "Epoch 115/2000\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 2287284480.0000 - val_loss: 2108311040.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측 값과 실제 값, 실행 번호가 들어갈 빈 리스트를 생성\n",
        "real_prices =[]\n",
        "pred_prices = []\n",
        "X_num = []\n",
        "\n",
        "# 25개의 샘플을 뽑아 실제 값, 예측 값을 출력.\n",
        "n_iter = 0\n",
        "Y_prediction = model.predict(X_test).flatten()\n",
        "for i in range(25):\n",
        "    real = y_test[i]\n",
        "    prediction = Y_prediction[i]\n",
        "    print(\"실제가격: {:.2f}, 예상가격: {:.2f}\".format(real, prediction))\n",
        "    real_prices.append(real)\n",
        "    pred_prices.append(prediction)\n",
        "    n_iter = n_iter + 1\n",
        "    X_num.append(n_iter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHJQtlED_9mI",
        "outputId": "75522ca5-d580-43fd-eaf2-de1b93a96c9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "실제가격: 147000.00, 예상가격: 117228.52\n",
            "실제가격: 290000.00, 예상가격: 280381.19\n",
            "실제가격: 107000.00, 예상가격: 146604.00\n",
            "실제가격: 284000.00, 예상가격: 326699.47\n",
            "실제가격: 112000.00, 예상가격: 114231.93\n",
            "실제가격: 131000.00, 예상가격: 138421.56\n",
            "실제가격: 170000.00, 예상가격: 184053.05\n",
            "실제가격: 252678.00, 예상가격: 210180.48\n",
            "실제가격: 168000.00, 예상가격: 184039.77\n",
            "실제가격: 117000.00, 예상가격: 141652.39\n",
            "실제가격: 151500.00, 예상가격: 128846.04\n",
            "실제가격: 39300.00, 예상가격: 19416.33\n",
            "실제가격: 262500.00, 예상가격: 245956.28\n",
            "실제가격: 110500.00, 예상가격: 82429.48\n",
            "실제가격: 148000.00, 예상가격: 161349.58\n",
            "실제가격: 103000.00, 예상가격: 157229.23\n",
            "실제가격: 155000.00, 예상가격: 167193.72\n",
            "실제가격: 119000.00, 예상가격: 148027.97\n",
            "실제가격: 160000.00, 예상가격: 187170.34\n",
            "실제가격: 233170.00, 예상가격: 217914.89\n",
            "실제가격: 213250.00, 예상가격: 229329.47\n",
            "실제가격: 144000.00, 예상가격: 128673.08\n",
            "실제가격: 169000.00, 예상가격: 197819.16\n",
            "실제가격: 133900.00, 예상가격: 117862.93\n",
            "실제가격: 275500.00, 예상가격: 252606.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#그래프를 통해 샘플로 뽑은 25개의 값을 비교.\n",
        "plt.plot(X_num, pred_prices, label='predicted price')\n",
        "plt.plot(X_num, real_prices, label='real price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "vXhi3bPxAlh4",
        "outputId": "3409053a-15da-41e2-f202-020d62193210"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 이미지\n",
        "* [참고 링크](http://neuralnetworksanddeeplearning.com/chap1.html)"
      ],
      "metadata": {
        "id": "xdw06sEPFM0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "print(\"학습셋 이미지 수 : %d 개\" % (X_train.shape[0]))\n",
        "print(\"테스트셋 이미지 수 : %d 개\" % (X_test.shape[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAtkBkxKBGdZ",
        "outputId": "960115fc-6416-4bbd-85d1-ff64eb9215e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "학습셋 이미지 수 : 60000 개\n",
            "테스트셋 이미지 수 : 10000 개\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(X_train[0], cmap='Greys')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "lu6dh6LBFuy3",
        "outputId": "15862dbc-e87e-4239-c9f8-5fdcde077e7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지가 인식되는 원리를 알아봅시다.\n",
        "for x in X_train[0]:\n",
        "    for i in x:\n",
        "        sys.stdout.write(\"%-3s\" % i)\n",
        "    sys.stdout.write('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhCl_RYTF7f8",
        "outputId": "35d60b69-a301-488a-a847-66d0bbf29c9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0  0  0  0  0  3  18 18 18 12613617526 1662552471270  0  0  0  \n",
            "0  0  0  0  0  0  0  0  30 36 94 15417025325325325325322517225324219564 0  0  0  0  \n",
            "0  0  0  0  0  0  0  49 23825325325325325325325325325193 82 82 56 39 0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  18 2192532532532532531981822472410  0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0  80 15610725325320511 0  43 1540  0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0  0  14 1  15425390 0  0  0  0  0  0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0  0  0  0  1392531902  0  0  0  0  0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0  0  0  0  11 19025370 0  0  0  0  0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0  0  0  0  0  35 2412251601081  0  0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0  0  0  0  0  0  81 24025325311925 0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0  0  0  0  0  0  0  45 18625325315027 0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  16 93 2522531870  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  24925324964 0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0  0  0  0  0  0  0  46 1301832532532072  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0  0  0  0  0  39 1482292532532532501820  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0  0  0  24 11422125325325325320178 0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0  23 66 21325325325325319881 2  0  0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  18 17121925325325325319580 9  0  0  0  0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  55 17222625325325325324413311 0  0  0  0  0  0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  13625325325321213513216 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 차원 변환 과정을 실습해 봅니다.\n",
        "X_train = X_train.reshape(X_train.shape[0], 784)\n",
        "X_train = X_train.astype('float64')\n",
        "X_train = X_train / 255\n",
        "\n",
        "X_test = X_test.reshape(X_test.shape[0], 784).astype('float64') / 255\n",
        "\n",
        "# 클래스 값을 확인해 봅니다.\n",
        "print(\"class : %d \" % (y_train[0]))\n",
        "\n",
        "# 바이너리화 과정을 실습해 봅니다.\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "print(y_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3utncgH7IV0s",
        "outputId": "e1f68591-106a-446a-b84b-460b8a048fcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class : 5 \n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# MNIST 데이터를 불러옵니다. \n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# 차원 변환 후, 테스트셋과 학습셋으로 나누어 줍니다.\n",
        "X_train = X_train.reshape(X_train.shape[0], 784).astype('float32') / 255\n",
        "X_test = X_test.reshape(X_test.shape[0], 784).astype('float32') / 255\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# 모델 구조를 설정합니다.\n",
        "model = Sequential()\n",
        "model.add(Dense(512, input_dim=784, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRZfQJ1_KOvM",
        "outputId": "daeb8f8f-5fc1-4189-e71c-7ada89140de7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 512)               401920    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 실행 환경을 설정합니다.\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 모델 최적화를 위한 설정구간입니다.\n",
        "MODEL_DIR = 'model16'\n",
        "if not os.path.exists(MODEL_DIR):\n",
        "    os.mkdir(MODEL_DIR)\n",
        "\n",
        "modelpath=\"MNIST_MLP.hdf5\"\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "# 모델을 실행합니다.\n",
        "history = model.fit(X_train, y_train, validation_split=0.25, epochs=30, batch_size=200, verbose=0, callbacks=[early_stopping_callback,checkpointer])\n",
        "\n",
        "# 테스트 정확도를 출력합니다.\n",
        "print(\"\\n Test Accuracy: %.4f\" % (model.evaluate(X_test, y_test)[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyJBsgEPKR7z",
        "outputId": "cf534495-d441-4e66-a483-bc61577f51f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: val_loss improved from inf to 0.09919, saving model to MNIST_MLP.hdf5\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.09919\n",
            "\n",
            "Epoch 3: val_loss improved from 0.09919 to 0.09454, saving model to MNIST_MLP.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.09454 to 0.09046, saving model to MNIST_MLP.hdf5\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.09046\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.09046\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.09046\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.09046\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.09046\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.09046\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.09046\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.09046\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.09046\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.09046\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0792 - accuracy: 0.9820\n",
            "\n",
            " Test Accuracy: 0.9820\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 검증셋과 학습셋의 오차를 저장합니다. \n",
        "y_vloss = history.history['val_loss']\n",
        "y_loss = history.history['loss']\n",
        "\n",
        "# 그래프로 표현해 봅니다.\n",
        "x_len = np.arange(len(y_loss))\n",
        "plt.plot(x_len, y_vloss, marker='.', c=\"red\", label='Testset_loss')\n",
        "plt.plot(x_len, y_loss, marker='.', c=\"blue\", label='Trainset_loss')\n",
        "\n",
        "# 그래프에 그리드를 주고 레이블을 표시해 보겠습니다.\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "LAoKdX7RKXrK",
        "outputId": "824ab23d-225a-4159-9ca7-8d56fd533aab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhU1fnA8e+blSXsYERAAROpUBANixHRIAq4L0XBrSpa1Iob2h+g4oJLcalaxYpWKS4IdalKKxUUiWgBZREVEAtGZNEiiySEJWR5f3+cO2QIM2GSyc2E5P08z33mrjNvJjP3nXPPueeIqmKMMcaUFRfrAIwxxtRMliCMMcaEZAnCGGNMSJYgjDHGhGQJwhhjTEgJsQ6gqrRs2VLbt29f6eN37NhBw4YNqy6gKmbxRcfii47FF52aHN/ixYs3q2qrkBtVtVZMGRkZGo05c+ZEdbzfLL7oWHzRsfiiU5PjAxZpmPOqr5eYRGSQiHwrIqtFZHSI7deJyNcislREPhWRzt769iKyy1u/VEQm+hmnMcaY/fl2iUlE4oFngNOA9cBCEZmuqiuCdntNVSd6+58DPA4M8rZ9p6rd/YrPGGNM+fwsQfQCVqtqjqruAaYB5wbvoKp5QYsNAbut2xhjaghRn7raEJHBwCBVvcZbvhzoraojyux3AzASSAJOUdVVItIeWA78F8gD7lLVT0K8xnBgOEBqamrGtGnTKh1vfn4+KSkplT7ebxZfdCy+6EQTn4jQsGFD4uPjqziqUqqKiPj2/NGqCfEVFxezY8cOyp7z+/Xrt1hVe4Q8KFzlRLQTMBh4IWj5cmBCOftfArzkzScDLbz5DGAd0Li817NK6tiy+KJTm+PLycnRTZs2aUlJSdUFVEZeXp5vz10VYh1fSUmJbtq0SXNycvbbRowqqTcA7YKW23rrwpkGnAegqgWqusWbXwx8BxzlU5zGGB/t3r2bFi1axPwXdF0mIrRo0YLdu3dX6Dg/E8RCIF1EOohIEjAUmB68g4ikBy2eCazy1rfyKrkRkY5AOpDjV6Dz58OUKYczf75fr2BM3WbJIfYq8z/wrRWTqhaJyAhgJhAPTFLV5SIyDlekmQ6MEJFTgULgF+AK7/CTgHEiUgiUANep6lY/4pw5E846C4qLOzBlCsyeDZmZfrySMcYcXHy9k1pVZwAzyqy7O2j+5jDHvQW85WdsAfPmQVERgLBnD2RnW4IwxhiwvpgYFLjrAiUpCbKyYhiMMabKbdmyhe7du9O9e3cOPfRQ2rRps3d5z549Bzw+OzubefPmVeq116xZw2uvvXbA5z/rrLMq9fx+qzV9MVVWZiZ07QqbN+/mrbfqW+nBmJpg/nxXnM/KirpI36JFC5YuXQrAvffeS0pKCrfffnvEx2dnZ5OSksIJJ5xQ4dcOJIizzz67wsfWBHU+QQAceyzMmBFnycEYv91yC3gn67Byc+Grr6CkBOLioFs3aNIk/P7du8P991cojMWLFzNy5Ejy8/Np2bIlkydPpnXr1jz11FNMnDiRhIQEOnfuzPjx45k4cSLx8fG8+uqrPP300/zvf//jvvvuIz4+niZNmjB37lyKi4sZPXo02dnZFBQUcMMNN3DttdcyevRovvnmG/r06cNVV13FrbfeWm5cW7duZdiwYeTk5NCgQQOef/55unXrxscff8zNN7sr8iLC3Llzyc/PZ8iQIeTl5VFUVMSzzz5L3759K/Q+HIglCCA9HTZvTmbnTmjQINbRGFPH5ea65ADuMTe3/ARRQarKjTfeyLvvvkurVq34+9//zp133smkSZMYP34833//PcnJyWzbto2mTZty3XXX7VPq6Nq1KzNnzqRNmzZs27YNgBdffJEmTZqwcOFCCgoK6NOnDwMGDGD8+PE89thjTJ06lUaNGh0wtnvuuYdjjz2Wd955h48++ojf/va3LF26lMcee4xnnnmGPn36kJ+fT7169Xj++ecZOHAgd955J8XFxezcubPK3qMASxBAWpp7zMmBX/86trEYU6s9+eSB95k/H/r3hz17ICkJpkw58GWm7dsjDqGgoIBly5Zx2mmnAe4O49atWwPQrVs3Lr30Us477zzOO++8kMf36dOHK6+8kosuuogLLrgAgFmzZvHVV1/x5ptvApCbm8uqVatISkqKOC6ATz/9lLfecu1zTjnlFLZs2UJeXh59+vRh5MiRXHrppVxwwQW0bduWnj17MmzYMAoLCznvvPPo3r3qu66r85XU4EoQAKtWxTYOYwwuGcye7S4b+dDuXFXp0qULS5cuZenSpXz99dfMmjULgPfee48bbriBJUuW0LNnT4pcE8d9TJw4kQceeIB169aRkZHBli1bUFWefvrpvc/5/fffM2DAgCqLefTo0bzwwgvs2rWLPn36sHLlSk466STmzp1LmzZtuPLKK3n55Zer7PUCLEFQWoJYvTq2cRhjPJmZMGaML23Ok5OT2bRpE/O9O2MLCwtZvnw5JSUlrFu3jn79+vHwww+Tm5tLfn4+jRo1YntQCeW7776jd+/ejBs3jlatWrFu3ToGDhzIs88+S2FhIQD//e9/2bFjx37HHkjfvn2ZMmUK4CrHW7ZsSePGjfnuu+/o2rUro0aNomfPnqxcuZIffviB1NRUfve733HNNdewZMmSKnyXHLvEhLu82bTpHlatqlhx0Bhz8ImLi+PNN9/kpptuIjc3l6KiIm655RaOOuooLrvsMnJzc1FVbrrpJpo2bcrZZ5/N4MGDeffdd3n66ad54oknWLVqFapK//79OeaYY+jWrRtr1qzhuOOOQ1Vp1aoV77zzDt26dSM+Pp4TTjiBYcOGHbCS+t5772XYsGF069aNBg0a8NJLLwHw5JNPMmfOHOLi4ujSpQunn34606ZN49FHHyUxMZGUlBRfShAxHwmuqqZoO+vr0mWb9usX1VP4qjZ35lYdLL7oRBPfihUrqi6QMGLdGd6B1JT4Qv0viNWIcgeTNm12WR2EMcYEsUtMnjZtdjFrFuzaBfXrxzoaY0xtM3PmTEaNGrXPug4dOvD222/HKKIDswThadt2FwDffWdNXY0xVW/gwIEMHDgw1mFUiF1i8rRp4xKEtWQyxhjHEoQnkCCsHsIYYxxLEJ6UlCJatrQShDHGBFiCCJKebiUIY4wJsAQRJC3NShDG1DbRjAexaNEibrrppiqNZ/Lkyfz444/l7pOVlcWiRYuq9HUrw1oxBUlPh1desaauxsRaFQ4HccDxIIqKikhICH0q7NGjBz169IgugDImT57Mr3/9aw477LAqfV4/WIIIEtyra5cusY3FmNqohgwHwZVXXkm9evX44osv6NOnD0OHDuXmm29m9+7d1K9fn7/97W906tSJ7OxsHnvsMf71r39x7733snbtWnJycli7di233HILN910Ezt27OCiiy5i/fr1FBcXM3bsWIYMGbLPmBNNmzbl1Vdf5T//+Q+LFi3i0ksvpX79+syfP5/6B/g1OnXqVB566CFUlTPPPJOHH36Y4uJirr76ahYtWoSI7O3Go+x4FtOmTavYG1OGJYggwb26WoIwJjZ8Hg5ir/Xr1zNv3jzi4+PJy8vjk08+ISEhgQ8//JA77rhjb7fbwVauXMmcOXPYvn07nTp14vrrr+f999/nsMMO47333vPiz6WwsHCfMScmT568d8yJCRMm8Nhjj0VUMvnxxx8ZNWoUixcvplmzZgwYMIB33nmHdu3asWHDBpYtWwawd1yKsuNZRMvXBCEig4A/A/HAC6o6vsz264AbgGIgHxiuqiu8bWOAq71tN6nqTD9jBTjySPdo9RDG+KMGDAex14UXXkh8fDzgTupXXHEFq1atQkT29spa1plnnklycjLJyckccsghbNy4ka5du3LbbbcxatQozjrrLPr27cuyZcv2GXOisLCQNm3aVDjGhQsXkpWVRatWrQC49NJLmTt3LmPHjiUnJ4cbb7yRM888c2/X4pGMZ1ERvlVSi0g88AxwOtAZuFhEOpfZ7TVV7aqq3YFHgMe9YzsDQ4EuwCDgL97z+apZM2jRwloyGRNLPg8HsVfDhg33zo8dO5Z+/fqxbNky/vnPf7J79+6QxyQnJ++dj4+Pp6ioiKOOOoolS5bQtWtX7rrrLsaNG7ffmBMLFizYO+ZEVWjWrBlffvklWVlZTJw4kWuuuQaIbDyLivCzFVMvYLWq5qjqHmAacG7wDqqaF7TYEFBv/lxgmqoWqOr3wGrv+XyXnm4lCGNizcfhIELKzc3d+wt/8uTJFTr2xx9/pEGDBlx22WX84Q9/YMmSJXTq1CnkmBNAhcaI6NWrFx9//DGbN2+muLiYqVOncvLJJ7N582ZKSkr4zW9+wwMPPMCSJUvCjmcRDT8vMbUB1gUtrwd6l91JRG4ARgJJwClBxy4oc+x+5TMRGQ4MB0hNTSU7O7vSwebn55OdnU2jRr/iyy+bkp294MAHVaNAfDWVxRed2hxfkyZNKjRoTmUUFxdH9BoFBQUkJiZSWFjIrl279h5zww03cN111zFu3DgGDBiAqrJ9+3Z27txJUVER27dv33ts4JiSkhLy8/NZtWoVY8eOJS4ujoSEBJ544gkKCgp46aWXuP3228nLy6OoqIjf//73HH744QwZMoThw4dTv359Pvzww5CV1MXFxezYsYOUlBTuueceTj75ZFSVgQMHcsopp/D111/z+9//nhKvsuaee+5h27ZtXHzxxeTl5aGqXHvttcTHx+/zvuzevbti/8dw/YBHOwGDcfUOgeXLgQnl7H8J8JI3PwG4LGjbi8Dg8l4v2vEgAv3d33efKqju3BnV01W52jxeQHWw+KJj40FEp6bEV5PGg9gAtAtabuutC2caEKhVqeixVSa4qasxxtRlfiaIhUC6iHQQkSRcpfP04B1EJD1o8UwgUD08HRgqIski0gFIBz73Mda9Ak1drR7CGOO3888/f+9d3YFp5kzfG2xGzLc6CFUtEpERwExcM9dJqrpcRMbhijTTgREicipQCPwCXOEdu1xEXgdWAEXADapa7FeswQIlCGvJZEzVUVVEJNZh1DjVOViQu5pUMb7eB6GqM4AZZdbdHTR/cznHPgg86F90oQWauloJwpiqUa9ePbZs2UKLFi0sScSIqrJlyxbq1atXoePsTuoQrNM+Y6pO27ZtWb9+PZs2bfLtNXbv3l3hk191qgnx1atXj7Zt21boGEsQIaSnw9y5sY7CmNohMTGRDh06+Poa2dnZHHvssb6+RjRqenzhWHffIaSlwbp1EOZmSmOMqRMsQYSQng6q1tTVGFO3WYIIIdCSyeohjDF1mSWIEIK7/TbGmLrKEkQIzZpB8+ZWgjDG1G2WIMJIT7cShDGmbrMEEYbdC2GMqessQYSRng5r11pTV2NM3WUJIoy0NNfU9fvvYx2JMcbEhiWIMKwlkzGmrrMEEYbdC2GMqessQYTRvLmbrARhjKmrLEGUw1oyGWPqMksQ5bB7IYwxdZkliHKkpbmmrgUFsY7EGGOqnyWIcgSaulqvrsaYusgSRDkCTV2tHsIYUxdZgihHoKmr1UMYY+oiXxOEiAwSkW9FZLWIjA6xfaSIrBCRr0RktogcEbStWESWetN0P+MMp0UL17OrlSCMMXWRb2NSi0g88AxwGrAeWCgi01V1RdBuXwA9VHWniFwPPAIM8bbtUtXufsUXqbQ0K0EYY+omP0sQvYDVqpqjqnuAacC5wTuo6hxV3ektLgDa+hhPpaSnWwnCGFM3iar688Qig4FBqnqNt3w50FtVR4TZfwLwP1V9wFsuApYCRcB4VX0nxDHDgeEAqampGdOmTat0vPn5+aSkpOy3/m9/a8+rrx7Bv/89l6Qkf96rSISLr6aw+KJj8UXH4qu8fv36LVbVHiE3qqovEzAYeCFo+XJgQph9L8OVIJKD1rXxHjsCa4Ajy3u9jIwMjcacOXNCrn/lFVVQ/eabqJ4+auHiqyksvuhYfNGx+CoPWKRhzqt+XmLaALQLWm7rrduHiJwK3Amco6p7b0lT1Q3eYw6QDRzrY6xhWad9xpi6ys8EsRBIF5EOIpIEDAX2aY0kIscCz+GSw89B65uJSLI33xLoAwRXblcb6/bbGFNX+daKSVWLRGQEMBOIByap6nIRGYcr0kwHHgVSgDdEBGCtqp4DHA08JyIluCQ2Xvdt/VRtmjeHpk2tBGGMqXt8SxAAqjoDmFFm3d1B86eGOW4e0NXP2CIlYp32GWPqJruTOgLW7bcxpi6yBBGB9HT44QfYsyfWkRhjTPWxBBGBtDQoKYHvv491JMYYU30sQUTAWjIZY+oiSxARsHshjDF1kSWICLRo4Zq6WgnCGFOXWIKIgIi1ZDLG1D2WICJk90IYY+oaSxARSkuzpq7GmLrFEkSE0tOtqasxpm6xBBEha8lkjKlrLEFEyO6FMMbUNZYgItSiBTRpYiUIY0zdYQkiQoGmrlaCMMbUFZYgKiA93UoQxpi6wxJEBaSlwZo11tTVGFM3WIKogEBT1zVrYh2JMcb4zxJEBQSaulo9hDGmLrAEUQGBpq5WD2GMqQssQVRAy5bQuLGVIIwxdYOvCUJEBonItyKyWkRGh9g+UkRWiMhXIjJbRI4I2naFiKzypiv8jDNSItaSyRhTd/iWIEQkHngGOB3oDFwsIp3L7PYF0ENVuwFvAo94xzYH7gF6A72Ae0SkmV+xVoTdC2GMqSv8LEH0Alarao6q7gGmAecG76Cqc1R1p7e4AGjrzQ8EPlDVrar6C/ABMMjHWCOWnm5NXY0xdUOCj8/dBlgXtLweVyII52rg3+Uc26bsASIyHBgOkJqaSnZ2dqWDzc/Pj+j4wsJUSkqO5vXXP6Nt212Vfr2KijS+WLH4omPxRcfi84efCSJiInIZ0AM4uSLHqerzwPMAPXr00KysrErHkJ2dTSTHJyXBww9D8+a9ieLlKizS+GLF4ouOxRcdi88ffl5i2gC0C1pu663bh4icCtwJnKOqBRU5Nhas229jTF3hZ4JYCKSLSAcRSQKGAtODdxCRY4HncMnh56BNM4EBItLMq5we4K2LuVatrKmrMaZu8O0Sk6oWicgI3Ik9HpikqstFZBywSFWnA48CKcAbIgKwVlXPUdWtInI/LskAjFPVrX7FWhGBXl2tBGGMqe18rYNQ1RnAjDLr7g6aP7WcYycBk/yLLsj8+Rw+ZQokJ0Nm5gF3T0+HRYuqIS5jjIkhu5N61iw46SQ6TJoE/fvD/PkHPCTQq2thof/hGWNMrFiC+PhjKCpCSkrczQ0RNEVLT4fiYuvV1RhTu1mCOOssSEx08/HxRNJ21VoyGWPqAksQmZnw4YfsadLENVE67rgDHhLo1dVaMhljajNLEAAnncTKO+6ADRvgz38+4O6tWkGjRlaCMMbUbhElCBG5WUQai/OiiCwRkQF+B1edtvbqBWefDfffDz/9VO6+gV5drQRhjKnNIi1BDFPVPNwNa82Ay4HxvkUVK48/7iqqR+/XM/l+7F4IY0xtF2mCEO/xDOAVVV0etK72SEuDW2+Fl1+Gzz4rd9f0dPj+e2vqaoypvSJNEItFZBYuQcwUkUZAiX9hxdCdd0Lr1nDjjVAS/k9MS3NNXX/4oRpjM8aYahRpgrgaGA309MZvSASu8i2qWGrUyHXXunChK0mEYS2ZjDG1XaQJIhP4VlW3eV1z3wXk+hdWjF16KRx/vKuLyMsLuYvdC2GMqe0iTRDPAjtF5BjgNuA7IPzP64NdXBw89RRs3OhaNYVwyCGQkmIlCGNM7RVpgihSVcUNGTpBVZ8BGvkXVg3QsycMG+bui/j22/02B5q6WgnCGFNbRZogtovIGFzz1vdEJA5XD1G7PfQQ1K/vWjaFkJZmJQhjTO0VaYIYAhTg7of4H26Et0d9i6qmSE2Fu++Gf/8b3ntvv83p6darqzGm9oooQXhJYQrQRETOAnarau2tgwh2443QqZMrRezZs8+mtDQoKrKmrsaY2inSrjYuAj4HLgQuAj4TkcF+BlZjJCXBk0+6a0ll+mkKNHW1eghjTG0U6SWmO3H3QFyhqr8FegFj/Qurhhk0yHULPm7cPv00BZq6Wj2EMaY2ijRBxKnqz0HLWypwbO3w+ONQUABjxuxdlZrqmrpaCcIYUxtFepJ/X0RmisiVInIl8B5lxpqu9dLTYeRIeOmlvf00iVinfcaY2ivSSuo/AM8D3bzpeVUddaDjRGSQiHwrIqtFZL8uUkXkJK/r8KKydRoiUiwiS71pemR/js9C9NNk3X4bY2qriC8TqepbqjrSm94+0P4iEg88A5wOdAYuFpHOZXZbC1wJvBbiKXapandvOifSOH3VqBGMH79PP01paa5X16KiGMdmjDFVrNwEISLbRSQvxLRdREJ3UlSqF7BaVXNUdQ8wDXcn9l6qukZVv+Jg6hn2ssv26acpPd2auhpjaidxPWj48MTuktEgVb3GW74c6K2qI0LsOxn4l6q+GbSuCFgKFAHjVfWdEMcNB4YDpKamZkybNq3S8ebn55OSkhLRvo1WriTj+utZO2QI75wwiptvPpZBg37irLN+okuXA+VN/+OLBYsvOhZfdCy+yuvXr99iVe0RcqOq+jIBg4EXgpYvx/XjFGrfycDgMuvaeI8dgTXAkeW9XkZGhkZjzpw5FTvgqqtUExP1X8+tU1AVUa1fX3XevKjCCKvC8VUziy86Fl90LL7KAxZpmPOqn01VNwDtgpbbeusioqobvMccIBs4tiqDi9of/wj16/PVnz4EQNXdaJ2dHduwjDGmqviZIBYC6SLSQUSSgKFARK2RRKSZiCR78y2BPsAK3yKtDK+fpqz/Pke9xGLANXvNyoptWMYYU1V8SxCqWgSMAGYC3wCvq+pyERknIucAiEhPEVmP68LjORFZ7h1+NLBIRL4E5uDqIGpWggC48UYyO/3CR00voFebDWhJCS1axDooY4ypGgl+PrmqzqDMDXWqenfQ/ELcpaeyx80DuvoZW5VISoJrryVz5Eim8xlprGLU7wp5++PmsY7MGGOiVre6y/DD7t0gQiobGc3DvDO3OXPnxjooY4yJniWIaGVlQb16IMKtPE6blG3cfvveG62NMeagZQkiWpmZMHs2jBtHgxMzeCj/JhYuhChuyTDGmBrBEkRVyMyEu+6CDz7gsqwNHMsSxtyyk927Yx2YMcZUniWIqlSvHnHT3+Gxo/7K2k0N+PPNObGOyBhjKs0SRFVr1IhT/nM/Z6XM4aHnW7Bp9lexjsgYYyrFEoQfWrbkkelHs4OG3HfWQli5MtYRGWNMhVmC8MnR/Q5l+CX5TNx9Bd9mXQtr18Y6JGOMqRBLED6694mmNGgojNryf3DaafDzzwc+yBhjaghLED465BAYc2c87xadycdrjoBBgyA3N9ZhGWNMRCxB+OyWW6BdO7jtiDco+Xo5nH027NwZ67CMMeaALEH4rH59eOghWLyqCa9d+zF8+ilceCEUFsY6NGOMKZcliGpwySVw3HFwx/Tj2fXUX2HGDLjiCuuPwxhTo1mCqAZxcfCnP8G6dfDk9qth/HiYOhVGjHAjDRljTA3ka3ffplRWFpxzjhuI7urVozhk61Z45BFo3hweeCDW4RljzH4sQVSjhx+GX/8a7rsPnpkwHn75BR580LVsOuwwl0UyM2MdpjHGAJYgqtWvfgXXXQcTJ8KIEcLRzz4L330HEya48UqTk+GjjyxJGGNqBKuDqGb33AMNG8KoUUB8PPTr55KDqht86JZbYM2aWIdpjDGWIKpbq1Zwxx3wz3/CnDlA//5uwKH4eDctWQLp6XD11bB6dazDNcbUYZYgYuCmm+Dww+G226Cktzfg0P33wyefwPffw/XXw2uvQadOcPnl1tmfMSYmfE0QIjJIRL4VkdUiMjrE9pNEZImIFInI4DLbrhCRVd50hZ9xVrfAzXNffAFTpuDqHMaMcY9t28JTT7lEceut8I9/QOfOdL7vPvj6a38Cmj/fNa+aP9+f5zfGHJR8SxAiEg88A5wOdAYuFpHOZXZbC1wJvFbm2ObAPUBvoBdwj4g08yvWWLj4YujRw11uCtnzxqGHwmOPufqI0aNp/tln0K0bXHCByyzRKCiAr75y46JedRX07etGxOvf35KEMWYvP1sx9QJWq2oOgIhMA84FVgR2UNU13raytxQPBD5Q1a3e9g+AQcBUH+OtVoGb504+GUaOhCOOCNPKtVUreOghFhx/PCcuXgx//jO8/TaceSaMHQu9e4d/kYIC+PZbWL4cVqxwj8uXu5ZTxcVun0AFOcCuXfDWW9aKyhgD+Jsg2gDrgpbX40oElT22TdmdRGQ4MBwgNTWV7OzsSgUKkJ+fH9XxldWt2zE891xT4uIgMbGEP/3pS7p0yds/vrg4svv1I75nT9q+/TZt33yTxOOPZ2uPHmzq04eG69ZR2LgxUlxMwzVraLhmDfU3bEC87jw0Lo5dbdqwo317dvTuzc727dlxxBEkbN9Ot9GjiduzB1Qpeeop1mzfzvoLL0QTIv94xOr9i5TFFx2LLzo1Pb6wVNWXCRgMvBC0fDkwIcy+k4HBQcu3A3cFLY8Fbi/v9TIyMjQac+bMier4yho5UtX9hFeNj1d96KHQ++0XX16e6sMPqzZtWvoEoBoXp9qpk+oFF6jedZfq1KmqX32lunt3+CDmzXMv/O67qued557nmGNUP/884r8jVu9fpCy+6Fh80anJ8QGLNMx51c8SxAagXdByW29dpMdmlTk2u0qiqmEGD3b3ye3Z4/ru69o1wgMbNYL/+z93Wei++1x6iI93N1qMHVuxIDIzSy8rnXOOu4R1ww1w/PGuydX990NKSsWe0xhz0POzFdNCIF1EOohIEjAUmB7hsTOBASLSzKucHuCtq3UyMyE7G4YNg6Qk13Dphx8q8AQDBpTeR5GUBKeeGn1Q558P33wD114LTz4JXbq4HmiNMXWKbwlCVYuAEbgT+zfA66q6XETGicg5ACLSU0TWAxcCz4nIcu/YrcD9uCSzEBjnrauVMjPhxRfdjXObN8OJJ7q65YgPDtxHMXt21VUwN2kCf/mLG7+iYUNXKX7xxbBxY9U8f7B//tOVfKwFlTE1iq99ManqDGBGmXV3B1Tj6L4AABlZSURBVM0vxF0+CnXsJGCSn/HVNIHSxIABruXprFnQvXuEB/rV8qhPH9es9uGHXceCM2e65rdXXeVaQFVUYSEsXQrz5rlpzhzYtMltu/9+6NULTjjBlVo6d3ZTkyZV+zcZYyJinfXVMMcc426oPvVU1+x1xgx3voyp5GS4+2646CIYPtx1A/LKK/D8865bkPJs2uRKBoGEsHCh63MK3O3krVu7YlOgqe3atfDll6X7ALRpU5osOncuTR7NvFtj5s93mdV6wzWxUIs/f5YgaqCjjnJXdk49FU47Dd59FyrQ4tQ/v/qV+yK8+CL84Q+uRv3uu+HEEzl8yhQXZJMmpclg/nxYtcodm5johtW7/vrSEk/btm6f/v1dLX1SkrsPo1cvVxETuH8jcA/HX/+6712Fhx7qnmPpUndfR1KSS1znn19D3jATkVifYCvy+gUFrpv+X36BrVvdsXfeCUVF7jP3zDPu5qYWLdx3IT7en5hVIT/fDRWQnQ2LF7sfcFX8/tm3qIY6/HBXkjjttMA9cS3Jyop1VLg7/H73OzjrLLj5ZvflEKGDKrzwQul+rVq5os8117jHjAzXx0hZgTqUsl/Qjh3ddPbZpfuWlLgSRnDi+PBD9+UE9+W96CL3RW3f3pVu0tIgLY3mO3e6MTfat3eJxFSdcCfYggLYvh3y8kJP27e7/+Grr7oEn5DgWmn06uVOsMFTcnK5r3/4lClunwOdIEtKSmPKzYX//Me11CsqcifzK690LfaCk0Bg/pdfwnR74Nmzx303AkRcKbd5c45LSIAOHdwAYS1a7Pu4caPrRufIIyE11cW1bdu+j2Xnc3P3H7L4ueeqth4SEK0lQ1726NFDFy1aVOnjs7OzyaoRZ+B9bd0KZ5wBCxcqkycLl18e64jK+O1v3a92cF+I3/zG9et05JGVq6OoqOASSEKC6wERXE+4q1a5x+3bS/ePj3e3rXuJg7Q0d3L48UfXxLdfP/9jDvE35EyaRMdhwyr35a7IL+CSEtc0eufO0mnBAjd16eKS8u7d+03fr1hBh9at99+2YYP7JVNS4v7frVu7/0Venns8kOA7+cuTkrJvwmjZ0j3u3AmvvIIWFSEJCe4HQkrKvifSQDLIzXWfhQO9XsOG7sTdrFnpFLwcPL9+vRs6uLDQff4efBAOOcR9cbds2fu4dfVqmkPputzcA78vTZq4qWnTfR+D5+fNc5cYSkrcZ/v++12/bhUgIotVtUfIbZYgnJqaIMB9pk8++Re++KIZzzwDv/99rCMK4p2gSwoKiEtOrvJfMBHHEO4EqQqbNrHk9dc5rnFjlzAC06pV7ldZsObNXS+6gRJMhw6lj23aRHfJoKTE/Qr9+efSacECeOqpfU9wrVsH3/pY/vTTT64VWEmJK90df7xr9hw4+ZdNBsF1OxUVF+dKgfXqual+fffhDG7ZdswxrsTYuLGbGjUqnQ81ffmlu5YauMQ4bZpL4Fu27Dtt3hx6uez/Lz6+9PJOkybuNQLzoZY3bIDRo92PhMRE1wjjpJMq9r5EkKD3O78UFrrY//hH131O4AR/222uVJ6S4t7vSF47+BJtJb5/liAiUJMTBMCsWXOZMOEk/vlP95kavV/fuDEU7S/gahD2/zt2rOtaN/ALOCPDndRycmDdun2L8YmJ7hJVcNLo2NGdJBctcsstWrgT/8aN+yaCn392FfaBy2HhJCS4L7pIZNOuXbBjR+nxrVu7OBo0KH+qX989zpoFb7xRmmCuu85NwYmgXj0+/uwzTu7ff/94q+AEFVUdxCefwIABlOzZU/kfKNVQBxL28xfr94/yE4TVQRwkkpJKeOstd4l0zJjSHx/VcRXngDIzWVtQQMcamhzKdcYZrtfEwBf0qadKv2SFha7OIyfHdb8e/LhokbtUEE6DBu568iGHuAqlHj3cfGBdYFq7Fi68sPIlsFCV/BU5/uijYfr00uMvuyzk7fwaruQUrg6pIqJppt23L3z0EWui+YHiZzPxSF47lu/fAViCOIgkJrrL/Y0bu9sS8vJcNx2RlERNGOV9QRMTXV3KkUeGPjY313WT/pe/lF4iuPVWuPdedx07El27wuzZlT/BRXuCqeEnqEhf/6D9gQKxf//KYQniIBMX585HjRvDI4+4JPG3v7lzmamkyn5BmzSBSy5xzX4Dv8AvuCDy5BD0+lGd4KI9wdTgE5SJLUsQByERGD/enZ/uvNNdpTjtNFfXZ9/zalYVv8CNqaEsQRykRNxodFu2wOOPu7q6Bx90PVfYOaqa2S9wU0vZ1euDXMuWpXUQBQXuEviBmlgbY0wkLEEc5LKy3A2k8fGuheTnn7tuit55J9aRGWMOdpYgDnLBvX3PnQuffeZKFeef725q/vHHWEdojDlYWYKoBTIz3b0RmZnQs6drov/HP7qeYI8+GiZO3L/bFmOMORBLELVQYqK70/rrr939Wddf7zqYXLky1pEZYw4mliBqsbQ019np3/7mOkA95hgYNy6yPtSMMcYSRC0n4rrnWLnS1Unccw8ce6zr5dgYY8pjCaKOOOQQeO01eO89N87IiSe6XmGtSawxJhy7Ua6OOeMMd7lp7FjXL92778KNN7qeo+1GYGNMMF9LECIySES+FZHVIrJfB9Uikiwif/e2fyYi7b317UVkl4gs9aaJfsZZ16SkwBNPuKEI6td3LaDuuMONlTNvXqyjM8bUFL4lCBGJB54BTgc6AxeLSOcyu10N/KKqacATwMNB275T1e7edJ1fcdZlPXu6+olAl+EFBTBkiBt/ppYME2KMiYKfJYhewGpVzVHVPcA04Nwy+5wLvOTNvwn0F6kRIxzUGf37uzFh4uNd89iiIjfy5jHHuMG9iotjHaExJlb8TBBtgHVBy+u9dSH3UdUiIBdo4W3rICJfiMjHItLXxzjrtOA7sT/+2PUM+/LLLlFcfDH86lelvVkbY+oW34YcFZHBwCBVvcZbvhzoraojgvZZ5u2z3lv+DugNbAdSVHWLiGQA7wBdVDWvzGsMB4YDpKamZkybNq3S8ebn55OSklLp4/1W3fGVlMCnn7bk1VePYNWqRrRqtZshQ9Zx5pk/Ua/e/rdl2/sXHYsvOhZf5fXr1y/skKOoqi8TkAnMDFoeA4wps89MINObTwA24yWtMvtlAz3Ke72MjAyNxpw5c6I63m+xiq+kRPX991X79lUF1VatVB96SHXbtpoRX6QsvuhYfNGpyfEBizTMedXPS0wLgXQR6SAiScBQYHqZfaYDV3jzg4GPVFVFpJVXyY2IdATSgRwfYzVhiMDAga4jwLlzXdcdd9wBRxzhRtvctMkNizxlyuHMnx/raI0xVcm3BKGuTmEErpTwDfC6qi4XkXEico6324tACxFZDYwEAk1hTwK+EpGluMrr61S1nBHiTXXo29d1ALh4sRvB7qGHoF07OOkkmDSpA/37Y0nCmFrE1xvlVHUGMKPMuruD5ncDF4Y47i3gLT9jM5V33HHwxhvwzTdw2WWwZAmAsGsXTJgAGRlueGZjzMHNutowlXb00S4h1KsHIoqI686jbVv4v/+D//431hEaY6JhCcJEJTMTPvoIrr76e+bOdZegTjzRjZPdqZPrvmPKFNi9O9aRGmMqyhKEiVpmJlx66VpOPBFOPx3+8Q9Yv94NWrRunbsMddhhcPPNsGxZrKM1xkTKEoTxxaGHukGLVq1yY1IMGOBGtuva1SWUSZNgx45YR2mMKY8lCOOruDjXnce0abBhA/zpT7BtG1x9NbRuDddd5wY0+uMfrQWUMTWNdfdtqk3LljByJNx6qxuw6K9/dcnhuefc9vh4Nzzq0KGupVT9+rGN15i6zkoQptqJuIrsl16CUaNKe5MtLnatok48ERo3dr3N3nijaxmVk2M9zBpT3awEYWLq9NPhscdcZ4BJSe7+iqIiN1bFggWuhDFhgtu3VSs4/vjSqWdPaNTIXZrKzrYBj4ypapYgTEwFepMte4I/1+sYvqjIjYAXSBjz57vxKsDVb3ToAGvWuM4Fk5Jg5kw4+eQY/CHG1EKWIEzMZWaG/+WfkODGpjjmGLj2Wrdu61b4/HOXMF57rXTMioICOOUUt++xx7p6jOOOg27dqufvMKa2sQRhDjrNm8OgQW4aONC1ktqzx1VyDxkCGzfC9OmuKS24kka7dj3p27c0aXTvDk2auO12icqY0CxBmINauEtUqu5mvS++cH1FffDBLubMacirr5Yee+SRrlfaTz5xpZCkJHfPRp8+sfhLjKl5LEGYg16oS1QirqfZdu3cEKpZWcvIyspi48bSpLFkiesmpLDQHbN7N/Tr50oXnTtDly6lU7t2riRiTF1iCcLUKamppZenwF1e6t/f1V/Ex8N557k6jpkzXTPcgJQU1zlhIGEEEsjhh7u6ELtEZWojSxCmTgt3iQpcolixwrWiWr7czb//PkyeXLpP/fouuZSUQGKiG9v7/POhY0dXwW7Mwcw+wqbOC9eKqnlzd9PeiSfuuz44cbz0UmkXIYWFrv+p0aNdskhPh1/9ypU8Ao+dOrnSiDEHA0sQxlRQcOLo1q20FVVSEjz9tCs5fPMNrFzpeq99993SprjgxssIThrFxTB37pHs3OlG6ktMjN3fZkwwSxDGRKG8S1QBe/bA6tUuYQQSxzfflO3Rth1vvOHmGjaEpk3d1KzZvo+h5n/4wZVoTj/dxWBMVbEEYUyUyrvRD1zJonNnNwVThTFj4NFHXR1GXJy70a9bN9fj7S+/uMf1611JZNs2yM0N3yfVI4+40f0OPdR1jNiqlZsC86HWNW0afSW73UdSe1mCMCZGRFyXIk89BQUFJSQnxzFuXPkn2ZISyMsrTSB/+YsriZSUuOfLyHDdj2zeDD//7OpJNm+GnTtDP19cnDs2EM/RR8Mhh7jK9+Bp69Y03n9///WBgaGKitylsZdfdk2FmzaN/FKZJZiay9cEISKDgD8D8cALqjq+zPZk4GUgA9gCDFHVNd62McDVQDFwk6rO9DNWY2IhcIlq0qQ1DBvW8YAnyLi40stL7dvDsGFuSNdAHcijj4Y+ye7cCZs2uWSxaVPp/Lvvwty5rlSi6p6nqMgll127Sqft2w/lX/9y28MpKHB3sgc0aFAaa7hpyxZ44onSBPPoo64ElZjo6nICU3nLixfDa68dTnKylYCqmm8JQkTigWeA04D1wEIRma6qK4J2uxr4RVXTRGQo8DAwREQ6A0OBLsBhwIcicpSqFmNMLZOZCQUFa8nM7FipYw9UBwLuZH3EEW4Kdvzx+1ayv/xy6OfIzv6UrKwsiovdDYWBxPGf/8CVV7oWXAkJrgVXq1auhFN22rgRvv22dLm4zLe5oABuuqnCb4GnI5MmuVJNSsr+JZ1w09atMHWqiyUhAUaMgKOOcgkokIQC8+HWrVjhbrrs3dv1MBwf76aEhNL5/Px48vP3XRe48TLaBOVngvOzBNELWK2qOQAiMg04FwhOEOcC93rzbwITRES89dNUtQD4XkRWe89nY44ZU8aB6kAOdGwkCSYgPt5Vojds6JaHDnVJp6InKFVXQT97tnuOQIJ5/HHXuquoyE2FhaXzoZb//W83qbpLZMcd54a1DS797NrlSlC//LL/+h07Si+xFRa60ow/+u63RsQlieBE2aCBS9RxcZFNBQXuMp+qS3izZ1dtkvAzQbQB1gUtrwd6h9tHVYtEJBdo4a1fUObYNv6FakzdFU2CqezxIu6X/rnnuu5OKvsLOCMD5swprcMJd4ktnMCd9IES1Ftvua5WCgtLk1FgPtS6qVPdJb5AI4Pf/Ma1JisudlNRkXtcuXI1HTqk7bPONW8uvcQn4l67Rw/3fJFMy5bBOu8su2ePex8PlgThOxEZDgwHSE1NJTs7u9LPlZ+fH9XxfrP4omPxRcfv+NxlNneCq6hHH23M55/Xp1evXRQU5FX4OR59tDFLlzale/dt1K+fx7ffHviYQP1H796Nef31YygsFBITlZNP/pIOHfL2279jx3xSUtbvtz41tTELFpQef8klX9Kly/7Hh7N8eWNuu80dn5CgNG78JdnZkR9/QKrqywRkAjODlscAY8rsMxPI9OYTgM2AlN03eL9wU0ZGhkZjzpw5UR3vN4svOhZfdCy+8ObNU33oIfcYTnnxRXJ8tK9fHmCRhjmv+lmCWAiki0gHYAOu0vmSMvtMB67A1S0MBj5SVRWR6cBrIvI4rpI6Hfjcx1iNMaZSYnGJriqPL49vCUJdncII3K//eGCSqi4XkXG4jDUdeBF4xauE3opLInj7vY6r0C4CblBrwWSMMdXK1zoIVZ0BzCiz7u6g+d3AhWGOfRB40M/4jDHGhGdDoBhjjAnJEoQxxpiQLEEYY4wJyRKEMcaYkETD9R18kBGRTcAPUTxFS9x9GDWVxRcdiy86Fl90anJ8R6hqq1Abak2CiJaILFLVHrGOIxyLLzoWX3QsvujU9PjCsUtMxhhjQrIEYYwxJiRLEKWej3UAB2DxRcfii47FF52aHl9IVgdhjDEmJCtBGGOMCckShDHGmJDqVIIQkUEi8q2IrBaR0SG2J4vI373tn4lI+2qMrZ2IzBGRFSKyXERuDrFPlojkishSb7o71HP5HOcaEfnae/1FIbaLiDzlvYdfichx1Rhbp6D3ZqmI5InILWX2qdb3UEQmicjPIrIsaF1zEflARFZ5j83CHHuFt88qEbmiGuN7VERWev+/t0WkaZhjy/0s+BjfvSKyIeh/eEaYY8v9vvsY39+DYlsjIkvDHOv7+xe1cANF1LYJ1+X4d0BHIAn4EuhcZp/fAxO9+aHA36sxvtbAcd58I+C/IeLLAv4V4/dxDdCynO1nAP/GDfx0PPBZDP/f/8PdBBSz9xA4CTgOWBa07hFgtDc/Gng4xHHNgRzvsZk336ya4hsAJHjzD4eKL5LPgo/x3QvcHsH/v9zvu1/xldn+J+DuWL1/0U51qQTRC1itqjmqugeYBpxbZp9zgZe8+TeB/iIi1RGcqv6kqku8+e3ANxyc43CfC7yszgKgqYi0jkEc/YHvVDWau+ujpqpzcWOdBAv+nL0EnBfi0IHAB6q6VVV/AT4ABlVHfKo6S1WLvMUFQNuqft1IhXn/IhHJ9z1q5cXnnTsuAqZW9etWl7qUINoA64KW17P/CXjvPt4XJBdoUS3RBfEubR0LfBZic6aIfCki/xaRLtUamKPALBFZ7I0JXlYk73N1GEr4L2as38NUVf3Jm/8fkBpin5ryPg7DlQhDOdBnwU8jvEtgk8JcoqsJ719fYKOqrgqzPZbvX0TqUoI4KIhICvAWcIuqlh19fAnukskxwNPAO9UdH3Ciqh4HnA7cICInxSCGcolIEnAO8EaIzTXhPdxL3bWGGtnWXETuxI3oOCXMLrH6LDwLHAl0B37CXcapiS6m/NJDjf8u1aUEsQFoF7Tc1lsXch8RSQCaAFuqJTr3mom45DBFVf9Rdruq5qlqvjc/A0gUkZbVFZ/3uhu8x5+Bt3FF+WCRvM9+Ox1Yoqoby26oCe8hsDFw2c17/DnEPjF9H0XkSuAs4FIvie0ngs+CL1R1o6oWq2oJ8Ncwrxvr9y8BuAD4e7h9YvX+VURdShALgXQR6eD9whwKTC+zz3Qg0FpkMPBRuC9HVfOuV74IfKOqj4fZ59BAnYiI9ML9/6ozgTUUkUaBeVxl5rIyu00Hfuu1ZjoeyA26nFJdwv5yi/V76An+nF0BvBtin5nAABFp5l1CGeCt852IDAL+DzhHVXeG2SeSz4Jf8QXXaZ0f5nUj+b776VRgpaquD7Uxlu9fhcS6lrw6J1wLm//iWjfc6a0bh/siANTDXZZYDXwOdKzG2E7EXWr4CljqTWcA1wHXefuMAJbjWmQsAE6o5vevo/faX3pxBN7D4BgFeMZ7j78GelRzjA1xJ/wmQeti9h7iEtVPQCHuOvjVuHqt2cAq4EOgubdvD+CFoGOHeZ/F1cBV1Rjfatz1+8DnMNCy7zBgRnmfhWqK7xXvs/UV7qTfumx83vJ+3/fqiM9bPznwmQvat9rfv2gn62rDGGNMSHXpEpMxxpgKsARhjDEmJEsQxhhjQrIEYYwxJiRLEMYYY0KyBGFMDeD1MvuvWMdhTDBLEMYYY0KyBGFMBYjIZSLyudeH/3MiEi8i+SLyhLhxPGaLSCtv3+4isiBoXIVm3vo0EfnQ6zBwiYgc6T19ioi86Y3FMKW6ehI2JhxLEMZESESOBoYAfVS1O1AMXIq7e3uRqnYBPgbu8Q55GRilqt1wd/4G1k8BnlHXYeAJuDtxwfXgewvQGXenbR/f/yhjypEQ6wCMOYj0BzKAhd6P+/q4jvZKKO2U7VXgHyLSBGiqqh97618C3vD632mjqm8DqOpuAO/5Plev7x5vFLL2wKf+/1nGhGYJwpjICfCSqo7ZZ6XI2DL7Vbb/moKg+WLs+2lizC4xGRO52cBgETkE9o4tfQTuezTY2+cS4FNVzQV+EZG+3vrLgY/VjRa4XkTO854jWUQaVOtfYUyE7BeKMRFS1RUichduFLA4XA+eNwA7gF7etp9x9RTguvKe6CWAHOAqb/3lwHMiMs57jgur8c8wJmLWm6sxURKRfFVNiXUcxlQ1u8RkjDEmJCtBGGOMCclKEMYYY0KyBGGMMSYkSxDGGGNCsgRhjDEmJEsQxhhjQvp/nqUxmNHbLA4AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "Ze7CRmyINZBh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# iris data practice\n",
        "1. train, test \n",
        "2. 딥러닝 모델 업데이트, 베스트 모델 생성\n",
        "3. 그래프 확인\n",
        "4. 학습 자동 중단 설정\n",
        "5. [5.2, 2.6, 1, 1.2] 품종 예측\n",
        "6. [6.7, 2.8, 6.6, 2] 품종 예측"
      ],
      "metadata": {
        "id": "i_iWogfCgr3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "CV3psOwkLRpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/deeplearning/data/iris3.csv')"
      ],
      "metadata": {
        "id": "HIg0DvoOLRhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "uBmy_s9tf_r0",
        "outputId": "2ad52a3b-1e5c-45a8-8328-d7af6d9f7abe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sepal_length  sepal_width  petal_length  petal_width         species\n",
              "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
              "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
              "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
              "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
              "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
              "..            ...          ...           ...          ...             ...\n",
              "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
              "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
              "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
              "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
              "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
              "\n",
              "[150 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e8959eb3-dc1e-4b4a-a00c-a6e499aeb477\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e8959eb3-dc1e-4b4a-a00c-a6e499aeb477')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e8959eb3-dc1e-4b4a-a00c-a6e499aeb477 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e8959eb3-dc1e-4b4a-a00c-a6e499aeb477');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:,0:4]\n",
        "y = df.iloc[:, -1]\n",
        "y = pd.get_dummies(y)"
      ],
      "metadata": {
        "id": "CWSnyvw8f_9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "PVeOThVMh4N7",
        "outputId": "0791f959-cd70-4a0a-c3a0-983d508e5f0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sepal_length  sepal_width  petal_length  petal_width\n",
              "0             5.1          3.5           1.4          0.2\n",
              "1             4.9          3.0           1.4          0.2\n",
              "2             4.7          3.2           1.3          0.2\n",
              "3             4.6          3.1           1.5          0.2\n",
              "4             5.0          3.6           1.4          0.2\n",
              "..            ...          ...           ...          ...\n",
              "145           6.7          3.0           5.2          2.3\n",
              "146           6.3          2.5           5.0          1.9\n",
              "147           6.5          3.0           5.2          2.0\n",
              "148           6.2          3.4           5.4          2.3\n",
              "149           5.9          3.0           5.1          1.8\n",
              "\n",
              "[150 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7125b811-0dfe-42bb-8378-f2a06a0979ff\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7125b811-0dfe-42bb-8378-f2a06a0979ff')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7125b811-0dfe-42bb-8378-f2a06a0979ff button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7125b811-0dfe-42bb-8378-f2a06a0979ff');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "f7TW9erXh5H0",
        "outputId": "7719c3cb-3c2e-464b-f97d-e75abc451108"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Iris-setosa  Iris-versicolor  Iris-virginica\n",
              "0              1                0               0\n",
              "1              1                0               0\n",
              "2              1                0               0\n",
              "3              1                0               0\n",
              "4              1                0               0\n",
              "..           ...              ...             ...\n",
              "145            0                0               1\n",
              "146            0                0               1\n",
              "147            0                0               1\n",
              "148            0                0               1\n",
              "149            0                0               1\n",
              "\n",
              "[150 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-76eff8c9-a01d-43fb-8c5e-6738912307f2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Iris-setosa</th>\n",
              "      <th>Iris-versicolor</th>\n",
              "      <th>Iris-virginica</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-76eff8c9-a01d-43fb-8c5e-6738912307f2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-76eff8c9-a01d-43fb-8c5e-6738912307f2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-76eff8c9-a01d-43fb-8c5e-6738912307f2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(24, input_dim=4, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "accuracy = model.evaluate(X_test, y_test)[1]\n",
        "\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)\n",
        "\n",
        "modelpath=\"iris_bestmodel.hdf5\"\n",
        "\n",
        "# 최적화 모델을 업데이트하고 저장\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=2000, batch_size=500, validation_split=0.25, verbose=1, callbacks=[early_stopping_callback, checkpointer])\n",
        "model.evaluate(X_test, y_test)\n",
        "\n",
        "test1 = [5.2, 2.6, 1, 1.2] \n",
        "test2 = [6.7, 2.8, 6.6, 2] \n",
        "\n",
        "model.predict([test1])\n",
        "model.predict([test2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7n6bA6SgQvk",
        "outputId": "e216d4b7-81e5-4dfd-9605-b53c52d321d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 227ms/step - loss: 1.1132 - accuracy: 0.3667\n",
            "Epoch 1/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1261 - accuracy: 0.3222\n",
            "Epoch 1: val_loss improved from inf to 1.12125, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 1.1261 - accuracy: 0.3222 - val_loss: 1.1213 - val_accuracy: 0.4000\n",
            "Epoch 2/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1000 - accuracy: 0.4667\n",
            "Epoch 2: val_loss improved from 1.12125 to 1.09465, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1.1000 - accuracy: 0.4667 - val_loss: 1.0946 - val_accuracy: 0.6000\n",
            "Epoch 3/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0751 - accuracy: 0.6111\n",
            "Epoch 3: val_loss improved from 1.09465 to 1.06919, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.0751 - accuracy: 0.6111 - val_loss: 1.0692 - val_accuracy: 0.6333\n",
            "Epoch 4/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0516 - accuracy: 0.6667\n",
            "Epoch 4: val_loss improved from 1.06919 to 1.04483, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.0516 - accuracy: 0.6667 - val_loss: 1.0448 - val_accuracy: 0.6333\n",
            "Epoch 5/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0297 - accuracy: 0.6667\n",
            "Epoch 5: val_loss improved from 1.04483 to 1.02274, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.0297 - accuracy: 0.6667 - val_loss: 1.0227 - val_accuracy: 0.6333\n",
            "Epoch 6/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0112 - accuracy: 0.6667\n",
            "Epoch 6: val_loss improved from 1.02274 to 1.00555, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.0112 - accuracy: 0.6667 - val_loss: 1.0056 - val_accuracy: 0.6333\n",
            "Epoch 7/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9969 - accuracy: 0.6667\n",
            "Epoch 7: val_loss improved from 1.00555 to 0.99088, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.9969 - accuracy: 0.6667 - val_loss: 0.9909 - val_accuracy: 0.6333\n",
            "Epoch 8/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9850 - accuracy: 0.6667\n",
            "Epoch 8: val_loss improved from 0.99088 to 0.97984, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.9850 - accuracy: 0.6667 - val_loss: 0.9798 - val_accuracy: 0.6333\n",
            "Epoch 9/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9746 - accuracy: 0.6667\n",
            "Epoch 9: val_loss improved from 0.97984 to 0.96989, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.9746 - accuracy: 0.6667 - val_loss: 0.9699 - val_accuracy: 0.6333\n",
            "Epoch 10/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9654 - accuracy: 0.6667\n",
            "Epoch 10: val_loss improved from 0.96989 to 0.96100, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.9654 - accuracy: 0.6667 - val_loss: 0.9610 - val_accuracy: 0.6333\n",
            "Epoch 11/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9566 - accuracy: 0.6667\n",
            "Epoch 11: val_loss improved from 0.96100 to 0.95223, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.9566 - accuracy: 0.6667 - val_loss: 0.9522 - val_accuracy: 0.6333\n",
            "Epoch 12/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9483 - accuracy: 0.6667\n",
            "Epoch 12: val_loss improved from 0.95223 to 0.94363, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.9483 - accuracy: 0.6667 - val_loss: 0.9436 - val_accuracy: 0.6333\n",
            "Epoch 13/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9400 - accuracy: 0.6667\n",
            "Epoch 13: val_loss improved from 0.94363 to 0.93519, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.9400 - accuracy: 0.6667 - val_loss: 0.9352 - val_accuracy: 0.6333\n",
            "Epoch 14/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9318 - accuracy: 0.6667\n",
            "Epoch 14: val_loss improved from 0.93519 to 0.92684, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 0.9318 - accuracy: 0.6667 - val_loss: 0.9268 - val_accuracy: 0.6333\n",
            "Epoch 15/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9235 - accuracy: 0.6667\n",
            "Epoch 15: val_loss improved from 0.92684 to 0.91860, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.9235 - accuracy: 0.6667 - val_loss: 0.9186 - val_accuracy: 0.6333\n",
            "Epoch 16/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9152 - accuracy: 0.6667\n",
            "Epoch 16: val_loss improved from 0.91860 to 0.91047, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.9152 - accuracy: 0.6667 - val_loss: 0.9105 - val_accuracy: 0.6333\n",
            "Epoch 17/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9068 - accuracy: 0.6667\n",
            "Epoch 17: val_loss improved from 0.91047 to 0.90262, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.9068 - accuracy: 0.6667 - val_loss: 0.9026 - val_accuracy: 0.6333\n",
            "Epoch 18/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8985 - accuracy: 0.6667\n",
            "Epoch 18: val_loss improved from 0.90262 to 0.89534, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.8985 - accuracy: 0.6667 - val_loss: 0.8953 - val_accuracy: 0.6333\n",
            "Epoch 19/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8901 - accuracy: 0.6667\n",
            "Epoch 19: val_loss improved from 0.89534 to 0.88798, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.8901 - accuracy: 0.6667 - val_loss: 0.8880 - val_accuracy: 0.6333\n",
            "Epoch 20/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8820 - accuracy: 0.6667\n",
            "Epoch 20: val_loss improved from 0.88798 to 0.88068, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.8820 - accuracy: 0.6667 - val_loss: 0.8807 - val_accuracy: 0.6333\n",
            "Epoch 21/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8739 - accuracy: 0.6667\n",
            "Epoch 21: val_loss improved from 0.88068 to 0.87392, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.8739 - accuracy: 0.6667 - val_loss: 0.8739 - val_accuracy: 0.6333\n",
            "Epoch 22/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8663 - accuracy: 0.6667\n",
            "Epoch 22: val_loss improved from 0.87392 to 0.86793, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.8663 - accuracy: 0.6667 - val_loss: 0.8679 - val_accuracy: 0.6333\n",
            "Epoch 23/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8591 - accuracy: 0.6667\n",
            "Epoch 23: val_loss improved from 0.86793 to 0.86223, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.8591 - accuracy: 0.6667 - val_loss: 0.8622 - val_accuracy: 0.6333\n",
            "Epoch 24/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8523 - accuracy: 0.6667\n",
            "Epoch 24: val_loss improved from 0.86223 to 0.85730, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.8523 - accuracy: 0.6667 - val_loss: 0.8573 - val_accuracy: 0.6333\n",
            "Epoch 25/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8463 - accuracy: 0.6667\n",
            "Epoch 25: val_loss improved from 0.85730 to 0.85265, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.8463 - accuracy: 0.6667 - val_loss: 0.8526 - val_accuracy: 0.6333\n",
            "Epoch 26/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8409 - accuracy: 0.6667\n",
            "Epoch 26: val_loss improved from 0.85265 to 0.84824, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.8409 - accuracy: 0.6667 - val_loss: 0.8482 - val_accuracy: 0.6333\n",
            "Epoch 27/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8355 - accuracy: 0.6667\n",
            "Epoch 27: val_loss improved from 0.84824 to 0.84378, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.8355 - accuracy: 0.6667 - val_loss: 0.8438 - val_accuracy: 0.6333\n",
            "Epoch 28/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8302 - accuracy: 0.6667\n",
            "Epoch 28: val_loss improved from 0.84378 to 0.83900, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.8302 - accuracy: 0.6667 - val_loss: 0.8390 - val_accuracy: 0.6333\n",
            "Epoch 29/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8246 - accuracy: 0.6667\n",
            "Epoch 29: val_loss improved from 0.83900 to 0.83366, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.8246 - accuracy: 0.6667 - val_loss: 0.8337 - val_accuracy: 0.6333\n",
            "Epoch 30/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8186 - accuracy: 0.6667\n",
            "Epoch 30: val_loss improved from 0.83366 to 0.82804, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.8186 - accuracy: 0.6667 - val_loss: 0.8280 - val_accuracy: 0.6333\n",
            "Epoch 31/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8123 - accuracy: 0.6667\n",
            "Epoch 31: val_loss improved from 0.82804 to 0.82218, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.8123 - accuracy: 0.6667 - val_loss: 0.8222 - val_accuracy: 0.6333\n",
            "Epoch 32/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8057 - accuracy: 0.6667\n",
            "Epoch 32: val_loss improved from 0.82218 to 0.81565, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.8057 - accuracy: 0.6667 - val_loss: 0.8157 - val_accuracy: 0.6333\n",
            "Epoch 33/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7988 - accuracy: 0.6667\n",
            "Epoch 33: val_loss improved from 0.81565 to 0.80863, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.7988 - accuracy: 0.6667 - val_loss: 0.8086 - val_accuracy: 0.6333\n",
            "Epoch 34/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7916 - accuracy: 0.6667\n",
            "Epoch 34: val_loss improved from 0.80863 to 0.80222, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.7916 - accuracy: 0.6667 - val_loss: 0.8022 - val_accuracy: 0.6333\n",
            "Epoch 35/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7848 - accuracy: 0.6667\n",
            "Epoch 35: val_loss improved from 0.80222 to 0.79667, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.7848 - accuracy: 0.6667 - val_loss: 0.7967 - val_accuracy: 0.6333\n",
            "Epoch 36/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7787 - accuracy: 0.6667\n",
            "Epoch 36: val_loss improved from 0.79667 to 0.79150, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.7787 - accuracy: 0.6667 - val_loss: 0.7915 - val_accuracy: 0.6333\n",
            "Epoch 37/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7735 - accuracy: 0.6667\n",
            "Epoch 37: val_loss improved from 0.79150 to 0.78693, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.7735 - accuracy: 0.6667 - val_loss: 0.7869 - val_accuracy: 0.6333\n",
            "Epoch 38/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7697 - accuracy: 0.6667\n",
            "Epoch 38: val_loss improved from 0.78693 to 0.78309, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 0.7697 - accuracy: 0.6667 - val_loss: 0.7831 - val_accuracy: 0.6333\n",
            "Epoch 39/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7664 - accuracy: 0.6667\n",
            "Epoch 39: val_loss improved from 0.78309 to 0.77990, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.7664 - accuracy: 0.6667 - val_loss: 0.7799 - val_accuracy: 0.6333\n",
            "Epoch 40/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7634 - accuracy: 0.6667\n",
            "Epoch 40: val_loss improved from 0.77990 to 0.77701, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.7634 - accuracy: 0.6667 - val_loss: 0.7770 - val_accuracy: 0.6333\n",
            "Epoch 41/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7607 - accuracy: 0.6778\n",
            "Epoch 41: val_loss improved from 0.77701 to 0.77414, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.7607 - accuracy: 0.6778 - val_loss: 0.7741 - val_accuracy: 0.6333\n",
            "Epoch 42/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7577 - accuracy: 0.6778\n",
            "Epoch 42: val_loss improved from 0.77414 to 0.77117, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.7577 - accuracy: 0.6778 - val_loss: 0.7712 - val_accuracy: 0.6333\n",
            "Epoch 43/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7547 - accuracy: 0.6778\n",
            "Epoch 43: val_loss improved from 0.77117 to 0.76795, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.7547 - accuracy: 0.6778 - val_loss: 0.7680 - val_accuracy: 0.6333\n",
            "Epoch 44/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7514 - accuracy: 0.6778\n",
            "Epoch 44: val_loss improved from 0.76795 to 0.76440, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.7514 - accuracy: 0.6778 - val_loss: 0.7644 - val_accuracy: 0.6333\n",
            "Epoch 45/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7478 - accuracy: 0.6778\n",
            "Epoch 45: val_loss improved from 0.76440 to 0.76056, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.7478 - accuracy: 0.6778 - val_loss: 0.7606 - val_accuracy: 0.6333\n",
            "Epoch 46/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7438 - accuracy: 0.6778\n",
            "Epoch 46: val_loss improved from 0.76056 to 0.75654, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.7438 - accuracy: 0.6778 - val_loss: 0.7565 - val_accuracy: 0.6333\n",
            "Epoch 47/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7397 - accuracy: 0.6778\n",
            "Epoch 47: val_loss improved from 0.75654 to 0.75244, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.7397 - accuracy: 0.6778 - val_loss: 0.7524 - val_accuracy: 0.6333\n",
            "Epoch 48/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7354 - accuracy: 0.6778\n",
            "Epoch 48: val_loss improved from 0.75244 to 0.74842, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.7354 - accuracy: 0.6778 - val_loss: 0.7484 - val_accuracy: 0.6333\n",
            "Epoch 49/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7311 - accuracy: 0.6778\n",
            "Epoch 49: val_loss improved from 0.74842 to 0.74440, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.7311 - accuracy: 0.6778 - val_loss: 0.7444 - val_accuracy: 0.6333\n",
            "Epoch 50/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7268 - accuracy: 0.6667\n",
            "Epoch 50: val_loss improved from 0.74440 to 0.74052, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.7268 - accuracy: 0.6667 - val_loss: 0.7405 - val_accuracy: 0.6333\n",
            "Epoch 51/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7226 - accuracy: 0.6667\n",
            "Epoch 51: val_loss improved from 0.74052 to 0.73674, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.7226 - accuracy: 0.6667 - val_loss: 0.7367 - val_accuracy: 0.6333\n",
            "Epoch 52/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7185 - accuracy: 0.6667\n",
            "Epoch 52: val_loss improved from 0.73674 to 0.73337, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.7185 - accuracy: 0.6667 - val_loss: 0.7334 - val_accuracy: 0.6333\n",
            "Epoch 53/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7146 - accuracy: 0.6667\n",
            "Epoch 53: val_loss improved from 0.73337 to 0.73009, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.7146 - accuracy: 0.6667 - val_loss: 0.7301 - val_accuracy: 0.6333\n",
            "Epoch 54/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7109 - accuracy: 0.6667\n",
            "Epoch 54: val_loss improved from 0.73009 to 0.72686, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.7109 - accuracy: 0.6667 - val_loss: 0.7269 - val_accuracy: 0.6333\n",
            "Epoch 55/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7072 - accuracy: 0.6667\n",
            "Epoch 55: val_loss improved from 0.72686 to 0.72374, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.7072 - accuracy: 0.6667 - val_loss: 0.7237 - val_accuracy: 0.6333\n",
            "Epoch 56/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7037 - accuracy: 0.6667\n",
            "Epoch 56: val_loss improved from 0.72374 to 0.72060, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.7037 - accuracy: 0.6667 - val_loss: 0.7206 - val_accuracy: 0.6333\n",
            "Epoch 57/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7002 - accuracy: 0.6667\n",
            "Epoch 57: val_loss improved from 0.72060 to 0.71742, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.7002 - accuracy: 0.6667 - val_loss: 0.7174 - val_accuracy: 0.6333\n",
            "Epoch 58/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6967 - accuracy: 0.6667\n",
            "Epoch 58: val_loss improved from 0.71742 to 0.71424, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.6967 - accuracy: 0.6667 - val_loss: 0.7142 - val_accuracy: 0.6333\n",
            "Epoch 59/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6933 - accuracy: 0.6667\n",
            "Epoch 59: val_loss improved from 0.71424 to 0.71106, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.6933 - accuracy: 0.6667 - val_loss: 0.7111 - val_accuracy: 0.6333\n",
            "Epoch 60/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6898 - accuracy: 0.6667\n",
            "Epoch 60: val_loss improved from 0.71106 to 0.70780, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.6898 - accuracy: 0.6667 - val_loss: 0.7078 - val_accuracy: 0.6333\n",
            "Epoch 61/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6863 - accuracy: 0.6667\n",
            "Epoch 61: val_loss improved from 0.70780 to 0.70448, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.6863 - accuracy: 0.6667 - val_loss: 0.7045 - val_accuracy: 0.6333\n",
            "Epoch 62/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6828 - accuracy: 0.6667\n",
            "Epoch 62: val_loss improved from 0.70448 to 0.70110, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.6828 - accuracy: 0.6667 - val_loss: 0.7011 - val_accuracy: 0.6333\n",
            "Epoch 63/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6793 - accuracy: 0.6667\n",
            "Epoch 63: val_loss improved from 0.70110 to 0.69766, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.6793 - accuracy: 0.6667 - val_loss: 0.6977 - val_accuracy: 0.6333\n",
            "Epoch 64/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6758 - accuracy: 0.6667\n",
            "Epoch 64: val_loss improved from 0.69766 to 0.69419, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.6758 - accuracy: 0.6667 - val_loss: 0.6942 - val_accuracy: 0.6333\n",
            "Epoch 65/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6723 - accuracy: 0.6667\n",
            "Epoch 65: val_loss improved from 0.69419 to 0.69067, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.6723 - accuracy: 0.6667 - val_loss: 0.6907 - val_accuracy: 0.6333\n",
            "Epoch 66/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6687 - accuracy: 0.6667\n",
            "Epoch 66: val_loss improved from 0.69067 to 0.68713, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.6687 - accuracy: 0.6667 - val_loss: 0.6871 - val_accuracy: 0.6333\n",
            "Epoch 67/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6652 - accuracy: 0.6667\n",
            "Epoch 67: val_loss improved from 0.68713 to 0.68366, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.6652 - accuracy: 0.6667 - val_loss: 0.6837 - val_accuracy: 0.6333\n",
            "Epoch 68/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6616 - accuracy: 0.6667\n",
            "Epoch 68: val_loss improved from 0.68366 to 0.68020, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.6616 - accuracy: 0.6667 - val_loss: 0.6802 - val_accuracy: 0.6333\n",
            "Epoch 69/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6581 - accuracy: 0.6667\n",
            "Epoch 69: val_loss improved from 0.68020 to 0.67676, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.6581 - accuracy: 0.6667 - val_loss: 0.6768 - val_accuracy: 0.6333\n",
            "Epoch 70/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6545 - accuracy: 0.6667\n",
            "Epoch 70: val_loss improved from 0.67676 to 0.67333, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.6545 - accuracy: 0.6667 - val_loss: 0.6733 - val_accuracy: 0.6333\n",
            "Epoch 71/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6510 - accuracy: 0.6667\n",
            "Epoch 71: val_loss improved from 0.67333 to 0.66990, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.6510 - accuracy: 0.6667 - val_loss: 0.6699 - val_accuracy: 0.6333\n",
            "Epoch 72/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6475 - accuracy: 0.6667\n",
            "Epoch 72: val_loss improved from 0.66990 to 0.66645, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.6475 - accuracy: 0.6667 - val_loss: 0.6665 - val_accuracy: 0.6333\n",
            "Epoch 73/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6440 - accuracy: 0.6667\n",
            "Epoch 73: val_loss improved from 0.66645 to 0.66300, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.6440 - accuracy: 0.6667 - val_loss: 0.6630 - val_accuracy: 0.6333\n",
            "Epoch 74/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6406 - accuracy: 0.6667\n",
            "Epoch 74: val_loss improved from 0.66300 to 0.65960, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.6406 - accuracy: 0.6667 - val_loss: 0.6596 - val_accuracy: 0.6333\n",
            "Epoch 75/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6372 - accuracy: 0.6778\n",
            "Epoch 75: val_loss improved from 0.65960 to 0.65623, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.6372 - accuracy: 0.6778 - val_loss: 0.6562 - val_accuracy: 0.6333\n",
            "Epoch 76/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6338 - accuracy: 0.6778\n",
            "Epoch 76: val_loss improved from 0.65623 to 0.65289, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.6338 - accuracy: 0.6778 - val_loss: 0.6529 - val_accuracy: 0.6333\n",
            "Epoch 77/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6305 - accuracy: 0.6778\n",
            "Epoch 77: val_loss improved from 0.65289 to 0.64958, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.6305 - accuracy: 0.6778 - val_loss: 0.6496 - val_accuracy: 0.6333\n",
            "Epoch 78/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6271 - accuracy: 0.6778\n",
            "Epoch 78: val_loss improved from 0.64958 to 0.64631, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.6271 - accuracy: 0.6778 - val_loss: 0.6463 - val_accuracy: 0.6333\n",
            "Epoch 79/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6238 - accuracy: 0.6889\n",
            "Epoch 79: val_loss improved from 0.64631 to 0.64308, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 0.6238 - accuracy: 0.6889 - val_loss: 0.6431 - val_accuracy: 0.6333\n",
            "Epoch 80/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6205 - accuracy: 0.6889\n",
            "Epoch 80: val_loss improved from 0.64308 to 0.63988, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.6205 - accuracy: 0.6889 - val_loss: 0.6399 - val_accuracy: 0.6333\n",
            "Epoch 81/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6172 - accuracy: 0.6889\n",
            "Epoch 81: val_loss improved from 0.63988 to 0.63672, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.6172 - accuracy: 0.6889 - val_loss: 0.6367 - val_accuracy: 0.6333\n",
            "Epoch 82/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6139 - accuracy: 0.6889\n",
            "Epoch 82: val_loss improved from 0.63672 to 0.63359, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.6139 - accuracy: 0.6889 - val_loss: 0.6336 - val_accuracy: 0.6333\n",
            "Epoch 83/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6106 - accuracy: 0.6889\n",
            "Epoch 83: val_loss improved from 0.63359 to 0.63050, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.6106 - accuracy: 0.6889 - val_loss: 0.6305 - val_accuracy: 0.6333\n",
            "Epoch 84/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6074 - accuracy: 0.6889\n",
            "Epoch 84: val_loss improved from 0.63050 to 0.62744, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.6074 - accuracy: 0.6889 - val_loss: 0.6274 - val_accuracy: 0.6333\n",
            "Epoch 85/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6041 - accuracy: 0.6889\n",
            "Epoch 85: val_loss improved from 0.62744 to 0.62442, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.6041 - accuracy: 0.6889 - val_loss: 0.6244 - val_accuracy: 0.6333\n",
            "Epoch 86/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6009 - accuracy: 0.6889\n",
            "Epoch 86: val_loss improved from 0.62442 to 0.62144, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.6009 - accuracy: 0.6889 - val_loss: 0.6214 - val_accuracy: 0.6333\n",
            "Epoch 87/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5977 - accuracy: 0.6889\n",
            "Epoch 87: val_loss improved from 0.62144 to 0.61850, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.5977 - accuracy: 0.6889 - val_loss: 0.6185 - val_accuracy: 0.6333\n",
            "Epoch 88/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5945 - accuracy: 0.7000\n",
            "Epoch 88: val_loss improved from 0.61850 to 0.61559, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.5945 - accuracy: 0.7000 - val_loss: 0.6156 - val_accuracy: 0.6333\n",
            "Epoch 89/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5913 - accuracy: 0.7000\n",
            "Epoch 89: val_loss improved from 0.61559 to 0.61271, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.5913 - accuracy: 0.7000 - val_loss: 0.6127 - val_accuracy: 0.6333\n",
            "Epoch 90/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5882 - accuracy: 0.7000\n",
            "Epoch 90: val_loss improved from 0.61271 to 0.60986, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.5882 - accuracy: 0.7000 - val_loss: 0.6099 - val_accuracy: 0.6333\n",
            "Epoch 91/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5851 - accuracy: 0.7000\n",
            "Epoch 91: val_loss improved from 0.60986 to 0.60702, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 0.5851 - accuracy: 0.7000 - val_loss: 0.6070 - val_accuracy: 0.6333\n",
            "Epoch 92/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5820 - accuracy: 0.7000\n",
            "Epoch 92: val_loss improved from 0.60702 to 0.60419, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.5820 - accuracy: 0.7000 - val_loss: 0.6042 - val_accuracy: 0.6333\n",
            "Epoch 93/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5789 - accuracy: 0.7333\n",
            "Epoch 93: val_loss improved from 0.60419 to 0.60136, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.5789 - accuracy: 0.7333 - val_loss: 0.6014 - val_accuracy: 0.6333\n",
            "Epoch 94/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5758 - accuracy: 0.7333\n",
            "Epoch 94: val_loss improved from 0.60136 to 0.59853, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 0.5758 - accuracy: 0.7333 - val_loss: 0.5985 - val_accuracy: 0.6333\n",
            "Epoch 95/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5728 - accuracy: 0.7333\n",
            "Epoch 95: val_loss improved from 0.59853 to 0.59570, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.5728 - accuracy: 0.7333 - val_loss: 0.5957 - val_accuracy: 0.6333\n",
            "Epoch 96/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5698 - accuracy: 0.7333\n",
            "Epoch 96: val_loss improved from 0.59570 to 0.59285, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.5698 - accuracy: 0.7333 - val_loss: 0.5928 - val_accuracy: 0.6333\n",
            "Epoch 97/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5668 - accuracy: 0.7444\n",
            "Epoch 97: val_loss improved from 0.59285 to 0.59000, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.5668 - accuracy: 0.7444 - val_loss: 0.5900 - val_accuracy: 0.6333\n",
            "Epoch 98/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5638 - accuracy: 0.7444\n",
            "Epoch 98: val_loss improved from 0.59000 to 0.58716, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.5638 - accuracy: 0.7444 - val_loss: 0.5872 - val_accuracy: 0.6333\n",
            "Epoch 99/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5608 - accuracy: 0.7444\n",
            "Epoch 99: val_loss improved from 0.58716 to 0.58433, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.5608 - accuracy: 0.7444 - val_loss: 0.5843 - val_accuracy: 0.6333\n",
            "Epoch 100/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5579 - accuracy: 0.7556\n",
            "Epoch 100: val_loss improved from 0.58433 to 0.58152, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.5579 - accuracy: 0.7556 - val_loss: 0.5815 - val_accuracy: 0.6333\n",
            "Epoch 101/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5549 - accuracy: 0.7556\n",
            "Epoch 101: val_loss improved from 0.58152 to 0.57875, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.5549 - accuracy: 0.7556 - val_loss: 0.5787 - val_accuracy: 0.6333\n",
            "Epoch 102/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5520 - accuracy: 0.7556\n",
            "Epoch 102: val_loss improved from 0.57875 to 0.57602, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.5520 - accuracy: 0.7556 - val_loss: 0.5760 - val_accuracy: 0.6333\n",
            "Epoch 103/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5492 - accuracy: 0.7667\n",
            "Epoch 103: val_loss improved from 0.57602 to 0.57332, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.5492 - accuracy: 0.7667 - val_loss: 0.5733 - val_accuracy: 0.6667\n",
            "Epoch 104/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5463 - accuracy: 0.7778\n",
            "Epoch 104: val_loss improved from 0.57332 to 0.57063, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.5463 - accuracy: 0.7778 - val_loss: 0.5706 - val_accuracy: 0.6667\n",
            "Epoch 105/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5435 - accuracy: 0.7889\n",
            "Epoch 105: val_loss improved from 0.57063 to 0.56794, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.5435 - accuracy: 0.7889 - val_loss: 0.5679 - val_accuracy: 0.6667\n",
            "Epoch 106/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5406 - accuracy: 0.7889\n",
            "Epoch 106: val_loss improved from 0.56794 to 0.56527, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.5406 - accuracy: 0.7889 - val_loss: 0.5653 - val_accuracy: 0.6667\n",
            "Epoch 107/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5378 - accuracy: 0.7889\n",
            "Epoch 107: val_loss improved from 0.56527 to 0.56261, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.5378 - accuracy: 0.7889 - val_loss: 0.5626 - val_accuracy: 0.6667\n",
            "Epoch 108/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5351 - accuracy: 0.8222\n",
            "Epoch 108: val_loss improved from 0.56261 to 0.55996, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.5351 - accuracy: 0.8222 - val_loss: 0.5600 - val_accuracy: 0.7333\n",
            "Epoch 109/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5323 - accuracy: 0.8222\n",
            "Epoch 109: val_loss improved from 0.55996 to 0.55732, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.5323 - accuracy: 0.8222 - val_loss: 0.5573 - val_accuracy: 0.7333\n",
            "Epoch 110/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5296 - accuracy: 0.8333\n",
            "Epoch 110: val_loss improved from 0.55732 to 0.55471, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.5296 - accuracy: 0.8333 - val_loss: 0.5547 - val_accuracy: 0.7333\n",
            "Epoch 111/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5269 - accuracy: 0.8333\n",
            "Epoch 111: val_loss improved from 0.55471 to 0.55211, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 0.5269 - accuracy: 0.8333 - val_loss: 0.5521 - val_accuracy: 0.7333\n",
            "Epoch 112/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5242 - accuracy: 0.8333\n",
            "Epoch 112: val_loss improved from 0.55211 to 0.54953, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5242 - accuracy: 0.8333 - val_loss: 0.5495 - val_accuracy: 0.7333\n",
            "Epoch 113/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5215 - accuracy: 0.8444\n",
            "Epoch 113: val_loss improved from 0.54953 to 0.54696, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.5215 - accuracy: 0.8444 - val_loss: 0.5470 - val_accuracy: 0.7333\n",
            "Epoch 114/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5188 - accuracy: 0.8444\n",
            "Epoch 114: val_loss improved from 0.54696 to 0.54442, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.5188 - accuracy: 0.8444 - val_loss: 0.5444 - val_accuracy: 0.7667\n",
            "Epoch 115/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5162 - accuracy: 0.8667\n",
            "Epoch 115: val_loss improved from 0.54442 to 0.54190, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.5162 - accuracy: 0.8667 - val_loss: 0.5419 - val_accuracy: 0.7667\n",
            "Epoch 116/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5136 - accuracy: 0.8667\n",
            "Epoch 116: val_loss improved from 0.54190 to 0.53943, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 0.5136 - accuracy: 0.8667 - val_loss: 0.5394 - val_accuracy: 0.7667\n",
            "Epoch 117/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5110 - accuracy: 0.8667\n",
            "Epoch 117: val_loss improved from 0.53943 to 0.53702, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.5110 - accuracy: 0.8667 - val_loss: 0.5370 - val_accuracy: 0.7667\n",
            "Epoch 118/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5084 - accuracy: 0.8778\n",
            "Epoch 118: val_loss improved from 0.53702 to 0.53465, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 0.5084 - accuracy: 0.8778 - val_loss: 0.5347 - val_accuracy: 0.8000\n",
            "Epoch 119/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5059 - accuracy: 0.8778\n",
            "Epoch 119: val_loss improved from 0.53465 to 0.53232, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.5059 - accuracy: 0.8778 - val_loss: 0.5323 - val_accuracy: 0.8000\n",
            "Epoch 120/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5033 - accuracy: 0.8778\n",
            "Epoch 120: val_loss improved from 0.53232 to 0.53002, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.5033 - accuracy: 0.8778 - val_loss: 0.5300 - val_accuracy: 0.8000\n",
            "Epoch 121/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5008 - accuracy: 0.8778\n",
            "Epoch 121: val_loss improved from 0.53002 to 0.52774, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.5008 - accuracy: 0.8778 - val_loss: 0.5277 - val_accuracy: 0.8000\n",
            "Epoch 122/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4983 - accuracy: 0.8889\n",
            "Epoch 122: val_loss improved from 0.52774 to 0.52550, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.4983 - accuracy: 0.8889 - val_loss: 0.5255 - val_accuracy: 0.8000\n",
            "Epoch 123/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4959 - accuracy: 0.8889\n",
            "Epoch 123: val_loss improved from 0.52550 to 0.52326, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.4959 - accuracy: 0.8889 - val_loss: 0.5233 - val_accuracy: 0.8000\n",
            "Epoch 124/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4934 - accuracy: 0.8889\n",
            "Epoch 124: val_loss improved from 0.52326 to 0.52103, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.4934 - accuracy: 0.8889 - val_loss: 0.5210 - val_accuracy: 0.8000\n",
            "Epoch 125/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4910 - accuracy: 0.8889\n",
            "Epoch 125: val_loss improved from 0.52103 to 0.51879, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 0.4910 - accuracy: 0.8889 - val_loss: 0.5188 - val_accuracy: 0.8000\n",
            "Epoch 126/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4886 - accuracy: 0.8889\n",
            "Epoch 126: val_loss improved from 0.51879 to 0.51658, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.4886 - accuracy: 0.8889 - val_loss: 0.5166 - val_accuracy: 0.8000\n",
            "Epoch 127/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4862 - accuracy: 0.8889\n",
            "Epoch 127: val_loss improved from 0.51658 to 0.51438, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.4862 - accuracy: 0.8889 - val_loss: 0.5144 - val_accuracy: 0.8000\n",
            "Epoch 128/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4839 - accuracy: 0.9000\n",
            "Epoch 128: val_loss improved from 0.51438 to 0.51221, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 0.4839 - accuracy: 0.9000 - val_loss: 0.5122 - val_accuracy: 0.8000\n",
            "Epoch 129/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4815 - accuracy: 0.9000\n",
            "Epoch 129: val_loss improved from 0.51221 to 0.51005, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.4815 - accuracy: 0.9000 - val_loss: 0.5100 - val_accuracy: 0.8000\n",
            "Epoch 130/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4792 - accuracy: 0.9000\n",
            "Epoch 130: val_loss improved from 0.51005 to 0.50790, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 0.4792 - accuracy: 0.9000 - val_loss: 0.5079 - val_accuracy: 0.8000\n",
            "Epoch 131/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4769 - accuracy: 0.9000\n",
            "Epoch 131: val_loss improved from 0.50790 to 0.50579, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.4769 - accuracy: 0.9000 - val_loss: 0.5058 - val_accuracy: 0.8000\n",
            "Epoch 132/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4746 - accuracy: 0.9000\n",
            "Epoch 132: val_loss improved from 0.50579 to 0.50371, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.4746 - accuracy: 0.9000 - val_loss: 0.5037 - val_accuracy: 0.8000\n",
            "Epoch 133/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4724 - accuracy: 0.9000\n",
            "Epoch 133: val_loss improved from 0.50371 to 0.50165, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.4724 - accuracy: 0.9000 - val_loss: 0.5016 - val_accuracy: 0.8000\n",
            "Epoch 134/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4701 - accuracy: 0.9000\n",
            "Epoch 134: val_loss improved from 0.50165 to 0.49962, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.4701 - accuracy: 0.9000 - val_loss: 0.4996 - val_accuracy: 0.8000\n",
            "Epoch 135/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4679 - accuracy: 0.9000\n",
            "Epoch 135: val_loss improved from 0.49962 to 0.49761, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 0.4679 - accuracy: 0.9000 - val_loss: 0.4976 - val_accuracy: 0.8000\n",
            "Epoch 136/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4657 - accuracy: 0.9000\n",
            "Epoch 136: val_loss improved from 0.49761 to 0.49562, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.4657 - accuracy: 0.9000 - val_loss: 0.4956 - val_accuracy: 0.8000\n",
            "Epoch 137/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4635 - accuracy: 0.9000\n",
            "Epoch 137: val_loss improved from 0.49562 to 0.49363, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.4635 - accuracy: 0.9000 - val_loss: 0.4936 - val_accuracy: 0.8000\n",
            "Epoch 138/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4613 - accuracy: 0.9000\n",
            "Epoch 138: val_loss improved from 0.49363 to 0.49166, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.4613 - accuracy: 0.9000 - val_loss: 0.4917 - val_accuracy: 0.8000\n",
            "Epoch 139/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4592 - accuracy: 0.9000\n",
            "Epoch 139: val_loss improved from 0.49166 to 0.48971, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.4592 - accuracy: 0.9000 - val_loss: 0.4897 - val_accuracy: 0.8000\n",
            "Epoch 140/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4570 - accuracy: 0.9111\n",
            "Epoch 140: val_loss improved from 0.48971 to 0.48776, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.4570 - accuracy: 0.9111 - val_loss: 0.4878 - val_accuracy: 0.8000\n",
            "Epoch 141/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4549 - accuracy: 0.9111\n",
            "Epoch 141: val_loss improved from 0.48776 to 0.48583, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.4549 - accuracy: 0.9111 - val_loss: 0.4858 - val_accuracy: 0.8000\n",
            "Epoch 142/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4528 - accuracy: 0.9222\n",
            "Epoch 142: val_loss improved from 0.48583 to 0.48392, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.4528 - accuracy: 0.9222 - val_loss: 0.4839 - val_accuracy: 0.8000\n",
            "Epoch 143/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4507 - accuracy: 0.9222\n",
            "Epoch 143: val_loss improved from 0.48392 to 0.48200, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 0.4507 - accuracy: 0.9222 - val_loss: 0.4820 - val_accuracy: 0.8000\n",
            "Epoch 144/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4487 - accuracy: 0.9222\n",
            "Epoch 144: val_loss improved from 0.48200 to 0.48009, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.4487 - accuracy: 0.9222 - val_loss: 0.4801 - val_accuracy: 0.8000\n",
            "Epoch 145/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4466 - accuracy: 0.9222\n",
            "Epoch 145: val_loss improved from 0.48009 to 0.47819, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.4466 - accuracy: 0.9222 - val_loss: 0.4782 - val_accuracy: 0.8000\n",
            "Epoch 146/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4446 - accuracy: 0.9222\n",
            "Epoch 146: val_loss improved from 0.47819 to 0.47631, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 0.4446 - accuracy: 0.9222 - val_loss: 0.4763 - val_accuracy: 0.8000\n",
            "Epoch 147/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4426 - accuracy: 0.9222\n",
            "Epoch 147: val_loss improved from 0.47631 to 0.47446, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.4426 - accuracy: 0.9222 - val_loss: 0.4745 - val_accuracy: 0.8000\n",
            "Epoch 148/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4406 - accuracy: 0.9222\n",
            "Epoch 148: val_loss improved from 0.47446 to 0.47264, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.4406 - accuracy: 0.9222 - val_loss: 0.4726 - val_accuracy: 0.8000\n",
            "Epoch 149/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4386 - accuracy: 0.9222\n",
            "Epoch 149: val_loss improved from 0.47264 to 0.47085, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.4386 - accuracy: 0.9222 - val_loss: 0.4708 - val_accuracy: 0.8000\n",
            "Epoch 150/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4366 - accuracy: 0.9222\n",
            "Epoch 150: val_loss improved from 0.47085 to 0.46907, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.4366 - accuracy: 0.9222 - val_loss: 0.4691 - val_accuracy: 0.8000\n",
            "Epoch 151/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4347 - accuracy: 0.9222\n",
            "Epoch 151: val_loss improved from 0.46907 to 0.46731, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.4347 - accuracy: 0.9222 - val_loss: 0.4673 - val_accuracy: 0.8000\n",
            "Epoch 152/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4327 - accuracy: 0.9333\n",
            "Epoch 152: val_loss improved from 0.46731 to 0.46557, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.4327 - accuracy: 0.9333 - val_loss: 0.4656 - val_accuracy: 0.8000\n",
            "Epoch 153/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4308 - accuracy: 0.9333\n",
            "Epoch 153: val_loss improved from 0.46557 to 0.46385, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.4308 - accuracy: 0.9333 - val_loss: 0.4639 - val_accuracy: 0.8000\n",
            "Epoch 154/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4289 - accuracy: 0.9333\n",
            "Epoch 154: val_loss improved from 0.46385 to 0.46215, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 0.4289 - accuracy: 0.9333 - val_loss: 0.4622 - val_accuracy: 0.8333\n",
            "Epoch 155/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4270 - accuracy: 0.9333\n",
            "Epoch 155: val_loss improved from 0.46215 to 0.46047, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.4270 - accuracy: 0.9333 - val_loss: 0.4605 - val_accuracy: 0.8333\n",
            "Epoch 156/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4252 - accuracy: 0.9333\n",
            "Epoch 156: val_loss improved from 0.46047 to 0.45880, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.4252 - accuracy: 0.9333 - val_loss: 0.4588 - val_accuracy: 0.8333\n",
            "Epoch 157/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4233 - accuracy: 0.9333\n",
            "Epoch 157: val_loss improved from 0.45880 to 0.45716, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.4233 - accuracy: 0.9333 - val_loss: 0.4572 - val_accuracy: 0.8333\n",
            "Epoch 158/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4215 - accuracy: 0.9333\n",
            "Epoch 158: val_loss improved from 0.45716 to 0.45554, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.4215 - accuracy: 0.9333 - val_loss: 0.4555 - val_accuracy: 0.8333\n",
            "Epoch 159/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4196 - accuracy: 0.9333\n",
            "Epoch 159: val_loss improved from 0.45554 to 0.45396, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.4196 - accuracy: 0.9333 - val_loss: 0.4540 - val_accuracy: 0.8333\n",
            "Epoch 160/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4178 - accuracy: 0.9333\n",
            "Epoch 160: val_loss improved from 0.45396 to 0.45240, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.4178 - accuracy: 0.9333 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
            "Epoch 161/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4160 - accuracy: 0.9333\n",
            "Epoch 161: val_loss improved from 0.45240 to 0.45086, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.4160 - accuracy: 0.9333 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
            "Epoch 162/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4142 - accuracy: 0.9333\n",
            "Epoch 162: val_loss improved from 0.45086 to 0.44933, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.4142 - accuracy: 0.9333 - val_loss: 0.4493 - val_accuracy: 0.8333\n",
            "Epoch 163/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4124 - accuracy: 0.9333\n",
            "Epoch 163: val_loss improved from 0.44933 to 0.44781, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 0.4124 - accuracy: 0.9333 - val_loss: 0.4478 - val_accuracy: 0.8333\n",
            "Epoch 164/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4107 - accuracy: 0.9333\n",
            "Epoch 164: val_loss improved from 0.44781 to 0.44630, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 0.4107 - accuracy: 0.9333 - val_loss: 0.4463 - val_accuracy: 0.8333\n",
            "Epoch 165/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4089 - accuracy: 0.9333\n",
            "Epoch 165: val_loss improved from 0.44630 to 0.44479, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.4089 - accuracy: 0.9333 - val_loss: 0.4448 - val_accuracy: 0.8333\n",
            "Epoch 166/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4072 - accuracy: 0.9333\n",
            "Epoch 166: val_loss improved from 0.44479 to 0.44328, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.4072 - accuracy: 0.9333 - val_loss: 0.4433 - val_accuracy: 0.8333\n",
            "Epoch 167/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4055 - accuracy: 0.9333\n",
            "Epoch 167: val_loss improved from 0.44328 to 0.44178, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 0.4055 - accuracy: 0.9333 - val_loss: 0.4418 - val_accuracy: 0.8667\n",
            "Epoch 168/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4038 - accuracy: 0.9333\n",
            "Epoch 168: val_loss improved from 0.44178 to 0.44027, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 0.4038 - accuracy: 0.9333 - val_loss: 0.4403 - val_accuracy: 0.8667\n",
            "Epoch 169/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4021 - accuracy: 0.9333\n",
            "Epoch 169: val_loss improved from 0.44027 to 0.43877, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.4021 - accuracy: 0.9333 - val_loss: 0.4388 - val_accuracy: 0.8667\n",
            "Epoch 170/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4004 - accuracy: 0.9444\n",
            "Epoch 170: val_loss improved from 0.43877 to 0.43727, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.4004 - accuracy: 0.9444 - val_loss: 0.4373 - val_accuracy: 0.8667\n",
            "Epoch 171/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3987 - accuracy: 0.9444\n",
            "Epoch 171: val_loss improved from 0.43727 to 0.43577, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 0.3987 - accuracy: 0.9444 - val_loss: 0.4358 - val_accuracy: 0.8667\n",
            "Epoch 172/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3971 - accuracy: 0.9444\n",
            "Epoch 172: val_loss improved from 0.43577 to 0.43427, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.3971 - accuracy: 0.9444 - val_loss: 0.4343 - val_accuracy: 0.8667\n",
            "Epoch 173/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3954 - accuracy: 0.9444\n",
            "Epoch 173: val_loss improved from 0.43427 to 0.43279, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.3954 - accuracy: 0.9444 - val_loss: 0.4328 - val_accuracy: 0.8667\n",
            "Epoch 174/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3938 - accuracy: 0.9444\n",
            "Epoch 174: val_loss improved from 0.43279 to 0.43130, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 0.3938 - accuracy: 0.9444 - val_loss: 0.4313 - val_accuracy: 0.8667\n",
            "Epoch 175/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3922 - accuracy: 0.9444\n",
            "Epoch 175: val_loss improved from 0.43130 to 0.42983, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.3922 - accuracy: 0.9444 - val_loss: 0.4298 - val_accuracy: 0.8667\n",
            "Epoch 176/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3905 - accuracy: 0.9556\n",
            "Epoch 176: val_loss improved from 0.42983 to 0.42836, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.3905 - accuracy: 0.9556 - val_loss: 0.4284 - val_accuracy: 0.8667\n",
            "Epoch 177/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3889 - accuracy: 0.9556\n",
            "Epoch 177: val_loss improved from 0.42836 to 0.42692, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.3889 - accuracy: 0.9556 - val_loss: 0.4269 - val_accuracy: 0.8667\n",
            "Epoch 178/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3873 - accuracy: 0.9556\n",
            "Epoch 178: val_loss improved from 0.42692 to 0.42551, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.3873 - accuracy: 0.9556 - val_loss: 0.4255 - val_accuracy: 0.8667\n",
            "Epoch 179/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3858 - accuracy: 0.9556\n",
            "Epoch 179: val_loss improved from 0.42551 to 0.42412, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.3858 - accuracy: 0.9556 - val_loss: 0.4241 - val_accuracy: 0.8667\n",
            "Epoch 180/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3842 - accuracy: 0.9556\n",
            "Epoch 180: val_loss improved from 0.42412 to 0.42276, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 0.3842 - accuracy: 0.9556 - val_loss: 0.4228 - val_accuracy: 0.8667\n",
            "Epoch 181/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3826 - accuracy: 0.9556\n",
            "Epoch 181: val_loss improved from 0.42276 to 0.42142, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3826 - accuracy: 0.9556 - val_loss: 0.4214 - val_accuracy: 0.8667\n",
            "Epoch 182/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3811 - accuracy: 0.9556\n",
            "Epoch 182: val_loss improved from 0.42142 to 0.42010, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.3811 - accuracy: 0.9556 - val_loss: 0.4201 - val_accuracy: 0.9000\n",
            "Epoch 183/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3795 - accuracy: 0.9556\n",
            "Epoch 183: val_loss improved from 0.42010 to 0.41880, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 0.3795 - accuracy: 0.9556 - val_loss: 0.4188 - val_accuracy: 0.9000\n",
            "Epoch 184/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3780 - accuracy: 0.9556\n",
            "Epoch 184: val_loss improved from 0.41880 to 0.41750, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.3780 - accuracy: 0.9556 - val_loss: 0.4175 - val_accuracy: 0.9000\n",
            "Epoch 185/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3765 - accuracy: 0.9556\n",
            "Epoch 185: val_loss improved from 0.41750 to 0.41620, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3765 - accuracy: 0.9556 - val_loss: 0.4162 - val_accuracy: 0.9000\n",
            "Epoch 186/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3750 - accuracy: 0.9556\n",
            "Epoch 186: val_loss improved from 0.41620 to 0.41491, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.3750 - accuracy: 0.9556 - val_loss: 0.4149 - val_accuracy: 0.9000\n",
            "Epoch 187/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3735 - accuracy: 0.9556\n",
            "Epoch 187: val_loss improved from 0.41491 to 0.41361, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.3735 - accuracy: 0.9556 - val_loss: 0.4136 - val_accuracy: 0.9000\n",
            "Epoch 188/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3720 - accuracy: 0.9556\n",
            "Epoch 188: val_loss improved from 0.41361 to 0.41232, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.3720 - accuracy: 0.9556 - val_loss: 0.4123 - val_accuracy: 0.9000\n",
            "Epoch 189/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3705 - accuracy: 0.9556\n",
            "Epoch 189: val_loss improved from 0.41232 to 0.41103, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 0.3705 - accuracy: 0.9556 - val_loss: 0.4110 - val_accuracy: 0.9000\n",
            "Epoch 190/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3690 - accuracy: 0.9556\n",
            "Epoch 190: val_loss improved from 0.41103 to 0.40974, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3690 - accuracy: 0.9556 - val_loss: 0.4097 - val_accuracy: 0.9000\n",
            "Epoch 191/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3675 - accuracy: 0.9556\n",
            "Epoch 191: val_loss improved from 0.40974 to 0.40848, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.3675 - accuracy: 0.9556 - val_loss: 0.4085 - val_accuracy: 0.9000\n",
            "Epoch 192/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3661 - accuracy: 0.9556\n",
            "Epoch 192: val_loss improved from 0.40848 to 0.40723, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 0.3661 - accuracy: 0.9556 - val_loss: 0.4072 - val_accuracy: 0.9000\n",
            "Epoch 193/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3646 - accuracy: 0.9556\n",
            "Epoch 193: val_loss improved from 0.40723 to 0.40601, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 0.3646 - accuracy: 0.9556 - val_loss: 0.4060 - val_accuracy: 0.9000\n",
            "Epoch 194/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3632 - accuracy: 0.9556\n",
            "Epoch 194: val_loss improved from 0.40601 to 0.40479, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.3632 - accuracy: 0.9556 - val_loss: 0.4048 - val_accuracy: 0.9000\n",
            "Epoch 195/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3617 - accuracy: 0.9556\n",
            "Epoch 195: val_loss improved from 0.40479 to 0.40360, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.3617 - accuracy: 0.9556 - val_loss: 0.4036 - val_accuracy: 0.9000\n",
            "Epoch 196/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3603 - accuracy: 0.9556\n",
            "Epoch 196: val_loss improved from 0.40360 to 0.40241, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.3603 - accuracy: 0.9556 - val_loss: 0.4024 - val_accuracy: 0.9000\n",
            "Epoch 197/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3589 - accuracy: 0.9556\n",
            "Epoch 197: val_loss improved from 0.40241 to 0.40121, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 0.3589 - accuracy: 0.9556 - val_loss: 0.4012 - val_accuracy: 0.9000\n",
            "Epoch 198/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3574 - accuracy: 0.9556\n",
            "Epoch 198: val_loss improved from 0.40121 to 0.40002, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.3574 - accuracy: 0.9556 - val_loss: 0.4000 - val_accuracy: 0.9000\n",
            "Epoch 199/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3560 - accuracy: 0.9556\n",
            "Epoch 199: val_loss improved from 0.40002 to 0.39883, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.3560 - accuracy: 0.9556 - val_loss: 0.3988 - val_accuracy: 0.9000\n",
            "Epoch 200/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3546 - accuracy: 0.9556\n",
            "Epoch 200: val_loss improved from 0.39883 to 0.39763, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.3546 - accuracy: 0.9556 - val_loss: 0.3976 - val_accuracy: 0.9000\n",
            "Epoch 201/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3533 - accuracy: 0.9556\n",
            "Epoch 201: val_loss improved from 0.39763 to 0.39643, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.3533 - accuracy: 0.9556 - val_loss: 0.3964 - val_accuracy: 0.9000\n",
            "Epoch 202/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3519 - accuracy: 0.9556\n",
            "Epoch 202: val_loss improved from 0.39643 to 0.39523, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3519 - accuracy: 0.9556 - val_loss: 0.3952 - val_accuracy: 0.9000\n",
            "Epoch 203/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3505 - accuracy: 0.9667\n",
            "Epoch 203: val_loss improved from 0.39523 to 0.39402, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.3505 - accuracy: 0.9667 - val_loss: 0.3940 - val_accuracy: 0.9000\n",
            "Epoch 204/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3491 - accuracy: 0.9667\n",
            "Epoch 204: val_loss improved from 0.39402 to 0.39282, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.3491 - accuracy: 0.9667 - val_loss: 0.3928 - val_accuracy: 0.9000\n",
            "Epoch 205/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3477 - accuracy: 0.9778\n",
            "Epoch 205: val_loss improved from 0.39282 to 0.39161, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.3477 - accuracy: 0.9778 - val_loss: 0.3916 - val_accuracy: 0.9000\n",
            "Epoch 206/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3464 - accuracy: 0.9778\n",
            "Epoch 206: val_loss improved from 0.39161 to 0.39041, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.3464 - accuracy: 0.9778 - val_loss: 0.3904 - val_accuracy: 0.9000\n",
            "Epoch 207/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3450 - accuracy: 0.9778\n",
            "Epoch 207: val_loss improved from 0.39041 to 0.38923, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.3450 - accuracy: 0.9778 - val_loss: 0.3892 - val_accuracy: 0.9000\n",
            "Epoch 208/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3437 - accuracy: 0.9778\n",
            "Epoch 208: val_loss improved from 0.38923 to 0.38806, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.3437 - accuracy: 0.9778 - val_loss: 0.3881 - val_accuracy: 0.9000\n",
            "Epoch 209/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3423 - accuracy: 0.9778\n",
            "Epoch 209: val_loss improved from 0.38806 to 0.38690, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.3423 - accuracy: 0.9778 - val_loss: 0.3869 - val_accuracy: 0.9000\n",
            "Epoch 210/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3410 - accuracy: 0.9778\n",
            "Epoch 210: val_loss improved from 0.38690 to 0.38576, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.3410 - accuracy: 0.9778 - val_loss: 0.3858 - val_accuracy: 0.9000\n",
            "Epoch 211/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3397 - accuracy: 0.9778\n",
            "Epoch 211: val_loss improved from 0.38576 to 0.38461, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.3397 - accuracy: 0.9778 - val_loss: 0.3846 - val_accuracy: 0.9000\n",
            "Epoch 212/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3384 - accuracy: 0.9778\n",
            "Epoch 212: val_loss improved from 0.38461 to 0.38346, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.3384 - accuracy: 0.9778 - val_loss: 0.3835 - val_accuracy: 0.9000\n",
            "Epoch 213/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3370 - accuracy: 0.9778\n",
            "Epoch 213: val_loss improved from 0.38346 to 0.38231, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.3370 - accuracy: 0.9778 - val_loss: 0.3823 - val_accuracy: 0.9000\n",
            "Epoch 214/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3357 - accuracy: 0.9778\n",
            "Epoch 214: val_loss improved from 0.38231 to 0.38117, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.3357 - accuracy: 0.9778 - val_loss: 0.3812 - val_accuracy: 0.9000\n",
            "Epoch 215/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3344 - accuracy: 0.9778\n",
            "Epoch 215: val_loss improved from 0.38117 to 0.38005, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.3344 - accuracy: 0.9778 - val_loss: 0.3800 - val_accuracy: 0.9000\n",
            "Epoch 216/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3331 - accuracy: 0.9778\n",
            "Epoch 216: val_loss improved from 0.38005 to 0.37895, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.3331 - accuracy: 0.9778 - val_loss: 0.3789 - val_accuracy: 0.9000\n",
            "Epoch 217/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3318 - accuracy: 0.9778\n",
            "Epoch 217: val_loss improved from 0.37895 to 0.37787, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.3318 - accuracy: 0.9778 - val_loss: 0.3779 - val_accuracy: 0.9000\n",
            "Epoch 218/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3305 - accuracy: 0.9778\n",
            "Epoch 218: val_loss improved from 0.37787 to 0.37681, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.3305 - accuracy: 0.9778 - val_loss: 0.3768 - val_accuracy: 0.9000\n",
            "Epoch 219/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3292 - accuracy: 0.9778\n",
            "Epoch 219: val_loss improved from 0.37681 to 0.37576, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.3292 - accuracy: 0.9778 - val_loss: 0.3758 - val_accuracy: 0.9000\n",
            "Epoch 220/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3280 - accuracy: 0.9778\n",
            "Epoch 220: val_loss improved from 0.37576 to 0.37473, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.3280 - accuracy: 0.9778 - val_loss: 0.3747 - val_accuracy: 0.9000\n",
            "Epoch 221/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3267 - accuracy: 0.9778\n",
            "Epoch 221: val_loss improved from 0.37473 to 0.37370, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.3267 - accuracy: 0.9778 - val_loss: 0.3737 - val_accuracy: 0.9000\n",
            "Epoch 222/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3254 - accuracy: 0.9778\n",
            "Epoch 222: val_loss improved from 0.37370 to 0.37266, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.3254 - accuracy: 0.9778 - val_loss: 0.3727 - val_accuracy: 0.9000\n",
            "Epoch 223/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3241 - accuracy: 0.9778\n",
            "Epoch 223: val_loss improved from 0.37266 to 0.37159, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.3241 - accuracy: 0.9778 - val_loss: 0.3716 - val_accuracy: 0.9000\n",
            "Epoch 224/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3229 - accuracy: 0.9778\n",
            "Epoch 224: val_loss improved from 0.37159 to 0.37051, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.3229 - accuracy: 0.9778 - val_loss: 0.3705 - val_accuracy: 0.9333\n",
            "Epoch 225/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3216 - accuracy: 0.9778\n",
            "Epoch 225: val_loss improved from 0.37051 to 0.36943, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.3216 - accuracy: 0.9778 - val_loss: 0.3694 - val_accuracy: 0.9333\n",
            "Epoch 226/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3204 - accuracy: 0.9778\n",
            "Epoch 226: val_loss improved from 0.36943 to 0.36836, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.3204 - accuracy: 0.9778 - val_loss: 0.3684 - val_accuracy: 0.9333\n",
            "Epoch 227/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3191 - accuracy: 0.9778\n",
            "Epoch 227: val_loss improved from 0.36836 to 0.36730, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.3191 - accuracy: 0.9778 - val_loss: 0.3673 - val_accuracy: 0.9333\n",
            "Epoch 228/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3179 - accuracy: 0.9778\n",
            "Epoch 228: val_loss improved from 0.36730 to 0.36624, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.3179 - accuracy: 0.9778 - val_loss: 0.3662 - val_accuracy: 0.9333\n",
            "Epoch 229/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3166 - accuracy: 0.9778\n",
            "Epoch 229: val_loss improved from 0.36624 to 0.36518, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.3166 - accuracy: 0.9778 - val_loss: 0.3652 - val_accuracy: 0.9333\n",
            "Epoch 230/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3154 - accuracy: 0.9778\n",
            "Epoch 230: val_loss improved from 0.36518 to 0.36413, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3154 - accuracy: 0.9778 - val_loss: 0.3641 - val_accuracy: 0.9333\n",
            "Epoch 231/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3142 - accuracy: 0.9778\n",
            "Epoch 231: val_loss improved from 0.36413 to 0.36309, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.3142 - accuracy: 0.9778 - val_loss: 0.3631 - val_accuracy: 0.9333\n",
            "Epoch 232/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3129 - accuracy: 0.9778\n",
            "Epoch 232: val_loss improved from 0.36309 to 0.36204, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.3129 - accuracy: 0.9778 - val_loss: 0.3620 - val_accuracy: 0.9333\n",
            "Epoch 233/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3117 - accuracy: 0.9778\n",
            "Epoch 233: val_loss improved from 0.36204 to 0.36100, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.3117 - accuracy: 0.9778 - val_loss: 0.3610 - val_accuracy: 0.9333\n",
            "Epoch 234/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3105 - accuracy: 0.9778\n",
            "Epoch 234: val_loss improved from 0.36100 to 0.35996, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.3105 - accuracy: 0.9778 - val_loss: 0.3600 - val_accuracy: 0.9333\n",
            "Epoch 235/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3093 - accuracy: 0.9778\n",
            "Epoch 235: val_loss improved from 0.35996 to 0.35893, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.3093 - accuracy: 0.9778 - val_loss: 0.3589 - val_accuracy: 0.9333\n",
            "Epoch 236/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3081 - accuracy: 0.9778\n",
            "Epoch 236: val_loss improved from 0.35893 to 0.35789, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 0.3081 - accuracy: 0.9778 - val_loss: 0.3579 - val_accuracy: 0.9333\n",
            "Epoch 237/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3069 - accuracy: 0.9778\n",
            "Epoch 237: val_loss improved from 0.35789 to 0.35686, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.3069 - accuracy: 0.9778 - val_loss: 0.3569 - val_accuracy: 0.9333\n",
            "Epoch 238/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3057 - accuracy: 0.9889\n",
            "Epoch 238: val_loss improved from 0.35686 to 0.35583, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.3057 - accuracy: 0.9889 - val_loss: 0.3558 - val_accuracy: 0.9333\n",
            "Epoch 239/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3044 - accuracy: 0.9889\n",
            "Epoch 239: val_loss improved from 0.35583 to 0.35480, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.3044 - accuracy: 0.9889 - val_loss: 0.3548 - val_accuracy: 0.9333\n",
            "Epoch 240/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3033 - accuracy: 0.9889\n",
            "Epoch 240: val_loss improved from 0.35480 to 0.35378, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.3033 - accuracy: 0.9889 - val_loss: 0.3538 - val_accuracy: 0.9333\n",
            "Epoch 241/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3021 - accuracy: 0.9889\n",
            "Epoch 241: val_loss improved from 0.35378 to 0.35276, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.3021 - accuracy: 0.9889 - val_loss: 0.3528 - val_accuracy: 0.9333\n",
            "Epoch 242/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3009 - accuracy: 0.9889\n",
            "Epoch 242: val_loss improved from 0.35276 to 0.35174, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.3009 - accuracy: 0.9889 - val_loss: 0.3517 - val_accuracy: 0.9333\n",
            "Epoch 243/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2997 - accuracy: 0.9889\n",
            "Epoch 243: val_loss improved from 0.35174 to 0.35072, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.2997 - accuracy: 0.9889 - val_loss: 0.3507 - val_accuracy: 0.9333\n",
            "Epoch 244/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2985 - accuracy: 0.9889\n",
            "Epoch 244: val_loss improved from 0.35072 to 0.34970, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.2985 - accuracy: 0.9889 - val_loss: 0.3497 - val_accuracy: 0.9333\n",
            "Epoch 245/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2973 - accuracy: 0.9889\n",
            "Epoch 245: val_loss improved from 0.34970 to 0.34872, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.2973 - accuracy: 0.9889 - val_loss: 0.3487 - val_accuracy: 0.9333\n",
            "Epoch 246/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2961 - accuracy: 0.9889\n",
            "Epoch 246: val_loss improved from 0.34872 to 0.34773, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.2961 - accuracy: 0.9889 - val_loss: 0.3477 - val_accuracy: 0.9333\n",
            "Epoch 247/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2950 - accuracy: 0.9889\n",
            "Epoch 247: val_loss improved from 0.34773 to 0.34673, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.2950 - accuracy: 0.9889 - val_loss: 0.3467 - val_accuracy: 0.9333\n",
            "Epoch 248/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2938 - accuracy: 0.9889\n",
            "Epoch 248: val_loss improved from 0.34673 to 0.34574, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 0.2938 - accuracy: 0.9889 - val_loss: 0.3457 - val_accuracy: 0.9333\n",
            "Epoch 249/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2926 - accuracy: 0.9889\n",
            "Epoch 249: val_loss improved from 0.34574 to 0.34474, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.2926 - accuracy: 0.9889 - val_loss: 0.3447 - val_accuracy: 0.9333\n",
            "Epoch 250/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2915 - accuracy: 0.9889\n",
            "Epoch 250: val_loss improved from 0.34474 to 0.34377, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.2915 - accuracy: 0.9889 - val_loss: 0.3438 - val_accuracy: 0.9333\n",
            "Epoch 251/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2903 - accuracy: 0.9889\n",
            "Epoch 251: val_loss improved from 0.34377 to 0.34280, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.2903 - accuracy: 0.9889 - val_loss: 0.3428 - val_accuracy: 0.9333\n",
            "Epoch 252/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2891 - accuracy: 0.9889\n",
            "Epoch 252: val_loss improved from 0.34280 to 0.34181, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.2891 - accuracy: 0.9889 - val_loss: 0.3418 - val_accuracy: 0.9333\n",
            "Epoch 253/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2880 - accuracy: 0.9889\n",
            "Epoch 253: val_loss improved from 0.34181 to 0.34083, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.2880 - accuracy: 0.9889 - val_loss: 0.3408 - val_accuracy: 0.9333\n",
            "Epoch 254/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2868 - accuracy: 0.9889\n",
            "Epoch 254: val_loss improved from 0.34083 to 0.33986, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.2868 - accuracy: 0.9889 - val_loss: 0.3399 - val_accuracy: 0.9333\n",
            "Epoch 255/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2857 - accuracy: 0.9889\n",
            "Epoch 255: val_loss improved from 0.33986 to 0.33889, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.2857 - accuracy: 0.9889 - val_loss: 0.3389 - val_accuracy: 0.9333\n",
            "Epoch 256/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2845 - accuracy: 0.9889\n",
            "Epoch 256: val_loss improved from 0.33889 to 0.33792, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.2845 - accuracy: 0.9889 - val_loss: 0.3379 - val_accuracy: 0.9333\n",
            "Epoch 257/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2834 - accuracy: 0.9889\n",
            "Epoch 257: val_loss improved from 0.33792 to 0.33696, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.2834 - accuracy: 0.9889 - val_loss: 0.3370 - val_accuracy: 0.9333\n",
            "Epoch 258/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2823 - accuracy: 0.9889\n",
            "Epoch 258: val_loss improved from 0.33696 to 0.33600, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.2823 - accuracy: 0.9889 - val_loss: 0.3360 - val_accuracy: 0.9333\n",
            "Epoch 259/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2811 - accuracy: 0.9889\n",
            "Epoch 259: val_loss improved from 0.33600 to 0.33502, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.2811 - accuracy: 0.9889 - val_loss: 0.3350 - val_accuracy: 0.9333\n",
            "Epoch 260/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2800 - accuracy: 0.9889\n",
            "Epoch 260: val_loss improved from 0.33502 to 0.33407, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.2800 - accuracy: 0.9889 - val_loss: 0.3341 - val_accuracy: 0.9333\n",
            "Epoch 261/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2789 - accuracy: 0.9889\n",
            "Epoch 261: val_loss improved from 0.33407 to 0.33313, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.2789 - accuracy: 0.9889 - val_loss: 0.3331 - val_accuracy: 0.9333\n",
            "Epoch 262/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2777 - accuracy: 0.9889\n",
            "Epoch 262: val_loss improved from 0.33313 to 0.33218, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.2777 - accuracy: 0.9889 - val_loss: 0.3322 - val_accuracy: 0.9333\n",
            "Epoch 263/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2766 - accuracy: 0.9889\n",
            "Epoch 263: val_loss improved from 0.33218 to 0.33122, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.2766 - accuracy: 0.9889 - val_loss: 0.3312 - val_accuracy: 0.9333\n",
            "Epoch 264/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2755 - accuracy: 0.9889\n",
            "Epoch 264: val_loss improved from 0.33122 to 0.33025, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.2755 - accuracy: 0.9889 - val_loss: 0.3302 - val_accuracy: 0.9333\n",
            "Epoch 265/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2744 - accuracy: 0.9889\n",
            "Epoch 265: val_loss improved from 0.33025 to 0.32929, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.2744 - accuracy: 0.9889 - val_loss: 0.3293 - val_accuracy: 0.9333\n",
            "Epoch 266/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2732 - accuracy: 0.9889\n",
            "Epoch 266: val_loss improved from 0.32929 to 0.32836, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.2732 - accuracy: 0.9889 - val_loss: 0.3284 - val_accuracy: 0.9333\n",
            "Epoch 267/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2721 - accuracy: 0.9889\n",
            "Epoch 267: val_loss improved from 0.32836 to 0.32740, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 0.2721 - accuracy: 0.9889 - val_loss: 0.3274 - val_accuracy: 0.9333\n",
            "Epoch 268/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2710 - accuracy: 0.9889\n",
            "Epoch 268: val_loss improved from 0.32740 to 0.32647, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.2710 - accuracy: 0.9889 - val_loss: 0.3265 - val_accuracy: 0.9333\n",
            "Epoch 269/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2699 - accuracy: 0.9889\n",
            "Epoch 269: val_loss improved from 0.32647 to 0.32552, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.2699 - accuracy: 0.9889 - val_loss: 0.3255 - val_accuracy: 0.9333\n",
            "Epoch 270/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2688 - accuracy: 0.9889\n",
            "Epoch 270: val_loss improved from 0.32552 to 0.32458, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.2688 - accuracy: 0.9889 - val_loss: 0.3246 - val_accuracy: 0.9333\n",
            "Epoch 271/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2677 - accuracy: 0.9889\n",
            "Epoch 271: val_loss improved from 0.32458 to 0.32366, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.2677 - accuracy: 0.9889 - val_loss: 0.3237 - val_accuracy: 0.9333\n",
            "Epoch 272/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2666 - accuracy: 0.9889\n",
            "Epoch 272: val_loss improved from 0.32366 to 0.32272, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2666 - accuracy: 0.9889 - val_loss: 0.3227 - val_accuracy: 0.9333\n",
            "Epoch 273/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2655 - accuracy: 0.9889\n",
            "Epoch 273: val_loss improved from 0.32272 to 0.32176, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2655 - accuracy: 0.9889 - val_loss: 0.3218 - val_accuracy: 0.9333\n",
            "Epoch 274/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2644 - accuracy: 0.9889\n",
            "Epoch 274: val_loss improved from 0.32176 to 0.32082, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.2644 - accuracy: 0.9889 - val_loss: 0.3208 - val_accuracy: 0.9333\n",
            "Epoch 275/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2633 - accuracy: 0.9889\n",
            "Epoch 275: val_loss improved from 0.32082 to 0.31988, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.2633 - accuracy: 0.9889 - val_loss: 0.3199 - val_accuracy: 0.9333\n",
            "Epoch 276/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2622 - accuracy: 0.9889\n",
            "Epoch 276: val_loss improved from 0.31988 to 0.31894, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.2622 - accuracy: 0.9889 - val_loss: 0.3189 - val_accuracy: 0.9333\n",
            "Epoch 277/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2611 - accuracy: 0.9889\n",
            "Epoch 277: val_loss improved from 0.31894 to 0.31798, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.2611 - accuracy: 0.9889 - val_loss: 0.3180 - val_accuracy: 0.9333\n",
            "Epoch 278/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2600 - accuracy: 0.9889\n",
            "Epoch 278: val_loss improved from 0.31798 to 0.31700, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.2600 - accuracy: 0.9889 - val_loss: 0.3170 - val_accuracy: 0.9333\n",
            "Epoch 279/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2589 - accuracy: 0.9889\n",
            "Epoch 279: val_loss improved from 0.31700 to 0.31597, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.2589 - accuracy: 0.9889 - val_loss: 0.3160 - val_accuracy: 0.9333\n",
            "Epoch 280/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2577 - accuracy: 0.9889\n",
            "Epoch 280: val_loss improved from 0.31597 to 0.31493, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.2577 - accuracy: 0.9889 - val_loss: 0.3149 - val_accuracy: 0.9333\n",
            "Epoch 281/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2565 - accuracy: 0.9889\n",
            "Epoch 281: val_loss improved from 0.31493 to 0.31388, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.2565 - accuracy: 0.9889 - val_loss: 0.3139 - val_accuracy: 0.9333\n",
            "Epoch 282/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2553 - accuracy: 0.9889\n",
            "Epoch 282: val_loss improved from 0.31388 to 0.31283, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.2553 - accuracy: 0.9889 - val_loss: 0.3128 - val_accuracy: 0.9333\n",
            "Epoch 283/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2540 - accuracy: 0.9889\n",
            "Epoch 283: val_loss improved from 0.31283 to 0.31179, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.2540 - accuracy: 0.9889 - val_loss: 0.3118 - val_accuracy: 0.9333\n",
            "Epoch 284/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2528 - accuracy: 0.9889\n",
            "Epoch 284: val_loss improved from 0.31179 to 0.31075, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.2528 - accuracy: 0.9889 - val_loss: 0.3107 - val_accuracy: 0.9333\n",
            "Epoch 285/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2515 - accuracy: 0.9889\n",
            "Epoch 285: val_loss improved from 0.31075 to 0.30972, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.2515 - accuracy: 0.9889 - val_loss: 0.3097 - val_accuracy: 0.9333\n",
            "Epoch 286/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2502 - accuracy: 0.9889\n",
            "Epoch 286: val_loss improved from 0.30972 to 0.30871, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.2502 - accuracy: 0.9889 - val_loss: 0.3087 - val_accuracy: 0.9333\n",
            "Epoch 287/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2489 - accuracy: 0.9889\n",
            "Epoch 287: val_loss improved from 0.30871 to 0.30771, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2489 - accuracy: 0.9889 - val_loss: 0.3077 - val_accuracy: 0.9333\n",
            "Epoch 288/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2477 - accuracy: 0.9889\n",
            "Epoch 288: val_loss improved from 0.30771 to 0.30673, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.2477 - accuracy: 0.9889 - val_loss: 0.3067 - val_accuracy: 0.9333\n",
            "Epoch 289/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2464 - accuracy: 0.9889\n",
            "Epoch 289: val_loss improved from 0.30673 to 0.30574, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.2464 - accuracy: 0.9889 - val_loss: 0.3057 - val_accuracy: 0.9333\n",
            "Epoch 290/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2452 - accuracy: 0.9889\n",
            "Epoch 290: val_loss improved from 0.30574 to 0.30473, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.2452 - accuracy: 0.9889 - val_loss: 0.3047 - val_accuracy: 0.9333\n",
            "Epoch 291/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2440 - accuracy: 0.9889\n",
            "Epoch 291: val_loss improved from 0.30473 to 0.30374, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.2440 - accuracy: 0.9889 - val_loss: 0.3037 - val_accuracy: 0.9333\n",
            "Epoch 292/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2428 - accuracy: 0.9889\n",
            "Epoch 292: val_loss improved from 0.30374 to 0.30277, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2428 - accuracy: 0.9889 - val_loss: 0.3028 - val_accuracy: 0.9333\n",
            "Epoch 293/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2418 - accuracy: 0.9889\n",
            "Epoch 293: val_loss improved from 0.30277 to 0.30186, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.2418 - accuracy: 0.9889 - val_loss: 0.3019 - val_accuracy: 0.9333\n",
            "Epoch 294/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2410 - accuracy: 0.9889\n",
            "Epoch 294: val_loss improved from 0.30186 to 0.30102, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.2410 - accuracy: 0.9889 - val_loss: 0.3010 - val_accuracy: 0.9333\n",
            "Epoch 295/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2399 - accuracy: 0.9889\n",
            "Epoch 295: val_loss improved from 0.30102 to 0.30020, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2399 - accuracy: 0.9889 - val_loss: 0.3002 - val_accuracy: 0.9333\n",
            "Epoch 296/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2386 - accuracy: 0.9889\n",
            "Epoch 296: val_loss improved from 0.30020 to 0.29935, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.2386 - accuracy: 0.9889 - val_loss: 0.2994 - val_accuracy: 0.9333\n",
            "Epoch 297/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2375 - accuracy: 0.9889\n",
            "Epoch 297: val_loss improved from 0.29935 to 0.29848, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.2375 - accuracy: 0.9889 - val_loss: 0.2985 - val_accuracy: 0.9333\n",
            "Epoch 298/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2364 - accuracy: 0.9889\n",
            "Epoch 298: val_loss improved from 0.29848 to 0.29757, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2364 - accuracy: 0.9889 - val_loss: 0.2976 - val_accuracy: 0.9333\n",
            "Epoch 299/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2354 - accuracy: 0.9889\n",
            "Epoch 299: val_loss improved from 0.29757 to 0.29662, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2354 - accuracy: 0.9889 - val_loss: 0.2966 - val_accuracy: 0.9333\n",
            "Epoch 300/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2344 - accuracy: 0.9889\n",
            "Epoch 300: val_loss improved from 0.29662 to 0.29567, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.2344 - accuracy: 0.9889 - val_loss: 0.2957 - val_accuracy: 0.9333\n",
            "Epoch 301/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2334 - accuracy: 0.9889\n",
            "Epoch 301: val_loss improved from 0.29567 to 0.29473, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.2334 - accuracy: 0.9889 - val_loss: 0.2947 - val_accuracy: 0.9333\n",
            "Epoch 302/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2324 - accuracy: 0.9889\n",
            "Epoch 302: val_loss improved from 0.29473 to 0.29379, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.2324 - accuracy: 0.9889 - val_loss: 0.2938 - val_accuracy: 0.9333\n",
            "Epoch 303/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2314 - accuracy: 0.9889\n",
            "Epoch 303: val_loss improved from 0.29379 to 0.29286, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2314 - accuracy: 0.9889 - val_loss: 0.2929 - val_accuracy: 0.9333\n",
            "Epoch 304/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2304 - accuracy: 0.9889\n",
            "Epoch 304: val_loss improved from 0.29286 to 0.29194, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.2304 - accuracy: 0.9889 - val_loss: 0.2919 - val_accuracy: 0.9333\n",
            "Epoch 305/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2293 - accuracy: 0.9889\n",
            "Epoch 305: val_loss improved from 0.29194 to 0.29103, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.2293 - accuracy: 0.9889 - val_loss: 0.2910 - val_accuracy: 0.9333\n",
            "Epoch 306/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2283 - accuracy: 0.9889\n",
            "Epoch 306: val_loss improved from 0.29103 to 0.29014, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.2283 - accuracy: 0.9889 - val_loss: 0.2901 - val_accuracy: 0.9333\n",
            "Epoch 307/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2273 - accuracy: 0.9889\n",
            "Epoch 307: val_loss improved from 0.29014 to 0.28924, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.2273 - accuracy: 0.9889 - val_loss: 0.2892 - val_accuracy: 0.9333\n",
            "Epoch 308/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2263 - accuracy: 0.9889\n",
            "Epoch 308: val_loss improved from 0.28924 to 0.28836, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.2263 - accuracy: 0.9889 - val_loss: 0.2884 - val_accuracy: 0.9333\n",
            "Epoch 309/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2252 - accuracy: 0.9889\n",
            "Epoch 309: val_loss improved from 0.28836 to 0.28747, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2252 - accuracy: 0.9889 - val_loss: 0.2875 - val_accuracy: 0.9333\n",
            "Epoch 310/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2242 - accuracy: 0.9889\n",
            "Epoch 310: val_loss improved from 0.28747 to 0.28659, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.2242 - accuracy: 0.9889 - val_loss: 0.2866 - val_accuracy: 0.9333\n",
            "Epoch 311/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2232 - accuracy: 0.9889\n",
            "Epoch 311: val_loss improved from 0.28659 to 0.28572, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.2232 - accuracy: 0.9889 - val_loss: 0.2857 - val_accuracy: 0.9333\n",
            "Epoch 312/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2222 - accuracy: 0.9889\n",
            "Epoch 312: val_loss improved from 0.28572 to 0.28486, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2222 - accuracy: 0.9889 - val_loss: 0.2849 - val_accuracy: 0.9333\n",
            "Epoch 313/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2213 - accuracy: 0.9889\n",
            "Epoch 313: val_loss improved from 0.28486 to 0.28401, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.2213 - accuracy: 0.9889 - val_loss: 0.2840 - val_accuracy: 0.9333\n",
            "Epoch 314/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2203 - accuracy: 0.9889\n",
            "Epoch 314: val_loss improved from 0.28401 to 0.28317, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.2203 - accuracy: 0.9889 - val_loss: 0.2832 - val_accuracy: 0.9333\n",
            "Epoch 315/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2193 - accuracy: 0.9889\n",
            "Epoch 315: val_loss improved from 0.28317 to 0.28235, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.2193 - accuracy: 0.9889 - val_loss: 0.2823 - val_accuracy: 0.9333\n",
            "Epoch 316/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2183 - accuracy: 0.9889\n",
            "Epoch 316: val_loss improved from 0.28235 to 0.28154, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.2183 - accuracy: 0.9889 - val_loss: 0.2815 - val_accuracy: 0.9333\n",
            "Epoch 317/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2174 - accuracy: 0.9889\n",
            "Epoch 317: val_loss improved from 0.28154 to 0.28072, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.2174 - accuracy: 0.9889 - val_loss: 0.2807 - val_accuracy: 0.9333\n",
            "Epoch 318/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2164 - accuracy: 0.9889\n",
            "Epoch 318: val_loss improved from 0.28072 to 0.27989, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2164 - accuracy: 0.9889 - val_loss: 0.2799 - val_accuracy: 0.9333\n",
            "Epoch 319/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2154 - accuracy: 0.9889\n",
            "Epoch 319: val_loss improved from 0.27989 to 0.27905, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.2154 - accuracy: 0.9889 - val_loss: 0.2791 - val_accuracy: 0.9333\n",
            "Epoch 320/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2144 - accuracy: 0.9889\n",
            "Epoch 320: val_loss improved from 0.27905 to 0.27820, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2144 - accuracy: 0.9889 - val_loss: 0.2782 - val_accuracy: 0.9333\n",
            "Epoch 321/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2135 - accuracy: 0.9889\n",
            "Epoch 321: val_loss improved from 0.27820 to 0.27735, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2135 - accuracy: 0.9889 - val_loss: 0.2773 - val_accuracy: 0.9333\n",
            "Epoch 322/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2125 - accuracy: 0.9889\n",
            "Epoch 322: val_loss improved from 0.27735 to 0.27647, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.2125 - accuracy: 0.9889 - val_loss: 0.2765 - val_accuracy: 0.9333\n",
            "Epoch 323/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2116 - accuracy: 0.9889\n",
            "Epoch 323: val_loss improved from 0.27647 to 0.27558, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.2116 - accuracy: 0.9889 - val_loss: 0.2756 - val_accuracy: 0.9333\n",
            "Epoch 324/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2106 - accuracy: 0.9889\n",
            "Epoch 324: val_loss improved from 0.27558 to 0.27468, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.2106 - accuracy: 0.9889 - val_loss: 0.2747 - val_accuracy: 0.9333\n",
            "Epoch 325/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2097 - accuracy: 0.9889\n",
            "Epoch 325: val_loss improved from 0.27468 to 0.27378, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.2097 - accuracy: 0.9889 - val_loss: 0.2738 - val_accuracy: 0.9333\n",
            "Epoch 326/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2087 - accuracy: 0.9889\n",
            "Epoch 326: val_loss improved from 0.27378 to 0.27287, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2087 - accuracy: 0.9889 - val_loss: 0.2729 - val_accuracy: 0.9333\n",
            "Epoch 327/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2078 - accuracy: 0.9889\n",
            "Epoch 327: val_loss improved from 0.27287 to 0.27198, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.2078 - accuracy: 0.9889 - val_loss: 0.2720 - val_accuracy: 0.9333\n",
            "Epoch 328/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2069 - accuracy: 0.9889\n",
            "Epoch 328: val_loss improved from 0.27198 to 0.27111, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2069 - accuracy: 0.9889 - val_loss: 0.2711 - val_accuracy: 0.9333\n",
            "Epoch 329/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2059 - accuracy: 0.9889\n",
            "Epoch 329: val_loss improved from 0.27111 to 0.27027, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.2059 - accuracy: 0.9889 - val_loss: 0.2703 - val_accuracy: 0.9333\n",
            "Epoch 330/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2050 - accuracy: 0.9889\n",
            "Epoch 330: val_loss improved from 0.27027 to 0.26947, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.2050 - accuracy: 0.9889 - val_loss: 0.2695 - val_accuracy: 0.9333\n",
            "Epoch 331/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2041 - accuracy: 0.9889\n",
            "Epoch 331: val_loss improved from 0.26947 to 0.26869, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2041 - accuracy: 0.9889 - val_loss: 0.2687 - val_accuracy: 0.9333\n",
            "Epoch 332/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2032 - accuracy: 0.9889\n",
            "Epoch 332: val_loss improved from 0.26869 to 0.26794, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.2032 - accuracy: 0.9889 - val_loss: 0.2679 - val_accuracy: 0.9333\n",
            "Epoch 333/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2023 - accuracy: 0.9889\n",
            "Epoch 333: val_loss improved from 0.26794 to 0.26719, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.2023 - accuracy: 0.9889 - val_loss: 0.2672 - val_accuracy: 0.9333\n",
            "Epoch 334/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2014 - accuracy: 0.9889\n",
            "Epoch 334: val_loss improved from 0.26719 to 0.26646, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.2014 - accuracy: 0.9889 - val_loss: 0.2665 - val_accuracy: 0.9333\n",
            "Epoch 335/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2004 - accuracy: 0.9889\n",
            "Epoch 335: val_loss improved from 0.26646 to 0.26570, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.2004 - accuracy: 0.9889 - val_loss: 0.2657 - val_accuracy: 0.9333\n",
            "Epoch 336/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1995 - accuracy: 0.9889\n",
            "Epoch 336: val_loss improved from 0.26570 to 0.26492, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1995 - accuracy: 0.9889 - val_loss: 0.2649 - val_accuracy: 0.9333\n",
            "Epoch 337/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1986 - accuracy: 0.9889\n",
            "Epoch 337: val_loss improved from 0.26492 to 0.26411, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.1986 - accuracy: 0.9889 - val_loss: 0.2641 - val_accuracy: 0.9333\n",
            "Epoch 338/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1978 - accuracy: 0.9889\n",
            "Epoch 338: val_loss improved from 0.26411 to 0.26329, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1978 - accuracy: 0.9889 - val_loss: 0.2633 - val_accuracy: 0.9333\n",
            "Epoch 339/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1969 - accuracy: 0.9889\n",
            "Epoch 339: val_loss improved from 0.26329 to 0.26246, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1969 - accuracy: 0.9889 - val_loss: 0.2625 - val_accuracy: 0.9333\n",
            "Epoch 340/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1960 - accuracy: 0.9889\n",
            "Epoch 340: val_loss improved from 0.26246 to 0.26163, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1960 - accuracy: 0.9889 - val_loss: 0.2616 - val_accuracy: 0.9333\n",
            "Epoch 341/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1951 - accuracy: 0.9889\n",
            "Epoch 341: val_loss improved from 0.26163 to 0.26080, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.1951 - accuracy: 0.9889 - val_loss: 0.2608 - val_accuracy: 0.9333\n",
            "Epoch 342/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1942 - accuracy: 0.9889\n",
            "Epoch 342: val_loss improved from 0.26080 to 0.25997, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1942 - accuracy: 0.9889 - val_loss: 0.2600 - val_accuracy: 0.9333\n",
            "Epoch 343/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1933 - accuracy: 0.9889\n",
            "Epoch 343: val_loss improved from 0.25997 to 0.25914, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1933 - accuracy: 0.9889 - val_loss: 0.2591 - val_accuracy: 0.9333\n",
            "Epoch 344/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1925 - accuracy: 0.9889\n",
            "Epoch 344: val_loss improved from 0.25914 to 0.25832, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1925 - accuracy: 0.9889 - val_loss: 0.2583 - val_accuracy: 0.9333\n",
            "Epoch 345/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1916 - accuracy: 0.9889\n",
            "Epoch 345: val_loss improved from 0.25832 to 0.25750, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1916 - accuracy: 0.9889 - val_loss: 0.2575 - val_accuracy: 0.9333\n",
            "Epoch 346/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1907 - accuracy: 0.9889\n",
            "Epoch 346: val_loss improved from 0.25750 to 0.25670, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1907 - accuracy: 0.9889 - val_loss: 0.2567 - val_accuracy: 0.9333\n",
            "Epoch 347/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1899 - accuracy: 0.9889\n",
            "Epoch 347: val_loss improved from 0.25670 to 0.25592, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1899 - accuracy: 0.9889 - val_loss: 0.2559 - val_accuracy: 0.9333\n",
            "Epoch 348/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1890 - accuracy: 0.9889\n",
            "Epoch 348: val_loss improved from 0.25592 to 0.25515, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1890 - accuracy: 0.9889 - val_loss: 0.2552 - val_accuracy: 0.9333\n",
            "Epoch 349/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1881 - accuracy: 0.9889\n",
            "Epoch 349: val_loss improved from 0.25515 to 0.25440, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.1881 - accuracy: 0.9889 - val_loss: 0.2544 - val_accuracy: 0.9333\n",
            "Epoch 350/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1873 - accuracy: 0.9889\n",
            "Epoch 350: val_loss improved from 0.25440 to 0.25364, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1873 - accuracy: 0.9889 - val_loss: 0.2536 - val_accuracy: 0.9333\n",
            "Epoch 351/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1864 - accuracy: 0.9889\n",
            "Epoch 351: val_loss improved from 0.25364 to 0.25288, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1864 - accuracy: 0.9889 - val_loss: 0.2529 - val_accuracy: 0.9333\n",
            "Epoch 352/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1856 - accuracy: 0.9889\n",
            "Epoch 352: val_loss improved from 0.25288 to 0.25213, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1856 - accuracy: 0.9889 - val_loss: 0.2521 - val_accuracy: 0.9333\n",
            "Epoch 353/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1848 - accuracy: 0.9889\n",
            "Epoch 353: val_loss improved from 0.25213 to 0.25138, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1848 - accuracy: 0.9889 - val_loss: 0.2514 - val_accuracy: 0.9333\n",
            "Epoch 354/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1839 - accuracy: 0.9889\n",
            "Epoch 354: val_loss improved from 0.25138 to 0.25064, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1839 - accuracy: 0.9889 - val_loss: 0.2506 - val_accuracy: 0.9333\n",
            "Epoch 355/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1831 - accuracy: 0.9889\n",
            "Epoch 355: val_loss improved from 0.25064 to 0.24988, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1831 - accuracy: 0.9889 - val_loss: 0.2499 - val_accuracy: 0.9333\n",
            "Epoch 356/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1823 - accuracy: 0.9889\n",
            "Epoch 356: val_loss improved from 0.24988 to 0.24912, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.1823 - accuracy: 0.9889 - val_loss: 0.2491 - val_accuracy: 0.9333\n",
            "Epoch 357/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1814 - accuracy: 0.9889\n",
            "Epoch 357: val_loss improved from 0.24912 to 0.24837, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1814 - accuracy: 0.9889 - val_loss: 0.2484 - val_accuracy: 0.9333\n",
            "Epoch 358/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1806 - accuracy: 0.9889\n",
            "Epoch 358: val_loss improved from 0.24837 to 0.24763, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1806 - accuracy: 0.9889 - val_loss: 0.2476 - val_accuracy: 0.9333\n",
            "Epoch 359/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1798 - accuracy: 0.9889\n",
            "Epoch 359: val_loss improved from 0.24763 to 0.24690, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.1798 - accuracy: 0.9889 - val_loss: 0.2469 - val_accuracy: 0.9333\n",
            "Epoch 360/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1790 - accuracy: 0.9889\n",
            "Epoch 360: val_loss improved from 0.24690 to 0.24616, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.1790 - accuracy: 0.9889 - val_loss: 0.2462 - val_accuracy: 0.9333\n",
            "Epoch 361/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1781 - accuracy: 0.9889\n",
            "Epoch 361: val_loss improved from 0.24616 to 0.24540, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1781 - accuracy: 0.9889 - val_loss: 0.2454 - val_accuracy: 0.9667\n",
            "Epoch 362/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1773 - accuracy: 0.9889\n",
            "Epoch 362: val_loss improved from 0.24540 to 0.24465, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1773 - accuracy: 0.9889 - val_loss: 0.2447 - val_accuracy: 0.9667\n",
            "Epoch 363/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1765 - accuracy: 0.9889\n",
            "Epoch 363: val_loss improved from 0.24465 to 0.24390, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1765 - accuracy: 0.9889 - val_loss: 0.2439 - val_accuracy: 0.9667\n",
            "Epoch 364/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1757 - accuracy: 0.9889\n",
            "Epoch 364: val_loss improved from 0.24390 to 0.24315, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1757 - accuracy: 0.9889 - val_loss: 0.2431 - val_accuracy: 0.9667\n",
            "Epoch 365/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1749 - accuracy: 0.9889\n",
            "Epoch 365: val_loss improved from 0.24315 to 0.24240, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1749 - accuracy: 0.9889 - val_loss: 0.2424 - val_accuracy: 0.9667\n",
            "Epoch 366/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1741 - accuracy: 0.9889\n",
            "Epoch 366: val_loss improved from 0.24240 to 0.24165, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1741 - accuracy: 0.9889 - val_loss: 0.2416 - val_accuracy: 0.9667\n",
            "Epoch 367/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1733 - accuracy: 0.9889\n",
            "Epoch 367: val_loss improved from 0.24165 to 0.24089, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1733 - accuracy: 0.9889 - val_loss: 0.2409 - val_accuracy: 0.9667\n",
            "Epoch 368/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1726 - accuracy: 0.9889\n",
            "Epoch 368: val_loss improved from 0.24089 to 0.24014, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1726 - accuracy: 0.9889 - val_loss: 0.2401 - val_accuracy: 0.9667\n",
            "Epoch 369/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1718 - accuracy: 0.9889\n",
            "Epoch 369: val_loss improved from 0.24014 to 0.23942, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1718 - accuracy: 0.9889 - val_loss: 0.2394 - val_accuracy: 0.9667\n",
            "Epoch 370/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1710 - accuracy: 0.9889\n",
            "Epoch 370: val_loss improved from 0.23942 to 0.23871, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1710 - accuracy: 0.9889 - val_loss: 0.2387 - val_accuracy: 0.9667\n",
            "Epoch 371/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1702 - accuracy: 0.9889\n",
            "Epoch 371: val_loss improved from 0.23871 to 0.23802, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1702 - accuracy: 0.9889 - val_loss: 0.2380 - val_accuracy: 0.9667\n",
            "Epoch 372/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1694 - accuracy: 0.9889\n",
            "Epoch 372: val_loss improved from 0.23802 to 0.23733, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1694 - accuracy: 0.9889 - val_loss: 0.2373 - val_accuracy: 0.9667\n",
            "Epoch 373/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1687 - accuracy: 0.9889\n",
            "Epoch 373: val_loss improved from 0.23733 to 0.23664, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1687 - accuracy: 0.9889 - val_loss: 0.2366 - val_accuracy: 0.9667\n",
            "Epoch 374/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1679 - accuracy: 0.9889\n",
            "Epoch 374: val_loss improved from 0.23664 to 0.23594, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1679 - accuracy: 0.9889 - val_loss: 0.2359 - val_accuracy: 0.9667\n",
            "Epoch 375/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1671 - accuracy: 0.9889\n",
            "Epoch 375: val_loss improved from 0.23594 to 0.23524, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1671 - accuracy: 0.9889 - val_loss: 0.2352 - val_accuracy: 0.9667\n",
            "Epoch 376/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1664 - accuracy: 0.9889\n",
            "Epoch 376: val_loss improved from 0.23524 to 0.23453, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1664 - accuracy: 0.9889 - val_loss: 0.2345 - val_accuracy: 0.9667\n",
            "Epoch 377/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1656 - accuracy: 0.9889\n",
            "Epoch 377: val_loss improved from 0.23453 to 0.23382, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1656 - accuracy: 0.9889 - val_loss: 0.2338 - val_accuracy: 0.9667\n",
            "Epoch 378/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1649 - accuracy: 0.9889\n",
            "Epoch 378: val_loss improved from 0.23382 to 0.23311, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1649 - accuracy: 0.9889 - val_loss: 0.2331 - val_accuracy: 0.9667\n",
            "Epoch 379/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1641 - accuracy: 0.9889\n",
            "Epoch 379: val_loss improved from 0.23311 to 0.23241, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1641 - accuracy: 0.9889 - val_loss: 0.2324 - val_accuracy: 0.9667\n",
            "Epoch 380/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1634 - accuracy: 0.9889\n",
            "Epoch 380: val_loss improved from 0.23241 to 0.23172, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1634 - accuracy: 0.9889 - val_loss: 0.2317 - val_accuracy: 0.9667\n",
            "Epoch 381/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1626 - accuracy: 0.9889\n",
            "Epoch 381: val_loss improved from 0.23172 to 0.23102, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1626 - accuracy: 0.9889 - val_loss: 0.2310 - val_accuracy: 0.9667\n",
            "Epoch 382/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1619 - accuracy: 0.9889\n",
            "Epoch 382: val_loss improved from 0.23102 to 0.23034, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.1619 - accuracy: 0.9889 - val_loss: 0.2303 - val_accuracy: 0.9667\n",
            "Epoch 383/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1611 - accuracy: 0.9889\n",
            "Epoch 383: val_loss improved from 0.23034 to 0.22966, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1611 - accuracy: 0.9889 - val_loss: 0.2297 - val_accuracy: 0.9667\n",
            "Epoch 384/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1604 - accuracy: 0.9889\n",
            "Epoch 384: val_loss improved from 0.22966 to 0.22898, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1604 - accuracy: 0.9889 - val_loss: 0.2290 - val_accuracy: 0.9667\n",
            "Epoch 385/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1597 - accuracy: 0.9889\n",
            "Epoch 385: val_loss improved from 0.22898 to 0.22830, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1597 - accuracy: 0.9889 - val_loss: 0.2283 - val_accuracy: 0.9667\n",
            "Epoch 386/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1589 - accuracy: 0.9889\n",
            "Epoch 386: val_loss improved from 0.22830 to 0.22761, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1589 - accuracy: 0.9889 - val_loss: 0.2276 - val_accuracy: 0.9667\n",
            "Epoch 387/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1582 - accuracy: 0.9889\n",
            "Epoch 387: val_loss improved from 0.22761 to 0.22692, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1582 - accuracy: 0.9889 - val_loss: 0.2269 - val_accuracy: 0.9667\n",
            "Epoch 388/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1575 - accuracy: 0.9889\n",
            "Epoch 388: val_loss improved from 0.22692 to 0.22625, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.1575 - accuracy: 0.9889 - val_loss: 0.2263 - val_accuracy: 0.9667\n",
            "Epoch 389/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1568 - accuracy: 0.9889\n",
            "Epoch 389: val_loss improved from 0.22625 to 0.22559, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1568 - accuracy: 0.9889 - val_loss: 0.2256 - val_accuracy: 0.9667\n",
            "Epoch 390/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1561 - accuracy: 0.9889\n",
            "Epoch 390: val_loss improved from 0.22559 to 0.22493, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1561 - accuracy: 0.9889 - val_loss: 0.2249 - val_accuracy: 0.9667\n",
            "Epoch 391/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1554 - accuracy: 0.9889\n",
            "Epoch 391: val_loss improved from 0.22493 to 0.22427, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1554 - accuracy: 0.9889 - val_loss: 0.2243 - val_accuracy: 0.9667\n",
            "Epoch 392/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1547 - accuracy: 0.9889\n",
            "Epoch 392: val_loss improved from 0.22427 to 0.22362, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1547 - accuracy: 0.9889 - val_loss: 0.2236 - val_accuracy: 0.9667\n",
            "Epoch 393/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1540 - accuracy: 0.9889\n",
            "Epoch 393: val_loss improved from 0.22362 to 0.22297, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1540 - accuracy: 0.9889 - val_loss: 0.2230 - val_accuracy: 0.9667\n",
            "Epoch 394/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1533 - accuracy: 0.9889\n",
            "Epoch 394: val_loss improved from 0.22297 to 0.22232, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1533 - accuracy: 0.9889 - val_loss: 0.2223 - val_accuracy: 0.9667\n",
            "Epoch 395/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1526 - accuracy: 0.9889\n",
            "Epoch 395: val_loss improved from 0.22232 to 0.22166, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1526 - accuracy: 0.9889 - val_loss: 0.2217 - val_accuracy: 0.9667\n",
            "Epoch 396/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1519 - accuracy: 0.9889\n",
            "Epoch 396: val_loss improved from 0.22166 to 0.22100, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1519 - accuracy: 0.9889 - val_loss: 0.2210 - val_accuracy: 0.9667\n",
            "Epoch 397/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1512 - accuracy: 0.9889\n",
            "Epoch 397: val_loss improved from 0.22100 to 0.22033, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1512 - accuracy: 0.9889 - val_loss: 0.2203 - val_accuracy: 0.9667\n",
            "Epoch 398/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1505 - accuracy: 0.9889\n",
            "Epoch 398: val_loss improved from 0.22033 to 0.21968, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1505 - accuracy: 0.9889 - val_loss: 0.2197 - val_accuracy: 0.9667\n",
            "Epoch 399/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1498 - accuracy: 0.9889\n",
            "Epoch 399: val_loss improved from 0.21968 to 0.21905, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1498 - accuracy: 0.9889 - val_loss: 0.2190 - val_accuracy: 0.9667\n",
            "Epoch 400/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1491 - accuracy: 0.9889\n",
            "Epoch 400: val_loss improved from 0.21905 to 0.21842, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1491 - accuracy: 0.9889 - val_loss: 0.2184 - val_accuracy: 0.9667\n",
            "Epoch 401/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1485 - accuracy: 0.9889\n",
            "Epoch 401: val_loss improved from 0.21842 to 0.21780, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.1485 - accuracy: 0.9889 - val_loss: 0.2178 - val_accuracy: 0.9667\n",
            "Epoch 402/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1478 - accuracy: 0.9889\n",
            "Epoch 402: val_loss improved from 0.21780 to 0.21718, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.1478 - accuracy: 0.9889 - val_loss: 0.2172 - val_accuracy: 0.9667\n",
            "Epoch 403/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1471 - accuracy: 0.9889\n",
            "Epoch 403: val_loss improved from 0.21718 to 0.21655, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1471 - accuracy: 0.9889 - val_loss: 0.2166 - val_accuracy: 0.9667\n",
            "Epoch 404/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1465 - accuracy: 0.9889\n",
            "Epoch 404: val_loss improved from 0.21655 to 0.21591, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.1465 - accuracy: 0.9889 - val_loss: 0.2159 - val_accuracy: 0.9667\n",
            "Epoch 405/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1458 - accuracy: 0.9889\n",
            "Epoch 405: val_loss improved from 0.21591 to 0.21527, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1458 - accuracy: 0.9889 - val_loss: 0.2153 - val_accuracy: 0.9667\n",
            "Epoch 406/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1451 - accuracy: 0.9889\n",
            "Epoch 406: val_loss improved from 0.21527 to 0.21464, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1451 - accuracy: 0.9889 - val_loss: 0.2146 - val_accuracy: 0.9667\n",
            "Epoch 407/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1445 - accuracy: 0.9889\n",
            "Epoch 407: val_loss improved from 0.21464 to 0.21402, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1445 - accuracy: 0.9889 - val_loss: 0.2140 - val_accuracy: 0.9667\n",
            "Epoch 408/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1438 - accuracy: 0.9889\n",
            "Epoch 408: val_loss improved from 0.21402 to 0.21342, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1438 - accuracy: 0.9889 - val_loss: 0.2134 - val_accuracy: 0.9667\n",
            "Epoch 409/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1432 - accuracy: 0.9889\n",
            "Epoch 409: val_loss improved from 0.21342 to 0.21282, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1432 - accuracy: 0.9889 - val_loss: 0.2128 - val_accuracy: 0.9667\n",
            "Epoch 410/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1425 - accuracy: 0.9889\n",
            "Epoch 410: val_loss improved from 0.21282 to 0.21221, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1425 - accuracy: 0.9889 - val_loss: 0.2122 - val_accuracy: 0.9667\n",
            "Epoch 411/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1419 - accuracy: 0.9889\n",
            "Epoch 411: val_loss improved from 0.21221 to 0.21159, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1419 - accuracy: 0.9889 - val_loss: 0.2116 - val_accuracy: 0.9667\n",
            "Epoch 412/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1413 - accuracy: 0.9889\n",
            "Epoch 412: val_loss improved from 0.21159 to 0.21099, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1413 - accuracy: 0.9889 - val_loss: 0.2110 - val_accuracy: 0.9667\n",
            "Epoch 413/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1406 - accuracy: 0.9889\n",
            "Epoch 413: val_loss improved from 0.21099 to 0.21039, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1406 - accuracy: 0.9889 - val_loss: 0.2104 - val_accuracy: 0.9667\n",
            "Epoch 414/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1400 - accuracy: 0.9889\n",
            "Epoch 414: val_loss improved from 0.21039 to 0.20979, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.1400 - accuracy: 0.9889 - val_loss: 0.2098 - val_accuracy: 0.9667\n",
            "Epoch 415/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1394 - accuracy: 0.9889\n",
            "Epoch 415: val_loss improved from 0.20979 to 0.20918, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.1394 - accuracy: 0.9889 - val_loss: 0.2092 - val_accuracy: 0.9667\n",
            "Epoch 416/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1387 - accuracy: 0.9889\n",
            "Epoch 416: val_loss improved from 0.20918 to 0.20859, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.1387 - accuracy: 0.9889 - val_loss: 0.2086 - val_accuracy: 0.9667\n",
            "Epoch 417/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1381 - accuracy: 0.9889\n",
            "Epoch 417: val_loss improved from 0.20859 to 0.20801, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.1381 - accuracy: 0.9889 - val_loss: 0.2080 - val_accuracy: 0.9667\n",
            "Epoch 418/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1375 - accuracy: 0.9889\n",
            "Epoch 418: val_loss improved from 0.20801 to 0.20742, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.1375 - accuracy: 0.9889 - val_loss: 0.2074 - val_accuracy: 0.9667\n",
            "Epoch 419/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1369 - accuracy: 0.9889\n",
            "Epoch 419: val_loss improved from 0.20742 to 0.20683, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.1369 - accuracy: 0.9889 - val_loss: 0.2068 - val_accuracy: 0.9667\n",
            "Epoch 420/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1363 - accuracy: 0.9889\n",
            "Epoch 420: val_loss improved from 0.20683 to 0.20623, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.1363 - accuracy: 0.9889 - val_loss: 0.2062 - val_accuracy: 0.9667\n",
            "Epoch 421/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1356 - accuracy: 0.9889\n",
            "Epoch 421: val_loss improved from 0.20623 to 0.20563, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1356 - accuracy: 0.9889 - val_loss: 0.2056 - val_accuracy: 0.9667\n",
            "Epoch 422/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1350 - accuracy: 0.9889\n",
            "Epoch 422: val_loss improved from 0.20563 to 0.20504, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1350 - accuracy: 0.9889 - val_loss: 0.2050 - val_accuracy: 0.9667\n",
            "Epoch 423/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1344 - accuracy: 0.9889\n",
            "Epoch 423: val_loss improved from 0.20504 to 0.20447, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1344 - accuracy: 0.9889 - val_loss: 0.2045 - val_accuracy: 0.9667\n",
            "Epoch 424/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1338 - accuracy: 0.9889\n",
            "Epoch 424: val_loss improved from 0.20447 to 0.20391, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.1338 - accuracy: 0.9889 - val_loss: 0.2039 - val_accuracy: 0.9667\n",
            "Epoch 425/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1332 - accuracy: 0.9889\n",
            "Epoch 425: val_loss improved from 0.20391 to 0.20336, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.1332 - accuracy: 0.9889 - val_loss: 0.2034 - val_accuracy: 0.9667\n",
            "Epoch 426/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1326 - accuracy: 0.9889\n",
            "Epoch 426: val_loss improved from 0.20336 to 0.20282, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1326 - accuracy: 0.9889 - val_loss: 0.2028 - val_accuracy: 0.9667\n",
            "Epoch 427/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1321 - accuracy: 0.9889\n",
            "Epoch 427: val_loss improved from 0.20282 to 0.20226, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1321 - accuracy: 0.9889 - val_loss: 0.2023 - val_accuracy: 0.9667\n",
            "Epoch 428/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1315 - accuracy: 0.9889\n",
            "Epoch 428: val_loss improved from 0.20226 to 0.20169, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1315 - accuracy: 0.9889 - val_loss: 0.2017 - val_accuracy: 0.9667\n",
            "Epoch 429/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1309 - accuracy: 0.9889\n",
            "Epoch 429: val_loss improved from 0.20169 to 0.20112, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.1309 - accuracy: 0.9889 - val_loss: 0.2011 - val_accuracy: 0.9667\n",
            "Epoch 430/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1303 - accuracy: 0.9889\n",
            "Epoch 430: val_loss improved from 0.20112 to 0.20053, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1303 - accuracy: 0.9889 - val_loss: 0.2005 - val_accuracy: 0.9667\n",
            "Epoch 431/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1297 - accuracy: 0.9889\n",
            "Epoch 431: val_loss improved from 0.20053 to 0.19996, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1297 - accuracy: 0.9889 - val_loss: 0.2000 - val_accuracy: 0.9667\n",
            "Epoch 432/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1291 - accuracy: 0.9889\n",
            "Epoch 432: val_loss improved from 0.19996 to 0.19940, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1291 - accuracy: 0.9889 - val_loss: 0.1994 - val_accuracy: 0.9667\n",
            "Epoch 433/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1286 - accuracy: 0.9889\n",
            "Epoch 433: val_loss improved from 0.19940 to 0.19886, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1286 - accuracy: 0.9889 - val_loss: 0.1989 - val_accuracy: 0.9667\n",
            "Epoch 434/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1280 - accuracy: 0.9889\n",
            "Epoch 434: val_loss improved from 0.19886 to 0.19832, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1280 - accuracy: 0.9889 - val_loss: 0.1983 - val_accuracy: 0.9667\n",
            "Epoch 435/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1274 - accuracy: 0.9889\n",
            "Epoch 435: val_loss improved from 0.19832 to 0.19780, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1274 - accuracy: 0.9889 - val_loss: 0.1978 - val_accuracy: 0.9667\n",
            "Epoch 436/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1269 - accuracy: 0.9889\n",
            "Epoch 436: val_loss improved from 0.19780 to 0.19728, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1269 - accuracy: 0.9889 - val_loss: 0.1973 - val_accuracy: 0.9667\n",
            "Epoch 437/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1263 - accuracy: 0.9889\n",
            "Epoch 437: val_loss improved from 0.19728 to 0.19675, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1263 - accuracy: 0.9889 - val_loss: 0.1967 - val_accuracy: 0.9667\n",
            "Epoch 438/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1258 - accuracy: 0.9889\n",
            "Epoch 438: val_loss improved from 0.19675 to 0.19620, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1258 - accuracy: 0.9889 - val_loss: 0.1962 - val_accuracy: 0.9667\n",
            "Epoch 439/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1252 - accuracy: 0.9889\n",
            "Epoch 439: val_loss improved from 0.19620 to 0.19564, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1252 - accuracy: 0.9889 - val_loss: 0.1956 - val_accuracy: 0.9667\n",
            "Epoch 440/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1247 - accuracy: 0.9889\n",
            "Epoch 440: val_loss improved from 0.19564 to 0.19509, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1247 - accuracy: 0.9889 - val_loss: 0.1951 - val_accuracy: 0.9667\n",
            "Epoch 441/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1241 - accuracy: 0.9889\n",
            "Epoch 441: val_loss improved from 0.19509 to 0.19454, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1241 - accuracy: 0.9889 - val_loss: 0.1945 - val_accuracy: 0.9667\n",
            "Epoch 442/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1236 - accuracy: 0.9889\n",
            "Epoch 442: val_loss improved from 0.19454 to 0.19400, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1236 - accuracy: 0.9889 - val_loss: 0.1940 - val_accuracy: 0.9667\n",
            "Epoch 443/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1230 - accuracy: 0.9889\n",
            "Epoch 443: val_loss improved from 0.19400 to 0.19349, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1230 - accuracy: 0.9889 - val_loss: 0.1935 - val_accuracy: 0.9667\n",
            "Epoch 444/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1225 - accuracy: 0.9889\n",
            "Epoch 444: val_loss improved from 0.19349 to 0.19298, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1225 - accuracy: 0.9889 - val_loss: 0.1930 - val_accuracy: 0.9667\n",
            "Epoch 445/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1219 - accuracy: 0.9889\n",
            "Epoch 445: val_loss improved from 0.19298 to 0.19248, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1219 - accuracy: 0.9889 - val_loss: 0.1925 - val_accuracy: 0.9667\n",
            "Epoch 446/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1214 - accuracy: 0.9889\n",
            "Epoch 446: val_loss improved from 0.19248 to 0.19199, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.1214 - accuracy: 0.9889 - val_loss: 0.1920 - val_accuracy: 0.9667\n",
            "Epoch 447/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1209 - accuracy: 0.9889\n",
            "Epoch 447: val_loss improved from 0.19199 to 0.19149, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1209 - accuracy: 0.9889 - val_loss: 0.1915 - val_accuracy: 0.9667\n",
            "Epoch 448/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1203 - accuracy: 0.9889\n",
            "Epoch 448: val_loss improved from 0.19149 to 0.19099, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1203 - accuracy: 0.9889 - val_loss: 0.1910 - val_accuracy: 0.9667\n",
            "Epoch 449/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1198 - accuracy: 0.9889\n",
            "Epoch 449: val_loss improved from 0.19099 to 0.19048, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1198 - accuracy: 0.9889 - val_loss: 0.1905 - val_accuracy: 0.9667\n",
            "Epoch 450/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1193 - accuracy: 0.9889\n",
            "Epoch 450: val_loss improved from 0.19048 to 0.18995, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1193 - accuracy: 0.9889 - val_loss: 0.1900 - val_accuracy: 0.9667\n",
            "Epoch 451/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1188 - accuracy: 0.9889\n",
            "Epoch 451: val_loss improved from 0.18995 to 0.18942, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1188 - accuracy: 0.9889 - val_loss: 0.1894 - val_accuracy: 0.9667\n",
            "Epoch 452/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1183 - accuracy: 0.9889\n",
            "Epoch 452: val_loss improved from 0.18942 to 0.18890, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1183 - accuracy: 0.9889 - val_loss: 0.1889 - val_accuracy: 0.9667\n",
            "Epoch 453/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1178 - accuracy: 0.9889\n",
            "Epoch 453: val_loss improved from 0.18890 to 0.18837, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1178 - accuracy: 0.9889 - val_loss: 0.1884 - val_accuracy: 0.9667\n",
            "Epoch 454/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1172 - accuracy: 0.9889\n",
            "Epoch 454: val_loss improved from 0.18837 to 0.18787, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.1172 - accuracy: 0.9889 - val_loss: 0.1879 - val_accuracy: 0.9667\n",
            "Epoch 455/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1167 - accuracy: 0.9889\n",
            "Epoch 455: val_loss improved from 0.18787 to 0.18738, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.1167 - accuracy: 0.9889 - val_loss: 0.1874 - val_accuracy: 0.9667\n",
            "Epoch 456/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1162 - accuracy: 0.9889\n",
            "Epoch 456: val_loss improved from 0.18738 to 0.18690, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.1162 - accuracy: 0.9889 - val_loss: 0.1869 - val_accuracy: 0.9667\n",
            "Epoch 457/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1157 - accuracy: 0.9889\n",
            "Epoch 457: val_loss improved from 0.18690 to 0.18644, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1157 - accuracy: 0.9889 - val_loss: 0.1864 - val_accuracy: 0.9667\n",
            "Epoch 458/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1152 - accuracy: 0.9889\n",
            "Epoch 458: val_loss improved from 0.18644 to 0.18598, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1152 - accuracy: 0.9889 - val_loss: 0.1860 - val_accuracy: 0.9667\n",
            "Epoch 459/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1147 - accuracy: 0.9889\n",
            "Epoch 459: val_loss improved from 0.18598 to 0.18552, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1147 - accuracy: 0.9889 - val_loss: 0.1855 - val_accuracy: 0.9667\n",
            "Epoch 460/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1142 - accuracy: 0.9889\n",
            "Epoch 460: val_loss improved from 0.18552 to 0.18506, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1142 - accuracy: 0.9889 - val_loss: 0.1851 - val_accuracy: 0.9667\n",
            "Epoch 461/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1137 - accuracy: 0.9889\n",
            "Epoch 461: val_loss improved from 0.18506 to 0.18458, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1137 - accuracy: 0.9889 - val_loss: 0.1846 - val_accuracy: 0.9667\n",
            "Epoch 462/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1133 - accuracy: 0.9889\n",
            "Epoch 462: val_loss improved from 0.18458 to 0.18408, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1133 - accuracy: 0.9889 - val_loss: 0.1841 - val_accuracy: 0.9667\n",
            "Epoch 463/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1128 - accuracy: 0.9889\n",
            "Epoch 463: val_loss improved from 0.18408 to 0.18358, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1128 - accuracy: 0.9889 - val_loss: 0.1836 - val_accuracy: 0.9667\n",
            "Epoch 464/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1123 - accuracy: 0.9889\n",
            "Epoch 464: val_loss improved from 0.18358 to 0.18307, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1123 - accuracy: 0.9889 - val_loss: 0.1831 - val_accuracy: 0.9667\n",
            "Epoch 465/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1118 - accuracy: 0.9889\n",
            "Epoch 465: val_loss improved from 0.18307 to 0.18257, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1118 - accuracy: 0.9889 - val_loss: 0.1826 - val_accuracy: 0.9667\n",
            "Epoch 466/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1113 - accuracy: 0.9889\n",
            "Epoch 466: val_loss improved from 0.18257 to 0.18208, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1113 - accuracy: 0.9889 - val_loss: 0.1821 - val_accuracy: 0.9667\n",
            "Epoch 467/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1109 - accuracy: 0.9889\n",
            "Epoch 467: val_loss improved from 0.18208 to 0.18161, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1109 - accuracy: 0.9889 - val_loss: 0.1816 - val_accuracy: 0.9667\n",
            "Epoch 468/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1104 - accuracy: 0.9889\n",
            "Epoch 468: val_loss improved from 0.18161 to 0.18116, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1104 - accuracy: 0.9889 - val_loss: 0.1812 - val_accuracy: 0.9667\n",
            "Epoch 469/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1099 - accuracy: 0.9889\n",
            "Epoch 469: val_loss improved from 0.18116 to 0.18072, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1099 - accuracy: 0.9889 - val_loss: 0.1807 - val_accuracy: 0.9667\n",
            "Epoch 470/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1094 - accuracy: 0.9889\n",
            "Epoch 470: val_loss improved from 0.18072 to 0.18030, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1094 - accuracy: 0.9889 - val_loss: 0.1803 - val_accuracy: 0.9667\n",
            "Epoch 471/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1090 - accuracy: 0.9889\n",
            "Epoch 471: val_loss improved from 0.18030 to 0.17987, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.1090 - accuracy: 0.9889 - val_loss: 0.1799 - val_accuracy: 0.9667\n",
            "Epoch 472/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1085 - accuracy: 0.9889\n",
            "Epoch 472: val_loss improved from 0.17987 to 0.17944, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.1085 - accuracy: 0.9889 - val_loss: 0.1794 - val_accuracy: 0.9667\n",
            "Epoch 473/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1081 - accuracy: 0.9889\n",
            "Epoch 473: val_loss improved from 0.17944 to 0.17899, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1081 - accuracy: 0.9889 - val_loss: 0.1790 - val_accuracy: 0.9667\n",
            "Epoch 474/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1076 - accuracy: 0.9889\n",
            "Epoch 474: val_loss improved from 0.17899 to 0.17853, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1076 - accuracy: 0.9889 - val_loss: 0.1785 - val_accuracy: 0.9667\n",
            "Epoch 475/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1072 - accuracy: 0.9889\n",
            "Epoch 475: val_loss improved from 0.17853 to 0.17807, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1072 - accuracy: 0.9889 - val_loss: 0.1781 - val_accuracy: 0.9667\n",
            "Epoch 476/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1067 - accuracy: 0.9889\n",
            "Epoch 476: val_loss improved from 0.17807 to 0.17763, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1067 - accuracy: 0.9889 - val_loss: 0.1776 - val_accuracy: 0.9667\n",
            "Epoch 477/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1063 - accuracy: 0.9889\n",
            "Epoch 477: val_loss improved from 0.17763 to 0.17720, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1063 - accuracy: 0.9889 - val_loss: 0.1772 - val_accuracy: 0.9667\n",
            "Epoch 478/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1058 - accuracy: 0.9889\n",
            "Epoch 478: val_loss improved from 0.17720 to 0.17678, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1058 - accuracy: 0.9889 - val_loss: 0.1768 - val_accuracy: 0.9667\n",
            "Epoch 479/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1054 - accuracy: 0.9889\n",
            "Epoch 479: val_loss improved from 0.17678 to 0.17636, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1054 - accuracy: 0.9889 - val_loss: 0.1764 - val_accuracy: 0.9667\n",
            "Epoch 480/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1049 - accuracy: 0.9889\n",
            "Epoch 480: val_loss improved from 0.17636 to 0.17594, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1049 - accuracy: 0.9889 - val_loss: 0.1759 - val_accuracy: 0.9667\n",
            "Epoch 481/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1045 - accuracy: 0.9889\n",
            "Epoch 481: val_loss improved from 0.17594 to 0.17551, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1045 - accuracy: 0.9889 - val_loss: 0.1755 - val_accuracy: 0.9667\n",
            "Epoch 482/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1040 - accuracy: 0.9889\n",
            "Epoch 482: val_loss improved from 0.17551 to 0.17507, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1040 - accuracy: 0.9889 - val_loss: 0.1751 - val_accuracy: 0.9667\n",
            "Epoch 483/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1036 - accuracy: 0.9889\n",
            "Epoch 483: val_loss improved from 0.17507 to 0.17462, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1036 - accuracy: 0.9889 - val_loss: 0.1746 - val_accuracy: 0.9667\n",
            "Epoch 484/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1032 - accuracy: 0.9889\n",
            "Epoch 484: val_loss improved from 0.17462 to 0.17419, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1032 - accuracy: 0.9889 - val_loss: 0.1742 - val_accuracy: 0.9667\n",
            "Epoch 485/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1028 - accuracy: 0.9889\n",
            "Epoch 485: val_loss improved from 0.17419 to 0.17376, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.1028 - accuracy: 0.9889 - val_loss: 0.1738 - val_accuracy: 0.9667\n",
            "Epoch 486/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1023 - accuracy: 0.9889\n",
            "Epoch 486: val_loss improved from 0.17376 to 0.17334, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1023 - accuracy: 0.9889 - val_loss: 0.1733 - val_accuracy: 0.9667\n",
            "Epoch 487/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1019 - accuracy: 0.9889\n",
            "Epoch 487: val_loss improved from 0.17334 to 0.17293, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.1019 - accuracy: 0.9889 - val_loss: 0.1729 - val_accuracy: 0.9667\n",
            "Epoch 488/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1015 - accuracy: 0.9889\n",
            "Epoch 488: val_loss improved from 0.17293 to 0.17251, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1015 - accuracy: 0.9889 - val_loss: 0.1725 - val_accuracy: 0.9667\n",
            "Epoch 489/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1011 - accuracy: 1.0000\n",
            "Epoch 489: val_loss improved from 0.17251 to 0.17209, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.1011 - accuracy: 1.0000 - val_loss: 0.1721 - val_accuracy: 0.9667\n",
            "Epoch 490/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1006 - accuracy: 1.0000\n",
            "Epoch 490: val_loss improved from 0.17209 to 0.17166, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1006 - accuracy: 1.0000 - val_loss: 0.1717 - val_accuracy: 0.9667\n",
            "Epoch 491/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1002 - accuracy: 1.0000\n",
            "Epoch 491: val_loss improved from 0.17166 to 0.17124, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.1002 - accuracy: 1.0000 - val_loss: 0.1712 - val_accuracy: 0.9667\n",
            "Epoch 492/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0998 - accuracy: 1.0000\n",
            "Epoch 492: val_loss improved from 0.17124 to 0.17083, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0998 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 0.9667\n",
            "Epoch 493/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0994 - accuracy: 1.0000\n",
            "Epoch 493: val_loss improved from 0.17083 to 0.17043, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0994 - accuracy: 1.0000 - val_loss: 0.1704 - val_accuracy: 0.9667\n",
            "Epoch 494/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0990 - accuracy: 1.0000\n",
            "Epoch 494: val_loss improved from 0.17043 to 0.17004, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0990 - accuracy: 1.0000 - val_loss: 0.1700 - val_accuracy: 0.9667\n",
            "Epoch 495/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0986 - accuracy: 1.0000\n",
            "Epoch 495: val_loss improved from 0.17004 to 0.16963, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0986 - accuracy: 1.0000 - val_loss: 0.1696 - val_accuracy: 0.9667\n",
            "Epoch 496/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0982 - accuracy: 1.0000\n",
            "Epoch 496: val_loss improved from 0.16963 to 0.16915, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0982 - accuracy: 1.0000 - val_loss: 0.1691 - val_accuracy: 0.9667\n",
            "Epoch 497/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0978 - accuracy: 1.0000\n",
            "Epoch 497: val_loss improved from 0.16915 to 0.16862, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0978 - accuracy: 1.0000 - val_loss: 0.1686 - val_accuracy: 0.9667\n",
            "Epoch 498/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0974 - accuracy: 1.0000\n",
            "Epoch 498: val_loss improved from 0.16862 to 0.16817, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0974 - accuracy: 1.0000 - val_loss: 0.1682 - val_accuracy: 0.9667\n",
            "Epoch 499/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0970 - accuracy: 1.0000\n",
            "Epoch 499: val_loss improved from 0.16817 to 0.16777, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0970 - accuracy: 1.0000 - val_loss: 0.1678 - val_accuracy: 0.9667\n",
            "Epoch 500/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0965 - accuracy: 1.0000\n",
            "Epoch 500: val_loss improved from 0.16777 to 0.16743, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0965 - accuracy: 1.0000 - val_loss: 0.1674 - val_accuracy: 0.9667\n",
            "Epoch 501/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0961 - accuracy: 1.0000\n",
            "Epoch 501: val_loss improved from 0.16743 to 0.16700, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0961 - accuracy: 1.0000 - val_loss: 0.1670 - val_accuracy: 0.9667\n",
            "Epoch 502/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0957 - accuracy: 1.0000\n",
            "Epoch 502: val_loss improved from 0.16700 to 0.16648, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0957 - accuracy: 1.0000 - val_loss: 0.1665 - val_accuracy: 0.9667\n",
            "Epoch 503/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0952 - accuracy: 1.0000\n",
            "Epoch 503: val_loss improved from 0.16648 to 0.16594, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0952 - accuracy: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9667\n",
            "Epoch 504/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0948 - accuracy: 1.0000\n",
            "Epoch 504: val_loss improved from 0.16594 to 0.16544, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0948 - accuracy: 1.0000 - val_loss: 0.1654 - val_accuracy: 0.9667\n",
            "Epoch 505/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0944 - accuracy: 1.0000\n",
            "Epoch 505: val_loss improved from 0.16544 to 0.16498, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0944 - accuracy: 1.0000 - val_loss: 0.1650 - val_accuracy: 0.9667\n",
            "Epoch 506/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0939 - accuracy: 1.0000\n",
            "Epoch 506: val_loss improved from 0.16498 to 0.16455, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0939 - accuracy: 1.0000 - val_loss: 0.1646 - val_accuracy: 0.9667\n",
            "Epoch 507/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0934 - accuracy: 1.0000\n",
            "Epoch 507: val_loss improved from 0.16455 to 0.16413, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0934 - accuracy: 1.0000 - val_loss: 0.1641 - val_accuracy: 0.9667\n",
            "Epoch 508/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0930 - accuracy: 1.0000\n",
            "Epoch 508: val_loss improved from 0.16413 to 0.16367, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0930 - accuracy: 1.0000 - val_loss: 0.1637 - val_accuracy: 0.9667\n",
            "Epoch 509/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0925 - accuracy: 1.0000\n",
            "Epoch 509: val_loss improved from 0.16367 to 0.16311, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0925 - accuracy: 1.0000 - val_loss: 0.1631 - val_accuracy: 0.9667\n",
            "Epoch 510/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0920 - accuracy: 1.0000\n",
            "Epoch 510: val_loss improved from 0.16311 to 0.16250, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0920 - accuracy: 1.0000 - val_loss: 0.1625 - val_accuracy: 0.9667\n",
            "Epoch 511/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0915 - accuracy: 1.0000\n",
            "Epoch 511: val_loss improved from 0.16250 to 0.16187, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0915 - accuracy: 1.0000 - val_loss: 0.1619 - val_accuracy: 0.9667\n",
            "Epoch 512/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0910 - accuracy: 1.0000\n",
            "Epoch 512: val_loss improved from 0.16187 to 0.16125, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0910 - accuracy: 1.0000 - val_loss: 0.1613 - val_accuracy: 0.9667\n",
            "Epoch 513/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0905 - accuracy: 1.0000\n",
            "Epoch 513: val_loss improved from 0.16125 to 0.16066, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0905 - accuracy: 1.0000 - val_loss: 0.1607 - val_accuracy: 0.9667\n",
            "Epoch 514/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0900 - accuracy: 1.0000\n",
            "Epoch 514: val_loss improved from 0.16066 to 0.16010, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0900 - accuracy: 1.0000 - val_loss: 0.1601 - val_accuracy: 0.9667\n",
            "Epoch 515/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0894 - accuracy: 1.0000\n",
            "Epoch 515: val_loss improved from 0.16010 to 0.15958, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0894 - accuracy: 1.0000 - val_loss: 0.1596 - val_accuracy: 0.9667\n",
            "Epoch 516/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0889 - accuracy: 1.0000\n",
            "Epoch 516: val_loss improved from 0.15958 to 0.15909, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0889 - accuracy: 1.0000 - val_loss: 0.1591 - val_accuracy: 0.9667\n",
            "Epoch 517/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0884 - accuracy: 1.0000\n",
            "Epoch 517: val_loss improved from 0.15909 to 0.15861, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0884 - accuracy: 1.0000 - val_loss: 0.1586 - val_accuracy: 0.9667\n",
            "Epoch 518/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0878 - accuracy: 1.0000\n",
            "Epoch 518: val_loss improved from 0.15861 to 0.15812, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0878 - accuracy: 1.0000 - val_loss: 0.1581 - val_accuracy: 0.9667\n",
            "Epoch 519/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0872 - accuracy: 1.0000\n",
            "Epoch 519: val_loss improved from 0.15812 to 0.15760, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0872 - accuracy: 1.0000 - val_loss: 0.1576 - val_accuracy: 0.9667\n",
            "Epoch 520/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0867 - accuracy: 1.0000\n",
            "Epoch 520: val_loss improved from 0.15760 to 0.15703, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0867 - accuracy: 1.0000 - val_loss: 0.1570 - val_accuracy: 0.9667\n",
            "Epoch 521/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0861 - accuracy: 1.0000\n",
            "Epoch 521: val_loss improved from 0.15703 to 0.15642, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0861 - accuracy: 1.0000 - val_loss: 0.1564 - val_accuracy: 0.9667\n",
            "Epoch 522/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0855 - accuracy: 1.0000\n",
            "Epoch 522: val_loss improved from 0.15642 to 0.15577, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0855 - accuracy: 1.0000 - val_loss: 0.1558 - val_accuracy: 0.9667\n",
            "Epoch 523/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0849 - accuracy: 1.0000\n",
            "Epoch 523: val_loss improved from 0.15577 to 0.15510, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0849 - accuracy: 1.0000 - val_loss: 0.1551 - val_accuracy: 0.9667\n",
            "Epoch 524/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0844 - accuracy: 1.0000\n",
            "Epoch 524: val_loss improved from 0.15510 to 0.15442, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0844 - accuracy: 1.0000 - val_loss: 0.1544 - val_accuracy: 0.9667\n",
            "Epoch 525/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0838 - accuracy: 1.0000\n",
            "Epoch 525: val_loss improved from 0.15442 to 0.15373, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0838 - accuracy: 1.0000 - val_loss: 0.1537 - val_accuracy: 0.9667\n",
            "Epoch 526/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0832 - accuracy: 1.0000\n",
            "Epoch 526: val_loss improved from 0.15373 to 0.15305, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0832 - accuracy: 1.0000 - val_loss: 0.1530 - val_accuracy: 0.9667\n",
            "Epoch 527/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0826 - accuracy: 1.0000\n",
            "Epoch 527: val_loss improved from 0.15305 to 0.15241, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0826 - accuracy: 1.0000 - val_loss: 0.1524 - val_accuracy: 0.9667\n",
            "Epoch 528/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0820 - accuracy: 1.0000\n",
            "Epoch 528: val_loss improved from 0.15241 to 0.15180, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0820 - accuracy: 1.0000 - val_loss: 0.1518 - val_accuracy: 0.9667\n",
            "Epoch 529/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0814 - accuracy: 1.0000\n",
            "Epoch 529: val_loss improved from 0.15180 to 0.15123, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0814 - accuracy: 1.0000 - val_loss: 0.1512 - val_accuracy: 0.9667\n",
            "Epoch 530/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0808 - accuracy: 1.0000\n",
            "Epoch 530: val_loss improved from 0.15123 to 0.15065, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0808 - accuracy: 1.0000 - val_loss: 0.1506 - val_accuracy: 0.9667\n",
            "Epoch 531/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0802 - accuracy: 1.0000\n",
            "Epoch 531: val_loss improved from 0.15065 to 0.15006, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0802 - accuracy: 1.0000 - val_loss: 0.1501 - val_accuracy: 0.9667\n",
            "Epoch 532/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0796 - accuracy: 1.0000\n",
            "Epoch 532: val_loss improved from 0.15006 to 0.14945, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0796 - accuracy: 1.0000 - val_loss: 0.1495 - val_accuracy: 0.9667\n",
            "Epoch 533/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0789 - accuracy: 1.0000\n",
            "Epoch 533: val_loss improved from 0.14945 to 0.14883, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0789 - accuracy: 1.0000 - val_loss: 0.1488 - val_accuracy: 0.9667\n",
            "Epoch 534/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0783 - accuracy: 1.0000\n",
            "Epoch 534: val_loss improved from 0.14883 to 0.14819, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0783 - accuracy: 1.0000 - val_loss: 0.1482 - val_accuracy: 0.9667\n",
            "Epoch 535/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0777 - accuracy: 1.0000\n",
            "Epoch 535: val_loss improved from 0.14819 to 0.14755, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0777 - accuracy: 1.0000 - val_loss: 0.1475 - val_accuracy: 0.9667\n",
            "Epoch 536/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0771 - accuracy: 1.0000\n",
            "Epoch 536: val_loss improved from 0.14755 to 0.14690, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0771 - accuracy: 1.0000 - val_loss: 0.1469 - val_accuracy: 0.9667\n",
            "Epoch 537/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0765 - accuracy: 1.0000\n",
            "Epoch 537: val_loss improved from 0.14690 to 0.14626, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0765 - accuracy: 1.0000 - val_loss: 0.1463 - val_accuracy: 0.9667\n",
            "Epoch 538/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0759 - accuracy: 1.0000\n",
            "Epoch 538: val_loss improved from 0.14626 to 0.14563, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0759 - accuracy: 1.0000 - val_loss: 0.1456 - val_accuracy: 0.9667\n",
            "Epoch 539/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0753 - accuracy: 1.0000\n",
            "Epoch 539: val_loss improved from 0.14563 to 0.14502, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0753 - accuracy: 1.0000 - val_loss: 0.1450 - val_accuracy: 0.9667\n",
            "Epoch 540/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0747 - accuracy: 1.0000\n",
            "Epoch 540: val_loss improved from 0.14502 to 0.14443, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0747 - accuracy: 1.0000 - val_loss: 0.1444 - val_accuracy: 0.9667\n",
            "Epoch 541/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0741 - accuracy: 1.0000\n",
            "Epoch 541: val_loss improved from 0.14443 to 0.14383, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0741 - accuracy: 1.0000 - val_loss: 0.1438 - val_accuracy: 0.9667\n",
            "Epoch 542/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0735 - accuracy: 1.0000\n",
            "Epoch 542: val_loss improved from 0.14383 to 0.14323, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0735 - accuracy: 1.0000 - val_loss: 0.1432 - val_accuracy: 0.9667\n",
            "Epoch 543/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0729 - accuracy: 1.0000\n",
            "Epoch 543: val_loss improved from 0.14323 to 0.14261, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0729 - accuracy: 1.0000 - val_loss: 0.1426 - val_accuracy: 0.9667\n",
            "Epoch 544/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0723 - accuracy: 1.0000\n",
            "Epoch 544: val_loss improved from 0.14261 to 0.14200, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0723 - accuracy: 1.0000 - val_loss: 0.1420 - val_accuracy: 0.9667\n",
            "Epoch 545/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0718 - accuracy: 1.0000\n",
            "Epoch 545: val_loss improved from 0.14200 to 0.14139, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0718 - accuracy: 1.0000 - val_loss: 0.1414 - val_accuracy: 0.9667\n",
            "Epoch 546/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0712 - accuracy: 1.0000\n",
            "Epoch 546: val_loss improved from 0.14139 to 0.14079, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0712 - accuracy: 1.0000 - val_loss: 0.1408 - val_accuracy: 0.9667\n",
            "Epoch 547/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0706 - accuracy: 1.0000\n",
            "Epoch 547: val_loss improved from 0.14079 to 0.14020, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0706 - accuracy: 1.0000 - val_loss: 0.1402 - val_accuracy: 0.9667\n",
            "Epoch 548/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0700 - accuracy: 1.0000\n",
            "Epoch 548: val_loss improved from 0.14020 to 0.13963, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0700 - accuracy: 1.0000 - val_loss: 0.1396 - val_accuracy: 0.9667\n",
            "Epoch 549/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0695 - accuracy: 1.0000\n",
            "Epoch 549: val_loss improved from 0.13963 to 0.13906, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0695 - accuracy: 1.0000 - val_loss: 0.1391 - val_accuracy: 0.9667\n",
            "Epoch 550/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0689 - accuracy: 1.0000\n",
            "Epoch 550: val_loss improved from 0.13906 to 0.13850, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0689 - accuracy: 1.0000 - val_loss: 0.1385 - val_accuracy: 0.9667\n",
            "Epoch 551/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0683 - accuracy: 1.0000\n",
            "Epoch 551: val_loss improved from 0.13850 to 0.13794, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0683 - accuracy: 1.0000 - val_loss: 0.1379 - val_accuracy: 0.9667\n",
            "Epoch 552/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0678 - accuracy: 1.0000\n",
            "Epoch 552: val_loss improved from 0.13794 to 0.13739, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0678 - accuracy: 1.0000 - val_loss: 0.1374 - val_accuracy: 0.9667\n",
            "Epoch 553/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0672 - accuracy: 1.0000\n",
            "Epoch 553: val_loss improved from 0.13739 to 0.13684, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0672 - accuracy: 1.0000 - val_loss: 0.1368 - val_accuracy: 0.9667\n",
            "Epoch 554/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0667 - accuracy: 1.0000\n",
            "Epoch 554: val_loss improved from 0.13684 to 0.13628, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0667 - accuracy: 1.0000 - val_loss: 0.1363 - val_accuracy: 0.9667\n",
            "Epoch 555/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0661 - accuracy: 1.0000\n",
            "Epoch 555: val_loss improved from 0.13628 to 0.13571, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0661 - accuracy: 1.0000 - val_loss: 0.1357 - val_accuracy: 0.9667\n",
            "Epoch 556/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0656 - accuracy: 1.0000\n",
            "Epoch 556: val_loss improved from 0.13571 to 0.13512, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0656 - accuracy: 1.0000 - val_loss: 0.1351 - val_accuracy: 0.9667\n",
            "Epoch 557/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0651 - accuracy: 1.0000\n",
            "Epoch 557: val_loss improved from 0.13512 to 0.13454, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0651 - accuracy: 1.0000 - val_loss: 0.1345 - val_accuracy: 0.9667\n",
            "Epoch 558/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0646 - accuracy: 1.0000\n",
            "Epoch 558: val_loss improved from 0.13454 to 0.13397, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0646 - accuracy: 1.0000 - val_loss: 0.1340 - val_accuracy: 0.9667\n",
            "Epoch 559/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0640 - accuracy: 1.0000\n",
            "Epoch 559: val_loss improved from 0.13397 to 0.13343, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0640 - accuracy: 1.0000 - val_loss: 0.1334 - val_accuracy: 0.9667\n",
            "Epoch 560/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0635 - accuracy: 1.0000\n",
            "Epoch 560: val_loss improved from 0.13343 to 0.13292, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0635 - accuracy: 1.0000 - val_loss: 0.1329 - val_accuracy: 0.9667\n",
            "Epoch 561/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0630 - accuracy: 1.0000\n",
            "Epoch 561: val_loss improved from 0.13292 to 0.13243, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0630 - accuracy: 1.0000 - val_loss: 0.1324 - val_accuracy: 0.9667\n",
            "Epoch 562/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0625 - accuracy: 1.0000\n",
            "Epoch 562: val_loss improved from 0.13243 to 0.13195, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0625 - accuracy: 1.0000 - val_loss: 0.1319 - val_accuracy: 0.9667\n",
            "Epoch 563/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0620 - accuracy: 1.0000\n",
            "Epoch 563: val_loss improved from 0.13195 to 0.13147, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0620 - accuracy: 1.0000 - val_loss: 0.1315 - val_accuracy: 0.9667\n",
            "Epoch 564/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0615 - accuracy: 1.0000\n",
            "Epoch 564: val_loss improved from 0.13147 to 0.13098, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0615 - accuracy: 1.0000 - val_loss: 0.1310 - val_accuracy: 0.9667\n",
            "Epoch 565/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0610 - accuracy: 1.0000\n",
            "Epoch 565: val_loss improved from 0.13098 to 0.13046, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0610 - accuracy: 1.0000 - val_loss: 0.1305 - val_accuracy: 0.9667\n",
            "Epoch 566/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0605 - accuracy: 1.0000\n",
            "Epoch 566: val_loss improved from 0.13046 to 0.12993, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0605 - accuracy: 1.0000 - val_loss: 0.1299 - val_accuracy: 0.9667\n",
            "Epoch 567/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0600 - accuracy: 1.0000\n",
            "Epoch 567: val_loss improved from 0.12993 to 0.12938, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 0.1294 - val_accuracy: 0.9667\n",
            "Epoch 568/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0596 - accuracy: 1.0000\n",
            "Epoch 568: val_loss improved from 0.12938 to 0.12884, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0596 - accuracy: 1.0000 - val_loss: 0.1288 - val_accuracy: 0.9667\n",
            "Epoch 569/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0591 - accuracy: 1.0000\n",
            "Epoch 569: val_loss improved from 0.12884 to 0.12833, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0591 - accuracy: 1.0000 - val_loss: 0.1283 - val_accuracy: 0.9667\n",
            "Epoch 570/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0586 - accuracy: 1.0000\n",
            "Epoch 570: val_loss improved from 0.12833 to 0.12785, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0586 - accuracy: 1.0000 - val_loss: 0.1278 - val_accuracy: 0.9667\n",
            "Epoch 571/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0582 - accuracy: 1.0000\n",
            "Epoch 571: val_loss improved from 0.12785 to 0.12740, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0582 - accuracy: 1.0000 - val_loss: 0.1274 - val_accuracy: 0.9667\n",
            "Epoch 572/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 1.0000\n",
            "Epoch 572: val_loss improved from 0.12740 to 0.12697, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0577 - accuracy: 1.0000 - val_loss: 0.1270 - val_accuracy: 0.9667\n",
            "Epoch 573/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0573 - accuracy: 1.0000\n",
            "Epoch 573: val_loss improved from 0.12697 to 0.12656, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0573 - accuracy: 1.0000 - val_loss: 0.1266 - val_accuracy: 0.9667\n",
            "Epoch 574/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0568 - accuracy: 1.0000\n",
            "Epoch 574: val_loss improved from 0.12656 to 0.12614, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0568 - accuracy: 1.0000 - val_loss: 0.1261 - val_accuracy: 0.9667\n",
            "Epoch 575/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0564 - accuracy: 1.0000\n",
            "Epoch 575: val_loss improved from 0.12614 to 0.12570, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0564 - accuracy: 1.0000 - val_loss: 0.1257 - val_accuracy: 0.9667\n",
            "Epoch 576/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0559 - accuracy: 1.0000\n",
            "Epoch 576: val_loss improved from 0.12570 to 0.12524, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0559 - accuracy: 1.0000 - val_loss: 0.1252 - val_accuracy: 0.9667\n",
            "Epoch 577/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0555 - accuracy: 1.0000\n",
            "Epoch 577: val_loss improved from 0.12524 to 0.12477, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0555 - accuracy: 1.0000 - val_loss: 0.1248 - val_accuracy: 0.9667\n",
            "Epoch 578/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0551 - accuracy: 1.0000\n",
            "Epoch 578: val_loss improved from 0.12477 to 0.12430, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0551 - accuracy: 1.0000 - val_loss: 0.1243 - val_accuracy: 0.9667\n",
            "Epoch 579/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0547 - accuracy: 1.0000\n",
            "Epoch 579: val_loss improved from 0.12430 to 0.12383, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0547 - accuracy: 1.0000 - val_loss: 0.1238 - val_accuracy: 0.9667\n",
            "Epoch 580/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0542 - accuracy: 1.0000\n",
            "Epoch 580: val_loss improved from 0.12383 to 0.12339, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0542 - accuracy: 1.0000 - val_loss: 0.1234 - val_accuracy: 0.9667\n",
            "Epoch 581/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0538 - accuracy: 1.0000\n",
            "Epoch 581: val_loss improved from 0.12339 to 0.12297, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0538 - accuracy: 1.0000 - val_loss: 0.1230 - val_accuracy: 0.9667\n",
            "Epoch 582/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0534 - accuracy: 1.0000\n",
            "Epoch 582: val_loss improved from 0.12297 to 0.12258, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0534 - accuracy: 1.0000 - val_loss: 0.1226 - val_accuracy: 0.9667\n",
            "Epoch 583/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0530 - accuracy: 1.0000\n",
            "Epoch 583: val_loss improved from 0.12258 to 0.12220, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0530 - accuracy: 1.0000 - val_loss: 0.1222 - val_accuracy: 0.9667\n",
            "Epoch 584/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0526 - accuracy: 1.0000\n",
            "Epoch 584: val_loss improved from 0.12220 to 0.12180, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0526 - accuracy: 1.0000 - val_loss: 0.1218 - val_accuracy: 0.9667\n",
            "Epoch 585/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0522 - accuracy: 1.0000\n",
            "Epoch 585: val_loss improved from 0.12180 to 0.12137, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0522 - accuracy: 1.0000 - val_loss: 0.1214 - val_accuracy: 0.9667\n",
            "Epoch 586/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0519 - accuracy: 1.0000\n",
            "Epoch 586: val_loss improved from 0.12137 to 0.12093, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0519 - accuracy: 1.0000 - val_loss: 0.1209 - val_accuracy: 0.9667\n",
            "Epoch 587/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0515 - accuracy: 1.0000\n",
            "Epoch 587: val_loss improved from 0.12093 to 0.12049, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0515 - accuracy: 1.0000 - val_loss: 0.1205 - val_accuracy: 0.9667\n",
            "Epoch 588/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0511 - accuracy: 1.0000\n",
            "Epoch 588: val_loss improved from 0.12049 to 0.12007, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0511 - accuracy: 1.0000 - val_loss: 0.1201 - val_accuracy: 0.9667\n",
            "Epoch 589/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0507 - accuracy: 1.0000\n",
            "Epoch 589: val_loss improved from 0.12007 to 0.11968, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0507 - accuracy: 1.0000 - val_loss: 0.1197 - val_accuracy: 0.9667\n",
            "Epoch 590/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0504 - accuracy: 1.0000\n",
            "Epoch 590: val_loss improved from 0.11968 to 0.11932, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0504 - accuracy: 1.0000 - val_loss: 0.1193 - val_accuracy: 0.9667\n",
            "Epoch 591/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0500 - accuracy: 1.0000\n",
            "Epoch 591: val_loss improved from 0.11932 to 0.11899, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0500 - accuracy: 1.0000 - val_loss: 0.1190 - val_accuracy: 0.9667\n",
            "Epoch 592/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0496 - accuracy: 1.0000\n",
            "Epoch 592: val_loss improved from 0.11899 to 0.11866, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0496 - accuracy: 1.0000 - val_loss: 0.1187 - val_accuracy: 0.9667\n",
            "Epoch 593/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0493 - accuracy: 1.0000\n",
            "Epoch 593: val_loss improved from 0.11866 to 0.11831, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0493 - accuracy: 1.0000 - val_loss: 0.1183 - val_accuracy: 0.9667\n",
            "Epoch 594/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0489 - accuracy: 1.0000\n",
            "Epoch 594: val_loss improved from 0.11831 to 0.11793, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0489 - accuracy: 1.0000 - val_loss: 0.1179 - val_accuracy: 0.9667\n",
            "Epoch 595/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0486 - accuracy: 1.0000\n",
            "Epoch 595: val_loss improved from 0.11793 to 0.11753, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0486 - accuracy: 1.0000 - val_loss: 0.1175 - val_accuracy: 0.9667\n",
            "Epoch 596/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0482 - accuracy: 1.0000\n",
            "Epoch 596: val_loss improved from 0.11753 to 0.11713, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0482 - accuracy: 1.0000 - val_loss: 0.1171 - val_accuracy: 0.9667\n",
            "Epoch 597/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0479 - accuracy: 1.0000\n",
            "Epoch 597: val_loss improved from 0.11713 to 0.11675, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0479 - accuracy: 1.0000 - val_loss: 0.1167 - val_accuracy: 0.9667\n",
            "Epoch 598/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0475 - accuracy: 1.0000\n",
            "Epoch 598: val_loss improved from 0.11675 to 0.11639, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0475 - accuracy: 1.0000 - val_loss: 0.1164 - val_accuracy: 0.9667\n",
            "Epoch 599/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0472 - accuracy: 1.0000\n",
            "Epoch 599: val_loss improved from 0.11639 to 0.11606, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0472 - accuracy: 1.0000 - val_loss: 0.1161 - val_accuracy: 0.9667\n",
            "Epoch 600/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0469 - accuracy: 1.0000\n",
            "Epoch 600: val_loss improved from 0.11606 to 0.11576, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0469 - accuracy: 1.0000 - val_loss: 0.1158 - val_accuracy: 0.9667\n",
            "Epoch 601/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0466 - accuracy: 1.0000\n",
            "Epoch 601: val_loss improved from 0.11576 to 0.11547, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0466 - accuracy: 1.0000 - val_loss: 0.1155 - val_accuracy: 0.9667\n",
            "Epoch 602/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0462 - accuracy: 1.0000\n",
            "Epoch 602: val_loss improved from 0.11547 to 0.11518, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0462 - accuracy: 1.0000 - val_loss: 0.1152 - val_accuracy: 0.9667\n",
            "Epoch 603/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0459 - accuracy: 1.0000\n",
            "Epoch 603: val_loss improved from 0.11518 to 0.11488, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0459 - accuracy: 1.0000 - val_loss: 0.1149 - val_accuracy: 0.9667\n",
            "Epoch 604/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0456 - accuracy: 1.0000\n",
            "Epoch 604: val_loss improved from 0.11488 to 0.11455, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0456 - accuracy: 1.0000 - val_loss: 0.1146 - val_accuracy: 0.9667\n",
            "Epoch 605/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0453 - accuracy: 1.0000\n",
            "Epoch 605: val_loss improved from 0.11455 to 0.11421, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0453 - accuracy: 1.0000 - val_loss: 0.1142 - val_accuracy: 0.9667\n",
            "Epoch 606/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0450 - accuracy: 1.0000\n",
            "Epoch 606: val_loss improved from 0.11421 to 0.11387, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0450 - accuracy: 1.0000 - val_loss: 0.1139 - val_accuracy: 0.9667\n",
            "Epoch 607/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0447 - accuracy: 1.0000\n",
            "Epoch 607: val_loss improved from 0.11387 to 0.11353, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0447 - accuracy: 1.0000 - val_loss: 0.1135 - val_accuracy: 0.9667\n",
            "Epoch 608/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0444 - accuracy: 1.0000\n",
            "Epoch 608: val_loss improved from 0.11353 to 0.11321, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0444 - accuracy: 1.0000 - val_loss: 0.1132 - val_accuracy: 0.9667\n",
            "Epoch 609/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0441 - accuracy: 1.0000\n",
            "Epoch 609: val_loss improved from 0.11321 to 0.11291, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0441 - accuracy: 1.0000 - val_loss: 0.1129 - val_accuracy: 0.9667\n",
            "Epoch 610/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0438 - accuracy: 1.0000\n",
            "Epoch 610: val_loss improved from 0.11291 to 0.11263, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0438 - accuracy: 1.0000 - val_loss: 0.1126 - val_accuracy: 0.9667\n",
            "Epoch 611/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0435 - accuracy: 1.0000\n",
            "Epoch 611: val_loss improved from 0.11263 to 0.11236, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0435 - accuracy: 1.0000 - val_loss: 0.1124 - val_accuracy: 0.9667\n",
            "Epoch 612/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 1.0000\n",
            "Epoch 612: val_loss improved from 0.11236 to 0.11208, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0432 - accuracy: 1.0000 - val_loss: 0.1121 - val_accuracy: 0.9667\n",
            "Epoch 613/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0429 - accuracy: 1.0000\n",
            "Epoch 613: val_loss improved from 0.11208 to 0.11179, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 0.1118 - val_accuracy: 0.9667\n",
            "Epoch 614/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0426 - accuracy: 1.0000\n",
            "Epoch 614: val_loss improved from 0.11179 to 0.11149, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0426 - accuracy: 1.0000 - val_loss: 0.1115 - val_accuracy: 0.9667\n",
            "Epoch 615/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0423 - accuracy: 1.0000\n",
            "Epoch 615: val_loss improved from 0.11149 to 0.11116, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0423 - accuracy: 1.0000 - val_loss: 0.1112 - val_accuracy: 0.9667\n",
            "Epoch 616/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0421 - accuracy: 1.0000\n",
            "Epoch 616: val_loss improved from 0.11116 to 0.11080, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 0.1108 - val_accuracy: 0.9667\n",
            "Epoch 617/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0418 - accuracy: 1.0000\n",
            "Epoch 617: val_loss improved from 0.11080 to 0.11047, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0418 - accuracy: 1.0000 - val_loss: 0.1105 - val_accuracy: 0.9667\n",
            "Epoch 618/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0415 - accuracy: 1.0000\n",
            "Epoch 618: val_loss improved from 0.11047 to 0.11017, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0415 - accuracy: 1.0000 - val_loss: 0.1102 - val_accuracy: 0.9667\n",
            "Epoch 619/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0413 - accuracy: 1.0000\n",
            "Epoch 619: val_loss improved from 0.11017 to 0.10991, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0413 - accuracy: 1.0000 - val_loss: 0.1099 - val_accuracy: 0.9667\n",
            "Epoch 620/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0410 - accuracy: 1.0000\n",
            "Epoch 620: val_loss improved from 0.10991 to 0.10969, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 0.1097 - val_accuracy: 0.9667\n",
            "Epoch 621/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0407 - accuracy: 1.0000\n",
            "Epoch 621: val_loss improved from 0.10969 to 0.10949, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0407 - accuracy: 1.0000 - val_loss: 0.1095 - val_accuracy: 0.9667\n",
            "Epoch 622/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0405 - accuracy: 1.0000\n",
            "Epoch 622: val_loss improved from 0.10949 to 0.10929, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0405 - accuracy: 1.0000 - val_loss: 0.1093 - val_accuracy: 0.9667\n",
            "Epoch 623/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0402 - accuracy: 1.0000\n",
            "Epoch 623: val_loss improved from 0.10929 to 0.10906, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 0.1091 - val_accuracy: 0.9667\n",
            "Epoch 624/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0400 - accuracy: 1.0000\n",
            "Epoch 624: val_loss improved from 0.10906 to 0.10880, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0400 - accuracy: 1.0000 - val_loss: 0.1088 - val_accuracy: 0.9667\n",
            "Epoch 625/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0397 - accuracy: 1.0000\n",
            "Epoch 625: val_loss improved from 0.10880 to 0.10851, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.1085 - val_accuracy: 0.9667\n",
            "Epoch 626/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0395 - accuracy: 1.0000\n",
            "Epoch 626: val_loss improved from 0.10851 to 0.10822, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0395 - accuracy: 1.0000 - val_loss: 0.1082 - val_accuracy: 0.9667\n",
            "Epoch 627/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0392 - accuracy: 1.0000\n",
            "Epoch 627: val_loss improved from 0.10822 to 0.10793, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0392 - accuracy: 1.0000 - val_loss: 0.1079 - val_accuracy: 0.9667\n",
            "Epoch 628/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0390 - accuracy: 1.0000\n",
            "Epoch 628: val_loss improved from 0.10793 to 0.10766, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0390 - accuracy: 1.0000 - val_loss: 0.1077 - val_accuracy: 0.9667\n",
            "Epoch 629/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0387 - accuracy: 1.0000\n",
            "Epoch 629: val_loss improved from 0.10766 to 0.10740, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 0.1074 - val_accuracy: 0.9667\n",
            "Epoch 630/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0385 - accuracy: 1.0000\n",
            "Epoch 630: val_loss improved from 0.10740 to 0.10716, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0385 - accuracy: 1.0000 - val_loss: 0.1072 - val_accuracy: 0.9667\n",
            "Epoch 631/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 1.0000\n",
            "Epoch 631: val_loss improved from 0.10716 to 0.10692, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0383 - accuracy: 1.0000 - val_loss: 0.1069 - val_accuracy: 0.9667\n",
            "Epoch 632/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0380 - accuracy: 1.0000\n",
            "Epoch 632: val_loss improved from 0.10692 to 0.10671, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0380 - accuracy: 1.0000 - val_loss: 0.1067 - val_accuracy: 0.9667\n",
            "Epoch 633/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0378 - accuracy: 1.0000\n",
            "Epoch 633: val_loss improved from 0.10671 to 0.10650, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 0.1065 - val_accuracy: 0.9667\n",
            "Epoch 634/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0376 - accuracy: 1.0000\n",
            "Epoch 634: val_loss improved from 0.10650 to 0.10630, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0376 - accuracy: 1.0000 - val_loss: 0.1063 - val_accuracy: 0.9667\n",
            "Epoch 635/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0373 - accuracy: 1.0000\n",
            "Epoch 635: val_loss improved from 0.10630 to 0.10608, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0373 - accuracy: 1.0000 - val_loss: 0.1061 - val_accuracy: 0.9667\n",
            "Epoch 636/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0371 - accuracy: 1.0000\n",
            "Epoch 636: val_loss improved from 0.10608 to 0.10586, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0371 - accuracy: 1.0000 - val_loss: 0.1059 - val_accuracy: 0.9667\n",
            "Epoch 637/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 1.0000\n",
            "Epoch 637: val_loss improved from 0.10586 to 0.10563, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 0.1056 - val_accuracy: 0.9667\n",
            "Epoch 638/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0367 - accuracy: 1.0000\n",
            "Epoch 638: val_loss improved from 0.10563 to 0.10540, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0367 - accuracy: 1.0000 - val_loss: 0.1054 - val_accuracy: 0.9667\n",
            "Epoch 639/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0364 - accuracy: 1.0000\n",
            "Epoch 639: val_loss improved from 0.10540 to 0.10517, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0364 - accuracy: 1.0000 - val_loss: 0.1052 - val_accuracy: 0.9667\n",
            "Epoch 640/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0362 - accuracy: 1.0000\n",
            "Epoch 640: val_loss improved from 0.10517 to 0.10496, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 0.1050 - val_accuracy: 0.9667\n",
            "Epoch 641/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0360 - accuracy: 1.0000\n",
            "Epoch 641: val_loss improved from 0.10496 to 0.10475, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 0.1048 - val_accuracy: 0.9667\n",
            "Epoch 642/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 1.0000\n",
            "Epoch 642: val_loss improved from 0.10475 to 0.10455, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0358 - accuracy: 1.0000 - val_loss: 0.1046 - val_accuracy: 0.9667\n",
            "Epoch 643/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0356 - accuracy: 1.0000\n",
            "Epoch 643: val_loss improved from 0.10455 to 0.10436, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 0.1044 - val_accuracy: 0.9667\n",
            "Epoch 644/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0354 - accuracy: 1.0000\n",
            "Epoch 644: val_loss improved from 0.10436 to 0.10416, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.1042 - val_accuracy: 0.9667\n",
            "Epoch 645/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0352 - accuracy: 1.0000\n",
            "Epoch 645: val_loss improved from 0.10416 to 0.10396, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 0.1040 - val_accuracy: 0.9667\n",
            "Epoch 646/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0350 - accuracy: 1.0000\n",
            "Epoch 646: val_loss improved from 0.10396 to 0.10376, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 0.1038 - val_accuracy: 0.9667\n",
            "Epoch 647/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 1.0000\n",
            "Epoch 647: val_loss improved from 0.10376 to 0.10355, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 0.1035 - val_accuracy: 0.9667\n",
            "Epoch 648/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0346 - accuracy: 1.0000\n",
            "Epoch 648: val_loss improved from 0.10355 to 0.10333, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 0.1033 - val_accuracy: 0.9667\n",
            "Epoch 649/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0344 - accuracy: 1.0000\n",
            "Epoch 649: val_loss improved from 0.10333 to 0.10312, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 0.1031 - val_accuracy: 0.9667\n",
            "Epoch 650/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 1.0000\n",
            "Epoch 650: val_loss improved from 0.10312 to 0.10292, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0342 - accuracy: 1.0000 - val_loss: 0.1029 - val_accuracy: 0.9667\n",
            "Epoch 651/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0340 - accuracy: 1.0000\n",
            "Epoch 651: val_loss improved from 0.10292 to 0.10273, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 0.1027 - val_accuracy: 0.9667\n",
            "Epoch 652/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0338 - accuracy: 1.0000\n",
            "Epoch 652: val_loss improved from 0.10273 to 0.10255, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.1026 - val_accuracy: 0.9667\n",
            "Epoch 653/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0336 - accuracy: 1.0000\n",
            "Epoch 653: val_loss improved from 0.10255 to 0.10239, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 0.1024 - val_accuracy: 0.9667\n",
            "Epoch 654/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0334 - accuracy: 1.0000\n",
            "Epoch 654: val_loss improved from 0.10239 to 0.10222, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 0.1022 - val_accuracy: 0.9667\n",
            "Epoch 655/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0332 - accuracy: 1.0000\n",
            "Epoch 655: val_loss improved from 0.10222 to 0.10204, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 0.1020 - val_accuracy: 0.9667\n",
            "Epoch 656/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 1.0000\n",
            "Epoch 656: val_loss improved from 0.10204 to 0.10185, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.1019 - val_accuracy: 0.9667\n",
            "Epoch 657/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0329 - accuracy: 1.0000\n",
            "Epoch 657: val_loss improved from 0.10185 to 0.10166, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.1017 - val_accuracy: 0.9667\n",
            "Epoch 658/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0327 - accuracy: 1.0000\n",
            "Epoch 658: val_loss improved from 0.10166 to 0.10146, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 0.1015 - val_accuracy: 0.9667\n",
            "Epoch 659/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0325 - accuracy: 1.0000\n",
            "Epoch 659: val_loss improved from 0.10146 to 0.10127, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.1013 - val_accuracy: 0.9667\n",
            "Epoch 660/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0323 - accuracy: 1.0000\n",
            "Epoch 660: val_loss improved from 0.10127 to 0.10109, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.1011 - val_accuracy: 0.9667\n",
            "Epoch 661/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0322 - accuracy: 1.0000\n",
            "Epoch 661: val_loss improved from 0.10109 to 0.10092, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0322 - accuracy: 1.0000 - val_loss: 0.1009 - val_accuracy: 0.9667\n",
            "Epoch 662/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 1.0000\n",
            "Epoch 662: val_loss improved from 0.10092 to 0.10076, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 0.1008 - val_accuracy: 0.9667\n",
            "Epoch 663/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 1.0000\n",
            "Epoch 663: val_loss improved from 0.10076 to 0.10061, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.1006 - val_accuracy: 0.9667\n",
            "Epoch 664/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0316 - accuracy: 1.0000\n",
            "Epoch 664: val_loss improved from 0.10061 to 0.10045, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.1005 - val_accuracy: 0.9667\n",
            "Epoch 665/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0315 - accuracy: 1.0000\n",
            "Epoch 665: val_loss improved from 0.10045 to 0.10027, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.1003 - val_accuracy: 0.9667\n",
            "Epoch 666/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0313 - accuracy: 1.0000\n",
            "Epoch 666: val_loss improved from 0.10027 to 0.10007, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.1001 - val_accuracy: 0.9667\n",
            "Epoch 667/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 1.0000\n",
            "Epoch 667: val_loss improved from 0.10007 to 0.09986, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0311 - accuracy: 1.0000 - val_loss: 0.0999 - val_accuracy: 0.9667\n",
            "Epoch 668/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 1.0000\n",
            "Epoch 668: val_loss improved from 0.09986 to 0.09966, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.0997 - val_accuracy: 0.9667\n",
            "Epoch 669/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0308 - accuracy: 1.0000\n",
            "Epoch 669: val_loss improved from 0.09966 to 0.09947, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.0995 - val_accuracy: 0.9667\n",
            "Epoch 670/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0306 - accuracy: 1.0000\n",
            "Epoch 670: val_loss improved from 0.09947 to 0.09931, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.0993 - val_accuracy: 0.9667\n",
            "Epoch 671/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0305 - accuracy: 1.0000\n",
            "Epoch 671: val_loss improved from 0.09931 to 0.09918, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.0992 - val_accuracy: 0.9667\n",
            "Epoch 672/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0303 - accuracy: 1.0000\n",
            "Epoch 672: val_loss improved from 0.09918 to 0.09905, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 0.0991 - val_accuracy: 0.9667\n",
            "Epoch 673/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0302 - accuracy: 1.0000\n",
            "Epoch 673: val_loss improved from 0.09905 to 0.09893, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 0.0989 - val_accuracy: 0.9667\n",
            "Epoch 674/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0300 - accuracy: 1.0000\n",
            "Epoch 674: val_loss improved from 0.09893 to 0.09878, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.0988 - val_accuracy: 0.9667\n",
            "Epoch 675/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0298 - accuracy: 1.0000\n",
            "Epoch 675: val_loss improved from 0.09878 to 0.09860, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 0.0986 - val_accuracy: 0.9667\n",
            "Epoch 676/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0297 - accuracy: 1.0000\n",
            "Epoch 676: val_loss improved from 0.09860 to 0.09841, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.0984 - val_accuracy: 0.9667\n",
            "Epoch 677/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0295 - accuracy: 1.0000\n",
            "Epoch 677: val_loss improved from 0.09841 to 0.09822, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.0982 - val_accuracy: 0.9667\n",
            "Epoch 678/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0294 - accuracy: 1.0000\n",
            "Epoch 678: val_loss improved from 0.09822 to 0.09805, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.0981 - val_accuracy: 0.9667\n",
            "Epoch 679/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 1.0000\n",
            "Epoch 679: val_loss improved from 0.09805 to 0.09791, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.0979 - val_accuracy: 0.9667\n",
            "Epoch 680/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0291 - accuracy: 1.0000\n",
            "Epoch 680: val_loss improved from 0.09791 to 0.09779, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.0978 - val_accuracy: 0.9667\n",
            "Epoch 681/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0289 - accuracy: 1.0000\n",
            "Epoch 681: val_loss improved from 0.09779 to 0.09768, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.0977 - val_accuracy: 0.9667\n",
            "Epoch 682/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 1.0000\n",
            "Epoch 682: val_loss improved from 0.09768 to 0.09757, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.0976 - val_accuracy: 0.9667\n",
            "Epoch 683/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0286 - accuracy: 1.0000\n",
            "Epoch 683: val_loss improved from 0.09757 to 0.09744, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.0974 - val_accuracy: 0.9667\n",
            "Epoch 684/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0285 - accuracy: 1.0000\n",
            "Epoch 684: val_loss improved from 0.09744 to 0.09730, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.0973 - val_accuracy: 0.9667\n",
            "Epoch 685/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0283 - accuracy: 1.0000\n",
            "Epoch 685: val_loss improved from 0.09730 to 0.09714, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.0971 - val_accuracy: 0.9667\n",
            "Epoch 686/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0282 - accuracy: 1.0000\n",
            "Epoch 686: val_loss improved from 0.09714 to 0.09697, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.0970 - val_accuracy: 0.9667\n",
            "Epoch 687/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0281 - accuracy: 1.0000\n",
            "Epoch 687: val_loss improved from 0.09697 to 0.09681, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.0968 - val_accuracy: 0.9667\n",
            "Epoch 688/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0279 - accuracy: 1.0000\n",
            "Epoch 688: val_loss improved from 0.09681 to 0.09666, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0279 - accuracy: 1.0000 - val_loss: 0.0967 - val_accuracy: 0.9667\n",
            "Epoch 689/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0278 - accuracy: 1.0000\n",
            "Epoch 689: val_loss improved from 0.09666 to 0.09653, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 0.0965 - val_accuracy: 0.9667\n",
            "Epoch 690/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0276 - accuracy: 1.0000\n",
            "Epoch 690: val_loss improved from 0.09653 to 0.09640, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 0.0964 - val_accuracy: 0.9667\n",
            "Epoch 691/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0275 - accuracy: 1.0000\n",
            "Epoch 691: val_loss improved from 0.09640 to 0.09628, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.0963 - val_accuracy: 0.9667\n",
            "Epoch 692/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0274 - accuracy: 1.0000\n",
            "Epoch 692: val_loss improved from 0.09628 to 0.09616, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 0.0962 - val_accuracy: 0.9667\n",
            "Epoch 693/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 1.0000\n",
            "Epoch 693: val_loss improved from 0.09616 to 0.09604, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 0.0960 - val_accuracy: 0.9667\n",
            "Epoch 694/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0271 - accuracy: 1.0000\n",
            "Epoch 694: val_loss improved from 0.09604 to 0.09591, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 0.0959 - val_accuracy: 0.9667\n",
            "Epoch 695/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0270 - accuracy: 1.0000\n",
            "Epoch 695: val_loss improved from 0.09591 to 0.09578, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.0958 - val_accuracy: 0.9667\n",
            "Epoch 696/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 1.0000\n",
            "Epoch 696: val_loss improved from 0.09578 to 0.09565, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 0.0957 - val_accuracy: 0.9667\n",
            "Epoch 697/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0267 - accuracy: 1.0000\n",
            "Epoch 697: val_loss improved from 0.09565 to 0.09552, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 0.0955 - val_accuracy: 0.9667\n",
            "Epoch 698/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0266 - accuracy: 1.0000\n",
            "Epoch 698: val_loss improved from 0.09552 to 0.09539, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 0.0954 - val_accuracy: 0.9667\n",
            "Epoch 699/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0265 - accuracy: 1.0000\n",
            "Epoch 699: val_loss improved from 0.09539 to 0.09527, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.0953 - val_accuracy: 0.9667\n",
            "Epoch 700/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 1.0000\n",
            "Epoch 700: val_loss improved from 0.09527 to 0.09515, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 0.0952 - val_accuracy: 0.9667\n",
            "Epoch 701/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0262 - accuracy: 1.0000\n",
            "Epoch 701: val_loss improved from 0.09515 to 0.09504, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 0.0950 - val_accuracy: 0.9667\n",
            "Epoch 702/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0261 - accuracy: 1.0000\n",
            "Epoch 702: val_loss improved from 0.09504 to 0.09493, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 0.0949 - val_accuracy: 0.9667\n",
            "Epoch 703/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 1.0000\n",
            "Epoch 703: val_loss improved from 0.09493 to 0.09481, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 0.0948 - val_accuracy: 0.9667\n",
            "Epoch 704/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0258 - accuracy: 1.0000\n",
            "Epoch 704: val_loss improved from 0.09481 to 0.09469, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 0.0947 - val_accuracy: 0.9667\n",
            "Epoch 705/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 1.0000\n",
            "Epoch 705: val_loss improved from 0.09469 to 0.09458, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.0946 - val_accuracy: 0.9667\n",
            "Epoch 706/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 1.0000\n",
            "Epoch 706: val_loss improved from 0.09458 to 0.09446, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 0.0945 - val_accuracy: 0.9667\n",
            "Epoch 707/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0255 - accuracy: 1.0000\n",
            "Epoch 707: val_loss improved from 0.09446 to 0.09433, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.0943 - val_accuracy: 0.9667\n",
            "Epoch 708/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0253 - accuracy: 1.0000\n",
            "Epoch 708: val_loss improved from 0.09433 to 0.09419, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 0.0942 - val_accuracy: 0.9667\n",
            "Epoch 709/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0252 - accuracy: 1.0000\n",
            "Epoch 709: val_loss improved from 0.09419 to 0.09407, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 0.0941 - val_accuracy: 0.9667\n",
            "Epoch 710/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0251 - accuracy: 1.0000\n",
            "Epoch 710: val_loss improved from 0.09407 to 0.09395, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.0940 - val_accuracy: 0.9667\n",
            "Epoch 711/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0250 - accuracy: 1.0000\n",
            "Epoch 711: val_loss improved from 0.09395 to 0.09385, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 0.0938 - val_accuracy: 0.9667\n",
            "Epoch 712/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 1.0000\n",
            "Epoch 712: val_loss improved from 0.09385 to 0.09376, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 0.0938 - val_accuracy: 0.9667\n",
            "Epoch 713/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 1.0000\n",
            "Epoch 713: val_loss improved from 0.09376 to 0.09364, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 0.0936 - val_accuracy: 0.9667\n",
            "Epoch 714/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 1.0000\n",
            "Epoch 714: val_loss improved from 0.09364 to 0.09352, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 0.0935 - val_accuracy: 0.9667\n",
            "Epoch 715/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 1.0000\n",
            "Epoch 715: val_loss improved from 0.09352 to 0.09339, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 0.0934 - val_accuracy: 0.9667\n",
            "Epoch 716/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0244 - accuracy: 1.0000\n",
            "Epoch 716: val_loss improved from 0.09339 to 0.09326, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 0.0933 - val_accuracy: 0.9667\n",
            "Epoch 717/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 1.0000\n",
            "Epoch 717: val_loss improved from 0.09326 to 0.09314, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.0931 - val_accuracy: 0.9667\n",
            "Epoch 718/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0242 - accuracy: 1.0000\n",
            "Epoch 718: val_loss improved from 0.09314 to 0.09304, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 0.0930 - val_accuracy: 0.9667\n",
            "Epoch 719/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0241 - accuracy: 1.0000\n",
            "Epoch 719: val_loss improved from 0.09304 to 0.09295, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.0929 - val_accuracy: 0.9667\n",
            "Epoch 720/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 1.0000\n",
            "Epoch 720: val_loss improved from 0.09295 to 0.09287, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 0.0929 - val_accuracy: 0.9667\n",
            "Epoch 721/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 1.0000\n",
            "Epoch 721: val_loss improved from 0.09287 to 0.09279, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.0928 - val_accuracy: 0.9667\n",
            "Epoch 722/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 1.0000\n",
            "Epoch 722: val_loss improved from 0.09279 to 0.09270, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.0927 - val_accuracy: 0.9667\n",
            "Epoch 723/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 1.0000\n",
            "Epoch 723: val_loss improved from 0.09270 to 0.09261, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.0926 - val_accuracy: 0.9667\n",
            "Epoch 724/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 1.0000\n",
            "Epoch 724: val_loss improved from 0.09261 to 0.09250, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.0925 - val_accuracy: 0.9667\n",
            "Epoch 725/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 1.0000\n",
            "Epoch 725: val_loss improved from 0.09250 to 0.09239, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.0924 - val_accuracy: 0.9667\n",
            "Epoch 726/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0233 - accuracy: 1.0000\n",
            "Epoch 726: val_loss improved from 0.09239 to 0.09228, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0233 - accuracy: 1.0000 - val_loss: 0.0923 - val_accuracy: 0.9667\n",
            "Epoch 727/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0232 - accuracy: 1.0000\n",
            "Epoch 727: val_loss improved from 0.09228 to 0.09217, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 0.0922 - val_accuracy: 0.9667\n",
            "Epoch 728/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0231 - accuracy: 1.0000\n",
            "Epoch 728: val_loss improved from 0.09217 to 0.09206, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.0921 - val_accuracy: 0.9667\n",
            "Epoch 729/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 1.0000\n",
            "Epoch 729: val_loss improved from 0.09206 to 0.09195, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 0.0919 - val_accuracy: 0.9667\n",
            "Epoch 730/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0229 - accuracy: 1.0000\n",
            "Epoch 730: val_loss improved from 0.09195 to 0.09185, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.0918 - val_accuracy: 0.9667\n",
            "Epoch 731/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 1.0000\n",
            "Epoch 731: val_loss improved from 0.09185 to 0.09176, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 0.0918 - val_accuracy: 0.9667\n",
            "Epoch 732/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0227 - accuracy: 1.0000\n",
            "Epoch 732: val_loss improved from 0.09176 to 0.09168, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.0917 - val_accuracy: 0.9667\n",
            "Epoch 733/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0226 - accuracy: 1.0000\n",
            "Epoch 733: val_loss improved from 0.09168 to 0.09161, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.0916 - val_accuracy: 0.9667\n",
            "Epoch 734/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 1.0000\n",
            "Epoch 734: val_loss improved from 0.09161 to 0.09154, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 0.0915 - val_accuracy: 0.9667\n",
            "Epoch 735/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0224 - accuracy: 1.0000\n",
            "Epoch 735: val_loss improved from 0.09154 to 0.09146, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.0915 - val_accuracy: 0.9667\n",
            "Epoch 736/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0223 - accuracy: 1.0000\n",
            "Epoch 736: val_loss improved from 0.09146 to 0.09137, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.0914 - val_accuracy: 0.9667\n",
            "Epoch 737/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 1.0000\n",
            "Epoch 737: val_loss improved from 0.09137 to 0.09128, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 0.0913 - val_accuracy: 0.9667\n",
            "Epoch 738/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0221 - accuracy: 1.0000\n",
            "Epoch 738: val_loss improved from 0.09128 to 0.09118, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.0912 - val_accuracy: 0.9667\n",
            "Epoch 739/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 1.0000\n",
            "Epoch 739: val_loss improved from 0.09118 to 0.09109, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.0911 - val_accuracy: 0.9667\n",
            "Epoch 740/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0219 - accuracy: 1.0000\n",
            "Epoch 740: val_loss improved from 0.09109 to 0.09100, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.0910 - val_accuracy: 0.9667\n",
            "Epoch 741/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 1.0000\n",
            "Epoch 741: val_loss improved from 0.09100 to 0.09092, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.0909 - val_accuracy: 0.9667\n",
            "Epoch 742/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0217 - accuracy: 1.0000\n",
            "Epoch 742: val_loss improved from 0.09092 to 0.09085, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.0908 - val_accuracy: 0.9667\n",
            "Epoch 743/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 1.0000\n",
            "Epoch 743: val_loss improved from 0.09085 to 0.09078, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.0908 - val_accuracy: 0.9667\n",
            "Epoch 744/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0215 - accuracy: 1.0000\n",
            "Epoch 744: val_loss improved from 0.09078 to 0.09071, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.0907 - val_accuracy: 0.9667\n",
            "Epoch 745/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 1.0000\n",
            "Epoch 745: val_loss improved from 0.09071 to 0.09063, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.0906 - val_accuracy: 0.9667\n",
            "Epoch 746/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 1.0000\n",
            "Epoch 746: val_loss improved from 0.09063 to 0.09055, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.0906 - val_accuracy: 0.9667\n",
            "Epoch 747/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 1.0000\n",
            "Epoch 747: val_loss improved from 0.09055 to 0.09047, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.0905 - val_accuracy: 0.9667\n",
            "Epoch 748/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0212 - accuracy: 1.0000\n",
            "Epoch 748: val_loss improved from 0.09047 to 0.09039, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.0904 - val_accuracy: 0.9667\n",
            "Epoch 749/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 1.0000\n",
            "Epoch 749: val_loss improved from 0.09039 to 0.09030, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.0903 - val_accuracy: 0.9667\n",
            "Epoch 750/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 1.0000\n",
            "Epoch 750: val_loss improved from 0.09030 to 0.09023, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.0902 - val_accuracy: 0.9667\n",
            "Epoch 751/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 1.0000\n",
            "Epoch 751: val_loss improved from 0.09023 to 0.09015, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.0902 - val_accuracy: 0.9667\n",
            "Epoch 752/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 1.0000\n",
            "Epoch 752: val_loss improved from 0.09015 to 0.09009, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.0901 - val_accuracy: 0.9667\n",
            "Epoch 753/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0207 - accuracy: 1.0000\n",
            "Epoch 753: val_loss improved from 0.09009 to 0.09002, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 0.0900 - val_accuracy: 0.9667\n",
            "Epoch 754/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0206 - accuracy: 1.0000\n",
            "Epoch 754: val_loss improved from 0.09002 to 0.08995, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.0900 - val_accuracy: 0.9667\n",
            "Epoch 755/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0205 - accuracy: 1.0000\n",
            "Epoch 755: val_loss improved from 0.08995 to 0.08988, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.0899 - val_accuracy: 0.9667\n",
            "Epoch 756/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0205 - accuracy: 1.0000\n",
            "Epoch 756: val_loss improved from 0.08988 to 0.08981, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.0898 - val_accuracy: 0.9667\n",
            "Epoch 757/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 1.0000\n",
            "Epoch 757: val_loss improved from 0.08981 to 0.08974, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.0897 - val_accuracy: 0.9667\n",
            "Epoch 758/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 1.0000\n",
            "Epoch 758: val_loss improved from 0.08974 to 0.08966, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.0897 - val_accuracy: 0.9667\n",
            "Epoch 759/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 1.0000\n",
            "Epoch 759: val_loss improved from 0.08966 to 0.08959, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.0896 - val_accuracy: 0.9667\n",
            "Epoch 760/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 1.0000\n",
            "Epoch 760: val_loss improved from 0.08959 to 0.08952, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.0895 - val_accuracy: 0.9667\n",
            "Epoch 761/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 1.0000\n",
            "Epoch 761: val_loss improved from 0.08952 to 0.08945, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.0895 - val_accuracy: 0.9667\n",
            "Epoch 762/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 1.0000\n",
            "Epoch 762: val_loss improved from 0.08945 to 0.08939, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.0894 - val_accuracy: 0.9667\n",
            "Epoch 763/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 1.0000\n",
            "Epoch 763: val_loss improved from 0.08939 to 0.08933, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.0893 - val_accuracy: 0.9667\n",
            "Epoch 764/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0198 - accuracy: 1.0000\n",
            "Epoch 764: val_loss improved from 0.08933 to 0.08927, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.0893 - val_accuracy: 0.9667\n",
            "Epoch 765/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 1.0000\n",
            "Epoch 765: val_loss improved from 0.08927 to 0.08920, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.0892 - val_accuracy: 0.9667\n",
            "Epoch 766/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 1.0000\n",
            "Epoch 766: val_loss improved from 0.08920 to 0.08914, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.0891 - val_accuracy: 0.9667\n",
            "Epoch 767/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 1.0000\n",
            "Epoch 767: val_loss improved from 0.08914 to 0.08907, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.0891 - val_accuracy: 0.9667\n",
            "Epoch 768/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 1.0000\n",
            "Epoch 768: val_loss improved from 0.08907 to 0.08901, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.0890 - val_accuracy: 0.9667\n",
            "Epoch 769/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 1.0000\n",
            "Epoch 769: val_loss improved from 0.08901 to 0.08894, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.0889 - val_accuracy: 0.9667\n",
            "Epoch 770/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0193 - accuracy: 1.0000\n",
            "Epoch 770: val_loss improved from 0.08894 to 0.08888, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.0889 - val_accuracy: 0.9667\n",
            "Epoch 771/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0192 - accuracy: 1.0000\n",
            "Epoch 771: val_loss improved from 0.08888 to 0.08882, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.0888 - val_accuracy: 0.9667\n",
            "Epoch 772/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0191 - accuracy: 1.0000\n",
            "Epoch 772: val_loss improved from 0.08882 to 0.08876, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.0888 - val_accuracy: 0.9667\n",
            "Epoch 773/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0191 - accuracy: 1.0000\n",
            "Epoch 773: val_loss improved from 0.08876 to 0.08871, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9667\n",
            "Epoch 774/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 1.0000\n",
            "Epoch 774: val_loss improved from 0.08871 to 0.08865, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.0886 - val_accuracy: 0.9667\n",
            "Epoch 775/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 1.0000\n",
            "Epoch 775: val_loss improved from 0.08865 to 0.08859, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.0886 - val_accuracy: 0.9667\n",
            "Epoch 776/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 1.0000\n",
            "Epoch 776: val_loss improved from 0.08859 to 0.08853, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.0885 - val_accuracy: 0.9667\n",
            "Epoch 777/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 1.0000\n",
            "Epoch 777: val_loss improved from 0.08853 to 0.08847, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.0885 - val_accuracy: 0.9667\n",
            "Epoch 778/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 1.0000\n",
            "Epoch 778: val_loss improved from 0.08847 to 0.08842, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.0884 - val_accuracy: 0.9667\n",
            "Epoch 779/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 1.0000\n",
            "Epoch 779: val_loss improved from 0.08842 to 0.08836, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.0884 - val_accuracy: 0.9667\n",
            "Epoch 780/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 1.0000\n",
            "Epoch 780: val_loss improved from 0.08836 to 0.08830, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.0883 - val_accuracy: 0.9667\n",
            "Epoch 781/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 1.0000\n",
            "Epoch 781: val_loss improved from 0.08830 to 0.08822, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.0882 - val_accuracy: 0.9667\n",
            "Epoch 782/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 1.0000\n",
            "Epoch 782: val_loss improved from 0.08822 to 0.08813, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.0881 - val_accuracy: 0.9667\n",
            "Epoch 783/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 1.0000\n",
            "Epoch 783: val_loss improved from 0.08813 to 0.08804, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 0.9667\n",
            "Epoch 784/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 1.0000\n",
            "Epoch 784: val_loss improved from 0.08804 to 0.08797, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 0.9333\n",
            "Epoch 785/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 1.0000\n",
            "Epoch 785: val_loss improved from 0.08797 to 0.08792, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.0879 - val_accuracy: 0.9333\n",
            "Epoch 786/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 1.0000\n",
            "Epoch 786: val_loss improved from 0.08792 to 0.08789, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.0879 - val_accuracy: 0.9333\n",
            "Epoch 787/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 1.0000\n",
            "Epoch 787: val_loss improved from 0.08789 to 0.08787, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.0879 - val_accuracy: 0.9333\n",
            "Epoch 788/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 1.0000\n",
            "Epoch 788: val_loss improved from 0.08787 to 0.08784, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.0878 - val_accuracy: 0.9333\n",
            "Epoch 789/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 1.0000\n",
            "Epoch 789: val_loss improved from 0.08784 to 0.08781, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.0878 - val_accuracy: 0.9333\n",
            "Epoch 790/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 1.0000\n",
            "Epoch 790: val_loss improved from 0.08781 to 0.08776, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.0878 - val_accuracy: 0.9333\n",
            "Epoch 791/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 1.0000\n",
            "Epoch 791: val_loss improved from 0.08776 to 0.08769, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.0877 - val_accuracy: 0.9333\n",
            "Epoch 792/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 1.0000\n",
            "Epoch 792: val_loss improved from 0.08769 to 0.08762, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.0876 - val_accuracy: 0.9333\n",
            "Epoch 793/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 1.0000\n",
            "Epoch 793: val_loss improved from 0.08762 to 0.08755, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.0876 - val_accuracy: 0.9333\n",
            "Epoch 794/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 1.0000\n",
            "Epoch 794: val_loss improved from 0.08755 to 0.08750, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.0875 - val_accuracy: 0.9333\n",
            "Epoch 795/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 1.0000\n",
            "Epoch 795: val_loss improved from 0.08750 to 0.08746, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.0875 - val_accuracy: 0.9333\n",
            "Epoch 796/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 1.0000\n",
            "Epoch 796: val_loss improved from 0.08746 to 0.08743, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.0874 - val_accuracy: 0.9333\n",
            "Epoch 797/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 1.0000\n",
            "Epoch 797: val_loss improved from 0.08743 to 0.08740, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.0874 - val_accuracy: 0.9333\n",
            "Epoch 798/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 1.0000\n",
            "Epoch 798: val_loss improved from 0.08740 to 0.08737, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.0874 - val_accuracy: 0.9333\n",
            "Epoch 799/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 1.0000\n",
            "Epoch 799: val_loss improved from 0.08737 to 0.08733, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.0873 - val_accuracy: 0.9333\n",
            "Epoch 800/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 1.0000\n",
            "Epoch 800: val_loss improved from 0.08733 to 0.08728, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.0873 - val_accuracy: 0.9333\n",
            "Epoch 801/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 1.0000\n",
            "Epoch 801: val_loss improved from 0.08728 to 0.08722, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.0872 - val_accuracy: 0.9333\n",
            "Epoch 802/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 1.0000\n",
            "Epoch 802: val_loss improved from 0.08722 to 0.08717, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.0872 - val_accuracy: 0.9333\n",
            "Epoch 803/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 1.0000\n",
            "Epoch 803: val_loss improved from 0.08717 to 0.08712, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.0871 - val_accuracy: 0.9333\n",
            "Epoch 804/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 1.0000\n",
            "Epoch 804: val_loss improved from 0.08712 to 0.08707, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.0871 - val_accuracy: 0.9333\n",
            "Epoch 805/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 1.0000\n",
            "Epoch 805: val_loss improved from 0.08707 to 0.08704, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.0870 - val_accuracy: 0.9333\n",
            "Epoch 806/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 1.0000\n",
            "Epoch 806: val_loss improved from 0.08704 to 0.08701, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.0870 - val_accuracy: 0.9333\n",
            "Epoch 807/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 1.0000\n",
            "Epoch 807: val_loss improved from 0.08701 to 0.08698, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.0870 - val_accuracy: 0.9333\n",
            "Epoch 808/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 1.0000\n",
            "Epoch 808: val_loss improved from 0.08698 to 0.08695, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.0869 - val_accuracy: 0.9333\n",
            "Epoch 809/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 1.0000\n",
            "Epoch 809: val_loss improved from 0.08695 to 0.08691, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.0869 - val_accuracy: 0.9333\n",
            "Epoch 810/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 1.0000\n",
            "Epoch 810: val_loss improved from 0.08691 to 0.08687, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.0869 - val_accuracy: 0.9333\n",
            "Epoch 811/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 1.0000\n",
            "Epoch 811: val_loss improved from 0.08687 to 0.08683, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.0868 - val_accuracy: 0.9333\n",
            "Epoch 812/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 1.0000\n",
            "Epoch 812: val_loss improved from 0.08683 to 0.08678, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.0868 - val_accuracy: 0.9333\n",
            "Epoch 813/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 1.0000\n",
            "Epoch 813: val_loss improved from 0.08678 to 0.08674, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.0867 - val_accuracy: 0.9333\n",
            "Epoch 814/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0162 - accuracy: 1.0000\n",
            "Epoch 814: val_loss improved from 0.08674 to 0.08670, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.0867 - val_accuracy: 0.9333\n",
            "Epoch 815/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 1.0000\n",
            "Epoch 815: val_loss improved from 0.08670 to 0.08666, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.0867 - val_accuracy: 0.9333\n",
            "Epoch 816/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 1.0000\n",
            "Epoch 816: val_loss improved from 0.08666 to 0.08662, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.0866 - val_accuracy: 0.9333\n",
            "Epoch 817/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 1.0000\n",
            "Epoch 817: val_loss improved from 0.08662 to 0.08659, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.0866 - val_accuracy: 0.9333\n",
            "Epoch 818/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 1.0000\n",
            "Epoch 818: val_loss improved from 0.08659 to 0.08656, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.0866 - val_accuracy: 0.9333\n",
            "Epoch 819/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 1.0000\n",
            "Epoch 819: val_loss improved from 0.08656 to 0.08653, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.0865 - val_accuracy: 0.9333\n",
            "Epoch 820/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 1.0000\n",
            "Epoch 820: val_loss improved from 0.08653 to 0.08650, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.0865 - val_accuracy: 0.9333\n",
            "Epoch 821/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 1.0000\n",
            "Epoch 821: val_loss improved from 0.08650 to 0.08647, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.0865 - val_accuracy: 0.9333\n",
            "Epoch 822/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 1.0000\n",
            "Epoch 822: val_loss improved from 0.08647 to 0.08643, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.0864 - val_accuracy: 0.9333\n",
            "Epoch 823/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 1.0000\n",
            "Epoch 823: val_loss improved from 0.08643 to 0.08640, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.0864 - val_accuracy: 0.9333\n",
            "Epoch 824/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 1.0000\n",
            "Epoch 824: val_loss improved from 0.08640 to 0.08636, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.0864 - val_accuracy: 0.9333\n",
            "Epoch 825/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 1.0000\n",
            "Epoch 825: val_loss improved from 0.08636 to 0.08633, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.0863 - val_accuracy: 0.9333\n",
            "Epoch 826/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 1.0000\n",
            "Epoch 826: val_loss improved from 0.08633 to 0.08630, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.0863 - val_accuracy: 0.9333\n",
            "Epoch 827/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 1.0000\n",
            "Epoch 827: val_loss improved from 0.08630 to 0.08627, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.0863 - val_accuracy: 0.9333\n",
            "Epoch 828/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 1.0000\n",
            "Epoch 828: val_loss improved from 0.08627 to 0.08624, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.0862 - val_accuracy: 0.9333\n",
            "Epoch 829/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 1.0000\n",
            "Epoch 829: val_loss improved from 0.08624 to 0.08622, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.0862 - val_accuracy: 0.9333\n",
            "Epoch 830/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 1.0000\n",
            "Epoch 830: val_loss improved from 0.08622 to 0.08619, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.0862 - val_accuracy: 0.9333\n",
            "Epoch 831/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 1.0000\n",
            "Epoch 831: val_loss improved from 0.08619 to 0.08617, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.0862 - val_accuracy: 0.9333\n",
            "Epoch 832/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 1.0000\n",
            "Epoch 832: val_loss improved from 0.08617 to 0.08614, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.0861 - val_accuracy: 0.9333\n",
            "Epoch 833/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 1.0000\n",
            "Epoch 833: val_loss improved from 0.08614 to 0.08611, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.0861 - val_accuracy: 0.9333\n",
            "Epoch 834/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 1.0000\n",
            "Epoch 834: val_loss improved from 0.08611 to 0.08608, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.0861 - val_accuracy: 0.9333\n",
            "Epoch 835/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 1.0000\n",
            "Epoch 835: val_loss improved from 0.08608 to 0.08605, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.0861 - val_accuracy: 0.9333\n",
            "Epoch 836/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 1.0000\n",
            "Epoch 836: val_loss improved from 0.08605 to 0.08603, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.0860 - val_accuracy: 0.9333\n",
            "Epoch 837/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 1.0000\n",
            "Epoch 837: val_loss improved from 0.08603 to 0.08600, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.0860 - val_accuracy: 0.9333\n",
            "Epoch 838/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 1.0000\n",
            "Epoch 838: val_loss improved from 0.08600 to 0.08598, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.0860 - val_accuracy: 0.9333\n",
            "Epoch 839/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 1.0000\n",
            "Epoch 839: val_loss improved from 0.08598 to 0.08595, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.0860 - val_accuracy: 0.9333\n",
            "Epoch 840/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 1.0000\n",
            "Epoch 840: val_loss improved from 0.08595 to 0.08593, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 0.9333\n",
            "Epoch 841/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0146 - accuracy: 1.0000\n",
            "Epoch 841: val_loss improved from 0.08593 to 0.08591, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 0.9333\n",
            "Epoch 842/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0146 - accuracy: 1.0000\n",
            "Epoch 842: val_loss improved from 0.08591 to 0.08588, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 0.9333\n",
            "Epoch 843/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0145 - accuracy: 1.0000\n",
            "Epoch 843: val_loss improved from 0.08588 to 0.08586, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 0.9333\n",
            "Epoch 844/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0145 - accuracy: 1.0000\n",
            "Epoch 844: val_loss improved from 0.08586 to 0.08584, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.0858 - val_accuracy: 0.9333\n",
            "Epoch 845/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 1.0000\n",
            "Epoch 845: val_loss improved from 0.08584 to 0.08582, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.0858 - val_accuracy: 0.9333\n",
            "Epoch 846/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 1.0000\n",
            "Epoch 846: val_loss improved from 0.08582 to 0.08579, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.0858 - val_accuracy: 0.9333\n",
            "Epoch 847/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 1.0000\n",
            "Epoch 847: val_loss improved from 0.08579 to 0.08577, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.0858 - val_accuracy: 0.9333\n",
            "Epoch 848/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 1.0000\n",
            "Epoch 848: val_loss improved from 0.08577 to 0.08575, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.0857 - val_accuracy: 0.9333\n",
            "Epoch 849/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 1.0000\n",
            "Epoch 849: val_loss improved from 0.08575 to 0.08573, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.0857 - val_accuracy: 0.9333\n",
            "Epoch 850/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 1.0000\n",
            "Epoch 850: val_loss improved from 0.08573 to 0.08571, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.0857 - val_accuracy: 0.9333\n",
            "Epoch 851/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 1.0000\n",
            "Epoch 851: val_loss improved from 0.08571 to 0.08569, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.0857 - val_accuracy: 0.9333\n",
            "Epoch 852/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 1.0000\n",
            "Epoch 852: val_loss improved from 0.08569 to 0.08568, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.0857 - val_accuracy: 0.9333\n",
            "Epoch 853/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 1.0000\n",
            "Epoch 853: val_loss improved from 0.08568 to 0.08566, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.0857 - val_accuracy: 0.9333\n",
            "Epoch 854/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 1.0000\n",
            "Epoch 854: val_loss improved from 0.08566 to 0.08564, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.0856 - val_accuracy: 0.9333\n",
            "Epoch 855/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 1.0000\n",
            "Epoch 855: val_loss improved from 0.08564 to 0.08562, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.0856 - val_accuracy: 0.9333\n",
            "Epoch 856/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 1.0000\n",
            "Epoch 856: val_loss improved from 0.08562 to 0.08560, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.0856 - val_accuracy: 0.9333\n",
            "Epoch 857/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 1.0000\n",
            "Epoch 857: val_loss improved from 0.08560 to 0.08559, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.0856 - val_accuracy: 0.9333\n",
            "Epoch 858/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 1.0000\n",
            "Epoch 858: val_loss improved from 0.08559 to 0.08557, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.0856 - val_accuracy: 0.9333\n",
            "Epoch 859/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 1.0000\n",
            "Epoch 859: val_loss improved from 0.08557 to 0.08555, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.0856 - val_accuracy: 0.9333\n",
            "Epoch 860/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 1.0000\n",
            "Epoch 860: val_loss improved from 0.08555 to 0.08553, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.0855 - val_accuracy: 0.9333\n",
            "Epoch 861/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 1.0000\n",
            "Epoch 861: val_loss improved from 0.08553 to 0.08552, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.0855 - val_accuracy: 0.9333\n",
            "Epoch 862/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 1.0000\n",
            "Epoch 862: val_loss improved from 0.08552 to 0.08551, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.0855 - val_accuracy: 0.9333\n",
            "Epoch 863/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 1.0000\n",
            "Epoch 863: val_loss improved from 0.08551 to 0.08549, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.0855 - val_accuracy: 0.9333\n",
            "Epoch 864/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 1.0000\n",
            "Epoch 864: val_loss improved from 0.08549 to 0.08548, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.0855 - val_accuracy: 0.9333\n",
            "Epoch 865/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 1.0000\n",
            "Epoch 865: val_loss improved from 0.08548 to 0.08547, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.0855 - val_accuracy: 0.9333\n",
            "Epoch 866/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 1.0000\n",
            "Epoch 866: val_loss improved from 0.08547 to 0.08545, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.0855 - val_accuracy: 0.9333\n",
            "Epoch 867/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 1.0000\n",
            "Epoch 867: val_loss improved from 0.08545 to 0.08544, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.0854 - val_accuracy: 0.9333\n",
            "Epoch 868/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 1.0000\n",
            "Epoch 868: val_loss improved from 0.08544 to 0.08542, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.0854 - val_accuracy: 0.9333\n",
            "Epoch 869/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0132 - accuracy: 1.0000\n",
            "Epoch 869: val_loss improved from 0.08542 to 0.08539, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.0854 - val_accuracy: 0.9333\n",
            "Epoch 870/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0132 - accuracy: 1.0000\n",
            "Epoch 870: val_loss improved from 0.08539 to 0.08535, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.0854 - val_accuracy: 0.9333\n",
            "Epoch 871/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 1.0000\n",
            "Epoch 871: val_loss improved from 0.08535 to 0.08531, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.0853 - val_accuracy: 0.9333\n",
            "Epoch 872/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 1.0000\n",
            "Epoch 872: val_loss improved from 0.08531 to 0.08528, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.0853 - val_accuracy: 0.9333\n",
            "Epoch 873/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 1.0000\n",
            "Epoch 873: val_loss improved from 0.08528 to 0.08528, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.0853 - val_accuracy: 0.9333\n",
            "Epoch 874/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 1.0000\n",
            "Epoch 874: val_loss did not improve from 0.08528\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.0853 - val_accuracy: 0.9333\n",
            "Epoch 875/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 1.0000\n",
            "Epoch 875: val_loss did not improve from 0.08528\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.0853 - val_accuracy: 0.9333\n",
            "Epoch 876/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 1.0000\n",
            "Epoch 876: val_loss did not improve from 0.08528\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.0853 - val_accuracy: 0.9333\n",
            "Epoch 877/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 1.0000\n",
            "Epoch 877: val_loss did not improve from 0.08528\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.0853 - val_accuracy: 0.9333\n",
            "Epoch 878/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 1.0000\n",
            "Epoch 878: val_loss did not improve from 0.08528\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.0853 - val_accuracy: 0.9333\n",
            "Epoch 879/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 1.0000\n",
            "Epoch 879: val_loss did not improve from 0.08528\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.0853 - val_accuracy: 0.9333\n",
            "Epoch 880/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 1.0000\n",
            "Epoch 880: val_loss improved from 0.08528 to 0.08526, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.0853 - val_accuracy: 0.9333\n",
            "Epoch 881/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 1.0000\n",
            "Epoch 881: val_loss improved from 0.08526 to 0.08523, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9333\n",
            "Epoch 882/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 1.0000\n",
            "Epoch 882: val_loss improved from 0.08523 to 0.08522, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9333\n",
            "Epoch 883/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 1.0000\n",
            "Epoch 883: val_loss improved from 0.08522 to 0.08522, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9333\n",
            "Epoch 884/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 1.0000\n",
            "Epoch 884: val_loss did not improve from 0.08522\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9333\n",
            "Epoch 885/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 1.0000\n",
            "Epoch 885: val_loss did not improve from 0.08522\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9333\n",
            "Epoch 886/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 1.0000\n",
            "Epoch 886: val_loss did not improve from 0.08522\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9333\n",
            "Epoch 887/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 1.0000\n",
            "Epoch 887: val_loss did not improve from 0.08522\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9333\n",
            "Epoch 888/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 1.0000\n",
            "Epoch 888: val_loss did not improve from 0.08522\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9333\n",
            "Epoch 889/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 1.0000\n",
            "Epoch 889: val_loss improved from 0.08522 to 0.08521, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9333\n",
            "Epoch 890/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 1.0000\n",
            "Epoch 890: val_loss improved from 0.08521 to 0.08520, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9333\n",
            "Epoch 891/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 1.0000\n",
            "Epoch 891: val_loss improved from 0.08520 to 0.08519, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9333\n",
            "Epoch 892/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 1.0000\n",
            "Epoch 892: val_loss improved from 0.08519 to 0.08518, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9333\n",
            "Epoch 893/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 1.0000\n",
            "Epoch 893: val_loss improved from 0.08518 to 0.08518, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9333\n",
            "Epoch 894/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 1.0000\n",
            "Epoch 894: val_loss did not improve from 0.08518\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9333\n",
            "Epoch 895/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 1.0000\n",
            "Epoch 895: val_loss did not improve from 0.08518\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9333\n",
            "Epoch 896/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 1.0000\n",
            "Epoch 896: val_loss did not improve from 0.08518\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9333\n",
            "Epoch 897/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 1.0000\n",
            "Epoch 897: val_loss did not improve from 0.08518\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9333\n",
            "Epoch 898/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 1.0000\n",
            "Epoch 898: val_loss did not improve from 0.08518\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9333\n",
            "Epoch 899/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 1.0000\n",
            "Epoch 899: val_loss did not improve from 0.08518\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9333\n",
            "Epoch 900/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 1.0000\n",
            "Epoch 900: val_loss improved from 0.08518 to 0.08518, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9333\n",
            "Epoch 901/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 1.0000\n",
            "Epoch 901: val_loss improved from 0.08518 to 0.08517, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9333\n",
            "Epoch 902/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 1.0000\n",
            "Epoch 902: val_loss improved from 0.08517 to 0.08517, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9333\n",
            "Epoch 903/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 1.0000\n",
            "Epoch 903: val_loss did not improve from 0.08517\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9333\n",
            "Epoch 904/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 1.0000\n",
            "Epoch 904: val_loss improved from 0.08517 to 0.08514, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9333\n",
            "Epoch 905/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 1.0000\n",
            "Epoch 905: val_loss improved from 0.08514 to 0.08509, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9333\n",
            "Epoch 906/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 1.0000\n",
            "Epoch 906: val_loss improved from 0.08509 to 0.08504, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0850 - val_accuracy: 0.9333\n",
            "Epoch 907/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 1.0000\n",
            "Epoch 907: val_loss improved from 0.08504 to 0.08501, saving model to iris_bestmodel.hdf5\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0850 - val_accuracy: 0.9333\n",
            "Epoch 908/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 1.0000\n",
            "Epoch 908: val_loss did not improve from 0.08501\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0850 - val_accuracy: 0.9333\n",
            "Epoch 909/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 1.0000\n",
            "Epoch 909: val_loss did not improve from 0.08501\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.0850 - val_accuracy: 0.9333\n",
            "Epoch 910/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 1.0000\n",
            "Epoch 910: val_loss did not improve from 0.08501\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9333\n",
            "Epoch 911/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 1.0000\n",
            "Epoch 911: val_loss did not improve from 0.08501\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9333\n",
            "Epoch 912/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 1.0000\n",
            "Epoch 912: val_loss did not improve from 0.08501\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9333\n",
            "Epoch 913/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 1.0000\n",
            "Epoch 913: val_loss did not improve from 0.08501\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9333\n",
            "Epoch 914/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 1.0000\n",
            "Epoch 914: val_loss did not improve from 0.08501\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9333\n",
            "Epoch 915/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 1.0000\n",
            "Epoch 915: val_loss did not improve from 0.08501\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9333\n",
            "Epoch 916/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 1.0000\n",
            "Epoch 916: val_loss did not improve from 0.08501\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9333\n",
            "Epoch 917/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 1.0000\n",
            "Epoch 917: val_loss did not improve from 0.08501\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9333\n",
            "Epoch 918/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 1.0000\n",
            "Epoch 918: val_loss did not improve from 0.08501\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9333\n",
            "Epoch 919/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 1.0000\n",
            "Epoch 919: val_loss did not improve from 0.08501\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9333\n",
            "Epoch 920/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 1.0000\n",
            "Epoch 920: val_loss did not improve from 0.08501\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9333\n",
            "Epoch 921/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 1.0000\n",
            "Epoch 921: val_loss did not improve from 0.08501\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9333\n",
            "Epoch 922/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 1.0000\n",
            "Epoch 922: val_loss did not improve from 0.08501\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9333\n",
            "Epoch 923/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 1.0000\n",
            "Epoch 923: val_loss did not improve from 0.08501\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9333\n",
            "Epoch 924/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 1.0000\n",
            "Epoch 924: val_loss did not improve from 0.08501\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9333\n",
            "Epoch 925/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 1.0000\n",
            "Epoch 925: val_loss did not improve from 0.08501\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9333\n",
            "Epoch 926/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 1.0000\n",
            "Epoch 926: val_loss did not improve from 0.08501\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9333\n",
            "Epoch 927/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 1.0000\n",
            "Epoch 927: val_loss did not improve from 0.08501\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9333\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2474 - accuracy: 0.9333\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.6073980e-07, 2.8076663e-04, 9.9971908e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 검증셋과 학습셋의 오차를 저장\n",
        "y_vloss = history.history['val_loss']\n",
        "y_loss = history.history['loss']\n",
        "\n",
        "# 그래프로 표현\n",
        "x_len = np.arange(len(y_loss))\n",
        "plt.plot(x_len, y_vloss, marker='.', c=\"red\", label='Testset_loss')\n",
        "plt.plot(x_len, y_loss, marker='.', c=\"blue\", label='Trainset_loss')\n",
        "\n",
        "# 그래프에 그리드를 주고 레이블을 표시\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "HL1UnH9vjZ_r",
        "outputId": "8071ef7d-5b6a-4b6e-9212-13c4fad7e640"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)\n",
        "\n",
        "# 모델의 이름 설정\n",
        "modelpath=\"Ch15-house.hdf5\"\n",
        "\n",
        "# 최적화 모델을 업데이트하고 저장합니다.\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=0, save_best_only=True)\n",
        "\n",
        "#실행 관련 설정을 하는 부분입니다. 전체의 20%를 검증셋으로 설정. \n",
        "history = model.fit(X_train, y_train, validation_split=0.25, epochs=2000, batch_size=32, callbacks=[early_stopping_callback, checkpointer])"
      ],
      "metadata": {
        "id": "QIsLqYdfmjBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# irir data practice 전체 코드\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv('/content/deeplearning/data/iris3.csv')\n",
        "\n",
        "X = df.iloc[:,0:4]\n",
        "y = df.iloc[:, -1]\n",
        "y = pd.get_dummies(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(24, input_dim=4, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "accuracy = model.evaluate(X_test, y_test)[1]\n",
        "\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)\n",
        "\n",
        "modelpath=\"iris_bestmodel.hdf5\"\n",
        "\n",
        "# 최적화 모델을 업데이트하고 저장\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=2000, batch_size=500, validation_split=0.25, verbose=1, callbacks=[early_stopping_callback, checkpointer])\n",
        "model.evaluate(X_test, y_test)\n",
        "\n",
        "test1 = [5.2, 2.6, 1, 1.2] \n",
        "test2 = [6.7, 2.8, 6.6, 2] \n",
        "\n",
        "model.predict([test1])\n",
        "model.predict([test2])\n",
        "\n",
        "# 검증셋과 학습셋의 오차를 저장\n",
        "y_vloss = history.history['val_loss']\n",
        "y_loss = history.history['loss']\n",
        "\n",
        "# 그래프로 표현\n",
        "x_len = np.arange(len(y_loss))\n",
        "plt.plot(x_len, y_vloss, marker='.', c=\"red\", label='Testset_loss')\n",
        "plt.plot(x_len, y_loss, marker='.', c=\"blue\", label='Trainset_loss')\n",
        "\n",
        "# 그래프에 그리드를 주고 레이블을 표시\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5Eqm28aLlPr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "186ZrGVkj0ET"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}